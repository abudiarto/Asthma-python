{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fa08f1bc-f995-446d-9d01-569bb5721d43",
   "metadata": {
    "tags": []
   },
   "source": [
    "## parameter search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91d5dca5-ff2e-4d72-859f-0591120484b3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !pip install scikeras\n",
    "# !pip install keras-tuner --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a1df8b3a-af8f-4e3b-8aed-f5d1c92c52b4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import model_helper_Search\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LeakyReLU\n",
    "from scikeras.wrappers import KerasClassifier\n",
    "import keras_tuner\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "\n",
    "tf.random.set_seed(99)\n",
    "\n",
    "target_outcome = '12months'\n",
    "max_codes = 150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "807ed6e0-f537-4743-95fd-d24dac736a09",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------- Load Data ------------------------------\n",
      "(94701, 16)\n",
      "-----------------we passed the heaviest part------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/rapids/notebooks/host/python/model_helper_Search.py:348: DtypeWarning: Columns (25,26,28,29,32,33,80,84) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  tabularData = pd.read_csv('../FinalData/cleaned_features_01122023.csv')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13\n",
      "(94701, 16)\n",
      "(696659, 100)\n",
      "(94701, 46)\n",
      "########## Data split, train=England, eval=Scot+Wales ################\n",
      "Train:  45552\n",
      "Val:  24403\n",
      "Eval (internal validation):  11388\n",
      "Test:  5287\n",
      "Test - Wales:  3023\n",
      "Test - Scotland:  2264\n",
      "############# make sure no data leak between sets #######################\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "2264\n",
      "############# Positive and negative groups ratio #######################\n",
      "0    0.834694\n",
      "1    0.165306\n",
      "Name: 12months, dtype: float64\n",
      "0    0.834692\n",
      "1    0.165308\n",
      "Name: 12months, dtype: float64\n",
      "0    0.834651\n",
      "1    0.165349\n",
      "Name: 12months, dtype: float64\n",
      "0    0.772839\n",
      "1    0.227161\n",
      "Name: 12months, dtype: float64\n",
      "0    0.780681\n",
      "1    0.219319\n",
      "Name: 12months, dtype: float64\n",
      "0    0.762367\n",
      "1    0.237633\n",
      "Name: 12months, dtype: float64\n",
      "############## Generate X (Xt: tabular | Xs: read code sequence | Xm: month visit sequence) and y ####################\n"
     ]
    }
   ],
   "source": [
    "# # %%time\n",
    "\n",
    "trainingData, valData, evalData, testData, testDataWales, testDataScotland, vocab_size_clinical, vocab_size_therapy, month_size = model_helper_Search.load_data_split(target_outcome)\n",
    "\n",
    "#generate X and y\n",
    "Xt_train, Xt_val, Xt_eval, Xt_test, Xt_testWales, Xt_testScotland, Xs_clin_train, Xs_clin_val, Xs_clin_eval, Xs_clin_test, Xs_clin_testWales, Xs_clin_testScotland, Xs_ther_train, Xs_ther_val, Xs_ther_eval, Xs_ther_test, Xs_ther_testWales, Xs_ther_testScotland, Xm_clin_train, Xm_clin_val, Xm_clin_eval, Xm_clin_test, Xm_clin_testWales, Xm_clin_testScotland, Xm_ther_train, Xm_ther_val, Xm_ther_eval, Xm_ther_test, Xm_ther_testWales, Xm_ther_testScotland, y_train, y_val, y_eval, y_test, y_testWales, y_testScotland = model_helper_Search.generate_X_y_split(trainingData, valData, evalData, testData, testDataWales, testDataScotland, target_outcome)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "85c44c87-b939-4a6f-ae49-3396f15f8ddf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "training_dataset_ClinTher = Xt_train, Xt_val, Xt_eval, Xs_clin_train, Xs_clin_val, Xs_clin_eval, Xs_ther_train, Xs_ther_val, Xs_ther_eval, Xm_clin_train, Xm_clin_val, Xm_clin_eval, Xm_ther_train, Xm_ther_val, Xm_ther_eval, y_train, y_val, y_eval\n",
    "test_dataset_ClinTher = Xt_test, Xt_testWales, Xt_testScotland, Xs_clin_test, Xs_clin_testWales, Xs_clin_testScotland, Xs_ther_test, Xs_ther_testWales, Xs_ther_testScotland, Xm_clin_test, Xm_clin_testWales, Xm_clin_testScotland, Xm_ther_test, Xm_ther_testWales, Xm_ther_testScotland, y_test, y_testWales, y_testScotland\n",
    "pickle.dump(training_dataset_ClinTher, open('../SeqModel/training_dataset_ClinTher.sav', 'wb'))\n",
    "pickle.dump(test_dataset_ClinTher, open('../SeqModel/test_dataset_ClinTher.sav', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c4570f9-7c41-4125-82fa-a2ca3f673fbb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sets = trainingData, valData, evalData, testData, testDataWales, testDataScotland\n",
    "pickle.dump(sets, open('../SeqModel/datasets_1year_clinical.sav', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91d23fac-c37c-4295-af1e-09ec49e6f13f",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# n_train = 20000\n",
    "# n_val = int((20/100)*50000)\n",
    "# sets_parameterSearch = Xt_train[:n_train], Xt_val[:n_val], Xs_train[:n_train], Xs_val[:n_val], Xm_train[:n_train], Xm_val[:n_val], y_train[:n_train], y_val[:n_val]\n",
    "sets_parameterSearch = Xt_train, Xt_val, Xt_eval, Xs_train, Xs_val, Xs_eval, Xm_train, Xm_val, Xm_eval, y_train, y_val, y_eval\n",
    "setsEval_parameterSearch = Xt_test, Xt_testWales, Xt_testScotland, Xs_test, Xs_testWales, Xs_testScotland, Xm_test, Xm_testWales, Xm_testScotland, y_test, y_testWales, y_testScotland\n",
    "pickle.dump(sets_parameterSearch, open('../SeqModel/sets_1year_therapy.sav', 'wb'))\n",
    "pickle.dump(setsEval_parameterSearch, open('../SeqModel/sets_eval_1year_therapy.sav', 'wb'))\n",
    "\n",
    "# sets = pickle.load(open('../SeqModel/sets_search_therapy.sav', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be06e1e5-9f12-4918-9e14-9883b07922c9",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "tuner = model_helper_Search.search_model_parameters('early')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6875dd5d-eebe-4eeb-b493-d47c09b3a0da",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "best_hps = tuner.get_best_hyperparameters(5)\n",
    "# Build the model with the best hp.\n",
    "model = model_helper_Search.MyHyperModel_late()\n",
    "model = model.build(best_hps[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93d304c6-8a00-4cb2-972b-19b284658e19",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sets = pickle.load(open('../SeqModel/sets.sav', 'rb'))\n",
    "Xt_train, Xt_val, Xt_eval, Xt_test, Xt_testWales, Xt_testScotland, Xs_train, Xs_val, Xs_eval, Xs_test, Xs_testWales, Xs_testScotland, Xm_train, Xm_val, Xm_eval, Xm_test, Xm_testWales, Xm_testScotland, y_train, y_val, y_eval, y_test, y_testWales, y_testScotland = sets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55ed5ae7-8302-46bf-bcf3-9b299f51e7dd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pos_weight = sum(x == 0 for x in y_train)/sum(x == 1 for x in y_train)\n",
    "class_weight = {0:1, 1:pos_weight}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5ad1a43-947f-48b5-8d9f-e875b9c006bc",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau, TensorBoard\n",
    "earlyStopping = EarlyStopping(monitor='val_auc', patience=8, verbose=0, mode='max', restore_best_weights=True)\n",
    "mcp_save = ModelCheckpoint('../SeqModel/seqModel_all_tabSeq.mdl_wts.hdf5', save_best_only=True, monitor='val_auc', mode='min')\n",
    "# log_dir = \"../SeqModel/logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "# tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "history = model.fit([Xt_train, Xs_train, Xm_train], y_train, validation_data=([Xt_val, Xs_val, Xm_val], y_val), \n",
    "                        epochs=100, batch_size=128, \n",
    "                            class_weight = class_weight, \n",
    "                            callbacks = [earlyStopping, mcp_save])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6f12e8d-3846-4bfc-8f62-5de99c1e7e53",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# list all data in history\n",
    "print(history.history.keys())\n",
    "# summarize history for accuracy\n",
    "plt.plot(history.history['auc'])\n",
    "plt.plot(history.history['val_auc'])\n",
    "# plt.ylim(0.55,1)\n",
    "plt.title('model AUC')\n",
    "plt.ylabel('AUC')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "# plt.ylim(0.1, 1.15)\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2ace446-7e38-4c1f-879d-b09e916d0ed8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "#model evaluation\n",
    "Xts = [Xt_eval, Xt_test, Xt_testWales, Xt_testScotland]\n",
    "Xss = [Xs_eval, Xs_test, Xs_testWales, Xs_testScotland]\n",
    "Xms = [Xm_eval, Xm_test, Xm_testWales, Xm_testScotland]\n",
    "ys = [y_eval, y_test, y_testWales, y_testScotland]\n",
    "sets = zip(Xts, Xss, Xms, ys)\n",
    "model_helper_Search.evaluate_model(model, sets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ef24211-1123-48fb-91b8-091402cce427",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
