{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "455d01d3-b746-40dc-915a-3fd111ba52e1",
   "metadata": {},
   "source": [
    "# Sequence generation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5e965f6-5bb0-4bfb-a2cc-50eae440bac3",
   "metadata": {},
   "source": [
    "- all available historical data\n",
    "- include static features\n",
    "\n",
    "- attention mechanism\n",
    "\n",
    "- validation on DataLoch\n",
    "\n",
    "- model explanation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee4d8f95-286c-4067-8985-4b7d6f9d0b6c",
   "metadata": {},
   "source": [
    "# LSTM Model using Clinical + Therapy sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae1286de-3d50-4eb3-b3c7-a4404748f00b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import imdb\n",
    "from tensorflow.keras.models import Sequential, Model, load_model\n",
    "from tensorflow.keras.layers import Dense, LSTM, Embedding, Dropout, Bidirectional, Input, Reshape, BatchNormalization, Flatten, concatenate, Add, Multiply, LeakyReLU\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from tensorflow.keras.metrics import AUC, SensitivityAtSpecificity\n",
    "from tensorflow.keras.optimizers import Adam, Adagrad, RMSprop, Adamax, SGD\n",
    "from tensorflow.keras.initializers import Constant\n",
    "from tensorflow.keras.regularizers import L1L2, L1, L2\n",
    "from livelossplot import PlotLossesKeras\n",
    "\n",
    "# from tensorflow.keras.backend.tensorflow_backend import set_session\n",
    "from tensorflow.python.keras import backend as K\n",
    "\n",
    "#internal validation\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report, f1_score, balanced_accuracy_score, matthews_corrcoef, auc, average_precision_score, roc_auc_score, balanced_accuracy_score, roc_curve, accuracy_score\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "# fix random seed for reproducibility\n",
    "tf.random.set_seed(1234)\n",
    "\n",
    "target_outcome = '12months'\n",
    "max_codes = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea9bb248-b202-4a96-9c23-3d62d44466b7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sets =  pickle.load(open('../SeqModel/sets_1year.sav', 'rb'))\n",
    "sets_eval = pickle.load(open('../SeqModel/sets_eval_1year.sav', 'rb'))\n",
    "code2idx = pickle.load(open('../SeqModel/all_vocab_1year.sav', 'rb'))\n",
    "month2idx = pickle.load(open('../SeqModel/all_vocab_month.sav', 'rb'))\n",
    "vocab_size = len(code2idx)+1\n",
    "month_size = len(month2idx)+1\n",
    "print(vocab_size)\n",
    "print(month_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8a3097b-be84-4d29-a0b3-08214933ab5c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "Xt_train, Xt_val, Xt_eval, Xs_train, Xs_val, Xs_eval, Xm_train, Xm_val, Xm_eval, y_train, y_val, y_eval = sets\n",
    "Xt_test, Xt_testWales, Xt_testScotland, Xs_test, Xs_testWales, Xs_testScotland, Xm_test, Xm_testWales, Xm_testScotland, y_test, y_testWales, y_testScotland = sets_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b243b2b0-2c59-481b-aa7a-87746c4d2370",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print('Train: ', Xs_train.shape)\n",
    "print('Val: ', Xs_val.shape[0])\n",
    "print('Eval (internal validation): ', Xs_eval.shape[0])\n",
    "print('Test: ', Xs_test.shape[0])\n",
    "print('Test - Wales: ', Xs_testWales.shape[0])\n",
    "print('Test - Scotland: ', Xs_testScotland.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b572f71-e586-4cba-b0cf-eb194000acbe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.utils import class_weight\n",
    "sklearn_weights = class_weight.compute_class_weight('balanced', classes=np.unique(y_train), y=y_train)\n",
    "class_weight = dict(enumerate(sklearn_weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76806668-a75f-4958-951b-70277beadd46",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# pickle.dump(code2idx_all_big, open('../SeqModel/code2idx_all_big.sav', 'wb'))\n",
    "# pickle.dump(idx2code_all_big, open('../SeqModel/idx2code_all_big.sav', 'wb'))\n",
    "# pickle.dump(data, open('../SeqModel/data_all_big.sav', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ae6a305-87a6-4371-ac5a-c8573063135e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "target_outcome = '12months'\n",
    "max_codes = 70\n",
    "tab_feature_size = Xt_train.shape[1]\n",
    "lr = 1e-5\n",
    "clipvalue = 0.2\n",
    "epoch = 1000\n",
    "batch_size = 256\n",
    "embedding_vector_length = 50\n",
    "month_embedding_vector_length = 5\n",
    "# embedding_vector_length = int(np.sqrt(vocab_size))\n",
    "# embedding_vector_length = int(np.cbrt(vocab_size))\n",
    "print(embedding_vector_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3391acd-6b1a-415d-a8cc-0cb2a2ba3ae2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def earlyFussion():\n",
    "       \n",
    "    inputs1 = Input(shape=tab_feature_size)\n",
    "    inputs2 = Input(shape=max_codes)\n",
    "    inputs3 = Input(shape=max_codes)\n",
    "    \n",
    "    \n",
    "    #clinical embedding for lstm\n",
    "    embedding = Embedding(vocab_size, 50, input_length=max_codes)(inputs2)\n",
    "    \n",
    "    #month embedding for lstm\n",
    "    embedding_month = Embedding(month_size, 7, input_length=max_codes)(inputs3)\n",
    "    \n",
    "    nn = Dense(32, activation=LeakyReLU(), kernel_initializer='glorot_uniform', kernel_regularizer=L1L2(l1=0.0, l2=0.1))(inputs1)\n",
    "    nn = Dropout(0.5)(nn)\n",
    "    lstmClinical = Bidirectional(LSTM(units=16, return_sequences=True, kernel_regularizer=L1L2(l1=0.0, l2=0.1)))(embedding)\n",
    "    lstmMonth = Bidirectional(LSTM(units=16, return_sequences=True, kernel_regularizer=L1L2(l1=0.0, l2=0.1)))(embedding_month)\n",
    "    # lstm = Add()([lstmClinical, lstmMonth])\n",
    "    lstm = lstmClinical\n",
    "    \n",
    "    # nn = Reshape((1, 32))(nn)\n",
    "    # add = concatenate([nn, lstm], axis=1)\n",
    "    nn = Dense(16, activation=LeakyReLU(), kernel_initializer='glorot_uniform', kernel_regularizer=L1L2(l1=0.0, l2=0.1))(nn)\n",
    "    nn = Dropout(0.5)(nn)\n",
    "    lstm = Bidirectional(LSTM(units=8, return_sequences=True, kernel_regularizer=L1L2(l1=0.0, l2=0.1)))(lstm)\n",
    "    lstm = Dropout(0.5)(lstm)\n",
    "    \n",
    "    # # nn = Reshape((301, 64))(nn)\n",
    "    # add = concatenate([nn, lstm], axis=1)\n",
    "    nn = Dense(16, activation=LeakyReLU(), kernel_initializer='glorot_uniform', kernel_regularizer=L1L2(l1=0.0, l2=0.1))(nn)\n",
    "    nn = Dropout(0.5)(nn)\n",
    "    lstm = Bidirectional(LSTM(units=8, return_sequences=True, kernel_regularizer=L1L2(l1=0.0, l2=0.1)))(lstm)\n",
    "    lstm = Dropout(0.5)(lstm)\n",
    "    \n",
    "    nn = Reshape((1, 16))(nn)\n",
    "    model_tot = concatenate([nn, lstm], axis=1)\n",
    "    # model_tot = BatchNormalization()(model_tot)\n",
    "\n",
    "    model_tot = Dense(units=8, activation=LeakyReLU())(model_tot)\n",
    "    nn = Dropout(0.5)(nn)\n",
    "    \n",
    "    model_tot = Flatten()(model_tot)\n",
    "    output = Dense(1, activation='sigmoid')(model_tot)\n",
    "    \n",
    "    opt = RMSprop(learning_rate=1e-4, clipvalue=.5)\n",
    "    metrics = [\n",
    "        AUC(num_thresholds=1000, name='auc', curve='ROC'),\n",
    "        AUC(num_thresholds=1000, name='auprc', curve='PR'),\n",
    "        tf.keras.metrics.Precision(name='prec'),\n",
    "        tf.keras.metrics.Recall(name='rec'),\n",
    "        tf.keras.metrics.TrueNegatives(name='TN'),\n",
    "        tf.keras.metrics.TruePositives(name='TP'),\n",
    "        tf.keras.metrics.PrecisionAtRecall(0.8)\n",
    "    ]\n",
    "    \n",
    "    loss = tf.keras.losses.BinaryCrossentropy()\n",
    "    \n",
    "    model = Model(inputs=[inputs1, inputs2, inputs3], outputs=output)\n",
    "    model.compile(\n",
    "        loss='binary_crossentropy', \n",
    "        optimizer=opt, \n",
    "        metrics=metrics)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9af0a085-97ea-48b3-813b-6cb8b07bfeff",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#visualise model\n",
    "model = earlyFussion()\n",
    "# model = earlyFussion()\n",
    "print(model.summary())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "636ce94d-af98-4b83-8191-8535cd8c7ab7",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# TF_GPU_ALLOCATOR=cuda_malloc_async\n",
    "#training\n",
    "with tf.device('/GPU:0'):\n",
    "    earlyStopping = EarlyStopping(monitor='val_auc', patience=50, verbose=0, mode='max', restore_best_weights=True)\n",
    "    mcp_save = ModelCheckpoint('../SeqModel/seqModel_therapy_tabSeq.mdl_wts.hdf5', save_best_only=True, monitor='val_auc', mode='min')\n",
    "    history = model.fit([Xt_train, Xs_train[:,:max_codes], Xm_train[:,:max_codes]], y_train, validation_data=([Xt_val, Xs_val[:,:max_codes], Xm_val[:,:max_codes]], y_val), \n",
    "                            epochs=epoch, batch_size=256, \n",
    "                        class_weight = class_weight, \n",
    "                        callbacks = [earlyStopping, mcp_save])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69776c31-4f5e-4781-951d-63e6b28bc32e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# list all data in history\n",
    "print(history.history.keys())\n",
    "# summarize history for accuracy\n",
    "plt.plot(history.history['auc'])\n",
    "plt.plot(history.history['val_auc'])\n",
    "# plt.ylim(0.55,1)\n",
    "plt.title('model AUC')\n",
    "plt.ylabel('AUC')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "# plt.ylim(0.1, 1.15)\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a67e324-a9d9-453a-bd0f-ef90c3467ec2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23a9bb79-4132-4388-9f9e-04b07cdcd816",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4755c4e5-d778-45f8-bee7-8c14f15f5b80",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39cf7906-eb77-4c44-8e17-f7fc6520af47",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afeed10f-72a8-457d-bfcb-f2662e74bfc6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# create the model\n",
    "# embedding_vector_length = int(np.sqrt(vocab_size))\n",
    "embedding_vector_length = 100\n",
    "earlyStopping = EarlyStopping(monitor='val_auc', patience=10, verbose=0, mode='max', restore_best_weights=True)\n",
    "mcp_save = ModelCheckpoint('../SeqModel/seqModel_all_new.mdl_wts.hdf5', save_best_only=True, monitor='val_auc', mode='min')\n",
    "# class_weight = {0: 1, 1: 6}\n",
    "\n",
    "\n",
    "with tf.device('/GPU:0'):\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(vocab_size, embedding_vector_length, input_length=max_codes))\n",
    "    model.add(LSTM(128, return_sequences=True,\n",
    "                   bias_regularizer=L1L2(l1=0.0, l2=0.01)))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(LSTM(128, return_sequences=True,\n",
    "                   bias_regularizer=L1L2(l1=0.0, l2=0.01)))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(LSTM(128, bias_regularizer=L1L2(l1=0.0, l2=0.01)))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    # model.add(Dense(32, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    opt = RMSprop(learning_rate=5e-4, clipvalue=0.5)\n",
    "    metrics = [\n",
    "        AUC(num_thresholds=1000, name='auc', curve='ROC'),\n",
    "        AUC(num_thresholds=1000, name='auprc', curve='PR'),\n",
    "        tf.keras.metrics.Precision(name='prec'),\n",
    "        tf.keras.metrics.Recall(name='rec'),\n",
    "        tf.keras.metrics.TrueNegatives(name='TN'),\n",
    "        tf.keras.metrics.TruePositives(name='TP'),\n",
    "        tf.keras.metrics.PrecisionAtRecall(0.8)\n",
    "    ]\n",
    "    model.compile(loss='binary_crossentropy', optimizer=opt, metrics=metrics, )\n",
    "    print(model.summary())\n",
    "    history = model.fit(Xs_train[:,:max_codes], y_train, validation_data=(Xs_val[:,:max_codes], y_val), \n",
    "                        epochs=1000, batch_size=128, \n",
    "                        class_weight = class_weight, \n",
    "                        callbacks = [earlyStopping, mcp_save])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c2a56d1-042d-4fb9-98ba-55323ae95c15",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb4cf3d2-2342-4df8-98ee-ecca942d40a0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f29527ec-f7d3-4668-ad0e-92c91e57411e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import io\n",
    "out_v = io.open('../SeqModel/vectors.tsv', 'w', encoding='utf-8')\n",
    "out_m = io.open('../SeqModel/metadata.tsv', 'w', encoding='utf-8')\n",
    "for index, word in enumerate(vocab):\n",
    "  if (index == 0)|(index == 1)|(index == 2):\n",
    "    continue  # skip 0,1,2, it's padding, satr and end\n",
    "  vec = embeddings_vector[index]\n",
    "  out_v.write('\\t'.join([str(x) for x in vec]) + \"\\n\")\n",
    "  out_m.write(word + \"\\n\")\n",
    "\n",
    "out_v.close()\n",
    "out_m.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c14e76ce-0a39-4ca0-a8cd-d9ba570ddd1f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdbddf77-c941-48d2-9bbd-b80b77d85e5b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20c11344-dfa9-40e6-b2d2-63388d84ba09",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with tf.device('/CPU:0'):\n",
    "    # model.evaluate(X_train, y_train)\n",
    "    model.evaluate(X_val, y_val, batch_size=300)\n",
    "    model.evaluate(X_eval, y_eval, batch_size=300)\n",
    "    model.evaluate(X_test, y_test, batch_size=300)\n",
    "    model.evaluate(X_testWales, y_testWales, batch_size=300)\n",
    "    model.evaluate(X_testScotland, y_testScotland, batch_size=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f7fd35d-2903-48e4-a655-b55f16b99da1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Model evaluation function\n",
    "def summariseResult (testY, preds):\n",
    "    tn, fp, fn, tp = confusion_matrix(testY, preds).ravel()\n",
    "    specificity = tn / (tn+fp)\n",
    "    sensitivity = tp / (tp+fn)\n",
    "    ppv = 100*tp/(tp+fp)\n",
    "    npv = 100*tn/(fn+tn)\n",
    "    acc = accuracy_score(testY, preds)\n",
    "    f1score = f1_score(testY, preds, average = 'binary')\n",
    "    balanceacc = balanced_accuracy_score(testY, preds)\n",
    "    fpr, tpr, thresholds = roc_curve(testY, preds, pos_label=1)\n",
    "    aucscore = auc(fpr, tpr)\n",
    "    # aucscore = roc_auc_score(testY, preds)\n",
    "    auprc = average_precision_score(testY, preds)\n",
    "    # plot_confusion_matrix(model, testX, testY, cmap='viridis')  \n",
    "    return np.round(acc,4), np.round(specificity,4), np.round(sensitivity,4), np.round(aucscore,4), np.round(auprc,4), np.round(balanceacc,4), np.round(f1score,4), np.round(ppv,4), np.round(npv,4)\n",
    "\n",
    "data_test_Xs = [X_eval, X_test, X_testWales, X_testScotland]\n",
    "data_test_ys = [y_eval, y_test, y_testWales, y_testScotland]\n",
    "for data_test_X, data_test_y in zip(data_test_Xs, data_test_ys):\n",
    "    with tf.device('/CPU:0'):\n",
    "        preds = model.predict(data_test_X)\n",
    "    preds = [0 if pred <0.5 else 1 for pred in preds]\n",
    "    print(summariseResult(data_test_y, np.squeeze(preds)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8a50962-2f80-4931-8eb7-df84792130ed",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# model.save('../SeqModel/model_all.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f9f42bb-89f7-4693-852f-ae329cc7afe7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd0c4b94-3df3-47ba-9ef3-ab2d5c61df98",
   "metadata": {},
   "outputs": [],
   "source": [
    "extractor = tf.keras.Model(inputs=model.inputs, outputs=model.get_layer('embedding').output)\n",
    "embeddings_vector = model.layers[0].get_weights()[0]\n",
    "\n",
    "# `embeddings` has a shape of (num_vocab, embedding_dim) \n",
    "\n",
    "# `word_to_index` is a mapping (i.e. dict) from words to their index, e.g. `love`: 69\n",
    "words_embeddings = {w:embeddings_vector[idx] for w, idx in code2idx.items()}\n",
    "\n",
    "vocab = list(code2idx.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "104cf9ea-6871-4009-9e7e-f626adbde85a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca_2dim = PCA(random_state=0).fit_transform(embeddings_vector)[:,:2]\n",
    "pca_2dim = pd.DataFrame(pca_2dim, columns=['PC1', 'PC2'])\n",
    "pca_2dim['code'] = vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d59d49e-2c2f-4fb3-8327-62ce56522beb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "asthma_readcodes = pd.read_csv('../RCodes/ClinicalCodes/definite_asthma_read_codes.csv')[['readcode_new']]\n",
    "ethnicity = pd.read_csv('../RCodes/ClinicalCodes/Ethinicity.csv')[['Read.Code']]\n",
    "smoking = pd.read_csv('../RCodes/ClinicalCodes/SmokingReadcodes.csv')[['Read Code']]\n",
    "ICS = pd.read_csv('../RCodes/ClinicalCodes/ICS_Asthma.csv')[['code_id']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcb211b9-1c91-421a-9c6b-6fada17fe001",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "asthma_readcodes.columns = ['ReadCode']\n",
    "asthma_readcodes['label'] = 'asthma specific'\n",
    "asthma_readcodes['label_num'] = 0\n",
    "ethnicity.columns = ['ReadCode']\n",
    "ethnicity['label'] = 'ethnicity'\n",
    "ethnicity['label_num'] = '1'\n",
    "smoking.columns = ['ReadCode']\n",
    "smoking['label'] = 'smoking'\n",
    "smoking['label_num'] = '2'\n",
    "ICS.columns = ['ReadCode']\n",
    "ICS['label'] = 'ICS'\n",
    "ICS['label_num'] = '3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0effbdc3-8838-4044-8832-7896bc25f704",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.concat([asthma_readcodes, ethnicity, smoking, ICS])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01aafc54-69d3-4a8c-99d2-7604318ba548",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pca_subset = pca_2dim[pca_2dim.code.isin(df.ReadCode.unique())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b758107c-f214-4ac1-b0a0-4d237b5c6793",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pca_subset = df.merge(pca_subset, how='right', left_on='ReadCode', right_on='code')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "392e4cba-da65-4c65-b756-7fcbf75920e8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.scatter(pca_subset.PC1.values,pca_subset.PC2.values, c=pca_subset.label_num.values)\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
