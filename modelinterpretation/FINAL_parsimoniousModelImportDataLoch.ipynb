{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fb5d5272-20fd-430d-be93-2f54b9dd248e",
   "metadata": {},
   "source": [
    "# Model intepretation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6f7287c-5c7e-4d25-9085-f3971b3d5784",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#uncomment this below code to install imblearn package\n",
    "# !pip install imbalanced-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bdbffb2-b2a4-45fb-b395-13d2cd7513a3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !pip install scikit-optimize\n",
    "# !pip install lime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c95c2128",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import shap\n",
    "import lime\n",
    "\n",
    "#statistics\n",
    "from scipy.stats import chi2_contingency, ttest_ind\n",
    "\n",
    "# import cudf #gpu-powered DataFrame (Pandas alternative)\n",
    "\n",
    "#imbalance handling\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler, RepeatedEditedNearestNeighbours\n",
    "from imblearn.pipeline import Pipeline\n",
    "\n",
    "#preprocessing\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import OrdinalEncoder, OneHotEncoder, LabelEncoder, MinMaxScaler, StandardScaler, RobustScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#hyperparameter search\n",
    "from skopt import BayesSearchCV\n",
    "from skopt.space import Real, Integer, Categorical\n",
    "from skopt.utils import use_named_args\n",
    "from skopt import gp_minimize\n",
    "\n",
    "#internal validation\n",
    "from sklearn.model_selection import StratifiedKFold, KFold, RepeatedStratifiedKFold, cross_val_score, GridSearchCV, PredefinedSplit, RandomizedSearchCV\n",
    "\n",
    "\n",
    "#performance metrices\n",
    "from sklearn.metrics import precision_recall_curve, make_scorer, confusion_matrix, classification_report, f1_score, balanced_accuracy_score, r2_score, auc, average_precision_score, roc_auc_score, recall_score, roc_curve, accuracy_score\n",
    "\n",
    "#Models selection\n",
    "from sklearn.naive_bayes import GaussianNB, ComplementNB\n",
    "from sklearn.linear_model import LogisticRegression, ElasticNet\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import xgboost as xgb\n",
    "# from cuml.svm import SVC #gpu-powered SVM\n",
    "\n",
    "\n",
    "#save and load trained model\n",
    "import pickle\n",
    "\n",
    "#visualisation\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "import os\n",
    "\n",
    "random_state = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5b581f89-d723-4772-9ce2-f1bc72a4686c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load data\n",
    "gridSearchData, crossValData, internalEvaluationData, externalEvaluationData = pickle.load(open('PATH-TO-FILE', 'rb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0c3a0b8-45ce-44dd-8ee6-ca6bc298652a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Candidate features: 'sex', 'rhinitis', 'cardiovascular', 'heartfailure', \n",
    "# 'psoriasis', 'anaphylaxis', 'diabetes', 'ihd', 'anxiety', 'eczema', 'nasalpolyps', \n",
    "# 'ethnic_group_Asian', 'ethnic_group_Black', 'ethnic_group_Mixed', 'ethnic_group_Other',\n",
    "# 'ethnic_group_White', 'ethnic_group_not recorded', 'smokingStatus_current', \n",
    "# 'smokingStatus_former', 'smokingStatus_never', 'DeviceType_BAI', 'DeviceType_DPI', \n",
    "# 'DeviceType_NEB', 'DeviceType_not recorded', 'DeviceType_pMDI', 'PriorEducation_No',\n",
    "# 'PriorEducation_Yes', 'age', 'average_daily_dose_ICS', 'prescribed_daily_dose_ICS',\n",
    "# 'ICS_medication_possesion_ratio', 'numPCS', 'numPCSAsthma', 'numAntibioticsEvents', \n",
    "# 'numAntibioticswithLRTI', 'numOCSEvents', 'numOCSwithLRTI', 'numAsthmaAttacks', \n",
    "# 'numAcuteRespEvents', 'numHospEvents', 'numAsthmaManagement', 'numAsthmaReview', \n",
    "# 'imd_decile', 'CharlsonScore', 'BTS_step', 'BMI_cat', 'PEFStatus', 'EosinophilLevel'\n",
    "\n",
    "features_columns = gridSearchData.columns.to_list()\n",
    "exclude_columns = ['patid', 'practice_id', 'set', #identifier\n",
    "                   'BMI', #use the categorical instead\n",
    "                   'ethnicity', #use ethnic_group instead\n",
    "                   'Spacer',  #all zero\n",
    "                   'asthmaPlan', #use the continuous one\n",
    "                   \n",
    "                   'outcome_3months', 'outcome_6months', 'outcome_9months', 'outcome_12months', 'outcome_15months', 'outcome_18months', \n",
    "                   'outcome_21months', 'outcome_24months', 'outcome_combined_6months', 'outcome_combined_9months', 'outcome_combined_12months', \n",
    "                   'outcome_combined_15months', 'outcome_combined_18months', 'outcome_combined_24months', '3months', '6months', '12months', '24months', #outcomes variable\n",
    "                   \n",
    "                   'postcode_district', 'County', 'LocalAuthority', 'OutputAreaClassification', #location related variables, use IMD decile only\n",
    "                   \n",
    "                   'age_cat', 'ICS_medication_possesion_ratio_cat', 'numOCS_cat', 'numOCSEvents_cat', 'numOCSwithLRTI_cat', 'numAcuteRespEvents_cat', \n",
    "                   'numAntibioticsEvents_cat', 'numAntibioticswithLRTI_cat', 'numAsthmaAttacks_cat', 'numHospEvents_cat', 'numPCS_cat', 'numPCSAsthma_cat', \n",
    "                   'numAsthmaManagement_cat', 'numAsthmaReview_cat', 'numAsthmaMedReview_cat', 'numAsthmaReviewRCP_cat', 'average_daily_dose_ICS_cat', \n",
    "                   'prescribed_daily_dose_ICS_cat', #use continous vars instead\n",
    "                   \n",
    "                   'count_rhinitis', 'count_cardiovascular', 'count_heartfailure',\n",
    "                   'count_psoriasis', 'count_anaphylaxis', 'count_diabetes', 'count_ihd',\n",
    "                   'count_anxiety', 'count_eczema', 'count_nasalpolyps',\n",
    "                   'count_paracetamol', 'count_nsaids', 'count_betablocker', #use binary ones\n",
    "                   \n",
    "                   'paracetamol', 'nsaids', 'betablocker', #no data in evaluation\n",
    "                   'numAsthmaMedReview', 'numAsthmaReviewRCP',\n",
    "                                      \n",
    "                  ]\n",
    "# exclude_columns = exclude_columns + [x for x in features_columns if '_count' in x] #filter out commorbid count variables\n",
    "features_columns = [x for x in features_columns if x not in exclude_columns]\n",
    "print('Features size: ', len(features_columns))\n",
    "print(features_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4193b296-4619-44cb-84a0-4835e5767378",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_cross = crossValData[features_columns]\n",
    "y_cross = externalEvaluationData[['outcome_12months']]\n",
    "X_grid = gridSearchData[features_columns]\n",
    "X_internalVal = internalEvaluationData[features_columns]\n",
    "X_externalVal = externalEvaluationData[features_columns]\n",
    "y_externalVal = externalEvaluationData[['outcome_12months']]\n",
    "\n",
    "print(X_cross.shape)\n",
    "print(X_grid.shape)\n",
    "print(X_internalVal.shape)\n",
    "print(X_externalVal.shape)\n",
    "\n",
    "\n",
    "target_outcomes = [\n",
    "    'outcome_3months', 'outcome_6months', 'outcome_9months', \n",
    "    'outcome_12months',\n",
    "] \n",
    "# target_outcomes = ['12months'] \n",
    "model_names = [\n",
    "    'LR',\n",
    "    # 'DT', 'RF', \n",
    "    'XGB'\n",
    "              ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5492a94a-344c-439b-ac4c-15c4cc6e1c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Helper for generate the output\n",
    "def summariseResult (testX, testY, model):\n",
    "    preds = model.predict_proba(testX)\n",
    "    preds = [x[1] for x in preds]\n",
    "    fpr, tpr, thresholds = roc_curve(testY, preds, pos_label=1)\n",
    "    aucscore = roc_auc_score(testY, preds)\n",
    "    auprc = average_precision_score(testY, preds)\n",
    "    return np.round(aucscore,4), np.round(auprc,4)\n",
    "\n",
    "\n",
    "#Helper for processing the hyperparameters\n",
    "def process_params(param_items, best_param):\n",
    "            a = eval(param_items)\n",
    "            b = eval(best_param)\n",
    "            c = {}\n",
    "            for key, value in zip(a,b):\n",
    "                c[key] = value\n",
    "            return c"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "767aa6a9-40ff-4aeb-b7de-9db37561fdbd",
   "metadata": {},
   "source": [
    "# Train parsimonious model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ef04342-7c4f-4f64-8dd1-2d3db155b5c8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "results = []\n",
    "for outcome in target_outcomes:\n",
    "    for model in model_names:\n",
    "        best_model = pickle.load(open('ORIGINAL_MODEL', 'rb'))\n",
    "        n_features = [10,15,20] #number of top important features will be incorporated into the model\n",
    "        AUC, AUPRC = summariseResult(X_externalVal, y_externalVal, best_model)\n",
    "        results.append([outcome, model, 'original_model', AUC, AUPRC])\n",
    "        #params\n",
    "        params_dict = pd.read_csv('../../MODELS/BS_result_new.csv')\n",
    "        params_dict['params'] = params_dict.apply(lambda x: dict(eval(x.best_param[11:])), axis=1)\n",
    "        for n in n_features:\n",
    "#             if model == 'XGB':\n",
    "#                 #extract n-important features 10,15,20\n",
    "#                 sorted_idx = best_model.feature_importances_.argsort()\n",
    "#                 # plt.figure(figsize=(7,10))\n",
    "#                 # plt.barh(X_cross.columns[sorted_idx][-n:], best_model.feature_importances_[sorted_idx][-n:])\n",
    "#                 # plt.xlabel\n",
    "#                 # plt.show()\n",
    "#                 topnfeatures = X_cross.columns[sorted_idx][-n:]\n",
    "\n",
    "#                 #retrain model using subset of n-features\n",
    "#                 params = params_dict[(params_dict['outcome']==outcome)&(params_dict['model']==model)]['params'].tolist()[0]\n",
    "#                 scale_pos_ratio = y_cross.value_counts()[0]/y_cross.value_counts()[1]\n",
    "#                 trained_model = xgb.XGBClassifier(objective ='binary:logistic', tree_method = \"hist\", \n",
    "#                                               n_estimators=params['n_estimators'],\n",
    "#                                               max_depth=params['max_depth'],\n",
    "#                                               learning_rate=params['learning_rate'],\n",
    "#                                               reg_alpha=params['reg_alpha'],\n",
    "#                                               reg_lambda=params['reg_lambda'],\n",
    "#                                               # subsample=params['subsample'],\n",
    "#                                               # colsample_bytree=params['colsample_bytree'],\n",
    "#                                               # scale_pos_weight=params['scale_pos_weight'],\n",
    "#                                               scale_pos_weight=scale_pos_ratio,\n",
    "#                                               device = \"cuda\", \n",
    "#                                               verbosity = 3,\n",
    "#                                               # importance_type = 'gain', \n",
    "#                                               random_state=random_state)\n",
    "#             elif model=='LR':\n",
    "#                 sorted_idx = best_model.coef_[0].argsort()\n",
    "#                 topnfeatures = X_cross.columns[sorted_idx][-n:]\n",
    "#                 #retrain model\n",
    "#                 params = params_dict[(params_dict['outcome']==outcome)&(params_dict['model']==model)]['params'].tolist()[0]\n",
    "#                 trained_model = LogisticRegression(class_weight='balanced', C = params['C'], max_iter=params['max_iter'], solver=params['solver'], random_state=random_state)\n",
    "        \n",
    "            \n",
    "            trained_model.fit(crossValData[topnfeatures], crossValData[[outcome]])\n",
    "            AUC, AUPRC = summariseResult(externalEvaluationData[topnfeatures], externalEvaluationData[[outcome]], trained_model)\n",
    "            results.append([outcome, model, n, AUC, AUPRC])\n",
    "            pickle.dump(trained_model, open('SAVED-MODEL-nFEATURES', 'wb'))    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "11ce30f2-7854-47f7-88e1-5d94d186455b",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame(results, columns=['outcome', 'model', 'n_features', 'AUC', 'AUPRC'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c66bb4c-05c6-4d03-9db4-d2ffc7b94981",
   "metadata": {},
   "outputs": [],
   "source": [
    "results[results.outcome=='outcome_12months']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
