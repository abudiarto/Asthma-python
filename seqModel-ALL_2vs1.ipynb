{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "455d01d3-b746-40dc-915a-3fd111ba52e1",
   "metadata": {},
   "source": [
    "# Sequence generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "679fb538-9356-4f8a-b54f-a86d547dca8d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pyreadr\n",
    "import numpy as np\n",
    "import torch\n",
    "import pickle\n",
    "from os import listdir\n",
    "from os.path import isfile, join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "086a67ef-b62d-4869-8451-311c7596d1cb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/rapids/lib/python3.10/site-packages/pyreadr/_pyreadr_parser.py:233: RuntimeWarning: invalid value encountered in cast\n",
      "  df[colname] = df[colname].values.astype(\"datetime64[D]\").astype(datetime)\n",
      "/opt/conda/envs/rapids/lib/python3.10/site-packages/pandas/core/tools/datetimes.py:557: RuntimeWarning: invalid value encountered in cast\n",
      "  arr, tz_parsed = tslib.array_with_unit_to_datetime(arg, unit, errors=errors)\n",
      "/opt/conda/envs/rapids/lib/python3.10/site-packages/pandas/core/tools/datetimes.py:557: RuntimeWarning: invalid value encountered in multiply\n",
      "  arr, tz_parsed = tslib.array_with_unit_to_datetime(arg, unit, errors=errors)\n",
      "/opt/conda/envs/rapids/lib/python3.10/site-packages/pyreadr/_pyreadr_parser.py:233: RuntimeWarning: invalid value encountered in cast\n",
      "  df[colname] = df[colname].values.astype(\"datetime64[D]\").astype(datetime)\n",
      "/opt/conda/envs/rapids/lib/python3.10/site-packages/pyreadr/_pyreadr_parser.py:233: RuntimeWarning: invalid value encountered in cast\n",
      "  df[colname] = df[colname].values.astype(\"datetime64[D]\").astype(datetime)\n"
     ]
    }
   ],
   "source": [
    "patient = pyreadr.read_r('../ServerData_13Oct2020/d_patient_overall.Rdata')\n",
    "practice = pyreadr.read_r('../ServerData_13Oct2020/d_practice.Rdata')\n",
    "patient = patient['d_patient_overall']\n",
    "practice = practice['d_practice']\n",
    "\n",
    "#Age in 2016-01-01\n",
    "patient['age'] = patient.year_of_birth.apply(lambda x: 2016-x)\n",
    "\n",
    "patient = patient[['patid', 'practice_id', 'age']].merge(practice[['practice_id', 'Country']], how='left', on='practice_id')\n",
    "\n",
    "# Outcomes data\n",
    "outcomes = pd.read_csv(\"../FinalData/cleaned_outcomes_11072023.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "031a5ce8-ae16-4ccd-892e-89d3523c2678",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "outcomes['new_12MonthsOutcome'] = outcomes.apply(lambda x: (x.outcome_15months)|(x.outcome_18months)|(x.outcome_21months)|(x.outcome_24months), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db0ea4b7-62b3-444e-9757-d7c7c3f5a163",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#load clinical information\n",
    "path = '../ServerData_13Oct2020/'\n",
    "clinical_files = [join(path, f) for f in listdir(path) if (isfile(join(path, f))) & ('f_clinical_part' in f)]\n",
    "clinical = pyreadr.read_r('../ServerData_13Oct2020/f_clinical_part1.Rdata')\n",
    "clinical = clinical['f_clinical_part']\n",
    "for file in clinical_files[1:3]:\n",
    "    temp = pyreadr.read_r(file)\n",
    "    temp = temp['f_clinical_part']\n",
    "    print(temp.shape)\n",
    "    clinical = pd.concat([clinical, temp])\n",
    "    clinical.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "#data selection \n",
    "clinical = clinical.dropna(subset=['code_id'])\n",
    "clinical['event_date'] = pd.to_datetime(clinical['event_date'])\n",
    "clinical = clinical.loc[(clinical['event_date'] >= '2016-01-01') & (clinical['event_date'] < '2018-01-01')]\n",
    "\n",
    "#add paractice information\n",
    "\n",
    "#load clinical information\n",
    "path = '../ServerData_13Oct2020/'\n",
    "therapy_files = [join(path, f) for f in listdir(path) if (isfile(join(path, f))) & ('f_therapy_part' in f)]\n",
    "therapy = pyreadr.read_r('../ServerData_13Oct2020/f_therapy_part1.Rdata')\n",
    "therapy = therapy['f_therapy_part']\n",
    "for file in therapy_files[1:3]:\n",
    "    temp = pyreadr.read_r(file)\n",
    "    temp = temp['f_therapy_part']\n",
    "    print(temp.shape)\n",
    "    therapy = pd.concat([therapy, temp])\n",
    "    therapy.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "#data selection \n",
    "therapy = therapy.dropna(subset=['code_id'])\n",
    "therapy['event_date'] = pd.to_datetime(therapy['event_date'])\n",
    "therapy = therapy.loc[(therapy['event_date'] >= '2016-01-01') & (therapy['event_date'] < '2018-01-01')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edbdc0f3-e73b-4850-a0a4-fccb9d333116",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "all_raw_data = pd.concat([clinical[['patid', 'event_date', 'code_id']],\n",
    "           therapy[['patid', 'event_date', 'code_id']]])\n",
    "all_raw_data.reset_index(drop=True, inplace=True)\n",
    "#vocab and code2idx generation\n",
    "vocab_all = all_raw_data.code_id.unique().tolist()\n",
    "idx_all = range(1, len(vocab_all)+1)\n",
    "\n",
    "code2idx_all = dict(zip(vocab_all, idx_all))\n",
    "idx2code_all = dict(zip(idx_all, vocab_all))\n",
    "\n",
    "code2idx_all['PAD'] = 0\n",
    "idx2code_all[0] = 'PAD'\n",
    "VOCAB_SIZE= len(code2idx_all)\n",
    "print('code2idx Size: {}'.format(len(code2idx_all)))\n",
    "print('idx2code Size: {}'.format(len(idx2code_all)))\n",
    "# print(code2idx)\n",
    "#extract year, month, day from event date\n",
    "all_raw_data['day'] = all_raw_data.apply(lambda x: str(x['event_date'].day), axis=1)\n",
    "all_raw_data['month'] = all_raw_data.apply(lambda x: str(x['event_date'].month), axis=1)\n",
    "all_raw_data['year'] = all_raw_data.apply(lambda x: str(x['event_date'].year), axis=1)\n",
    "all_raw_data['read_code_seq'] = all_raw_data.sort_values(['event_date'], ascending=True).groupby('patid')['code_id'].transform(lambda x: ', '.join(x))\n",
    "event_data_seq_all = all_raw_data.sort_values(['event_date']).groupby('patid').agg({'day': lambda x: x.tolist(),\n",
    "                                                          'month': lambda x: x.tolist(),\n",
    "                                                          'year': lambda x: x.tolist()}).reset_index()\n",
    "all_raw_data = all_raw_data.drop_duplicates(subset=['patid']).reset_index(drop=True)     \n",
    "data_all = all_raw_data[['patid', 'read_code_seq']].merge(event_data_seq_all, how='left',  on='patid')\n",
    "data_all = data_all.merge(outcomes[['patid', 'new_12MonthsOutcome',\n",
    "                           'outcome_combined_24months']], how='inner', on='patid')\n",
    "\n",
    "data_all['read_code_seq'] = data_all['read_code_seq'].apply(lambda x: x.strip('\"\"').split(', '))\n",
    "data_all['length_read_code_seq'] = data_all['read_code_seq'].apply(lambda x: len(x))\n",
    "data_all = data_all[data_all.length_read_code_seq > 10]\n",
    "\n",
    "#padding at the beginning of the list\n",
    "max_seq = 150\n",
    "def make_uniform_data(x):\n",
    "    if len(x) < max_seq:\n",
    "        pads = ['PAD'] * (max_seq - len(x))\n",
    "        return pads + x\n",
    "    elif len(x) > max_seq:\n",
    "        x = x[len(x)-max_seq:]\n",
    "        return x\n",
    "    else:\n",
    "        return x\n",
    "    \n",
    "data_all['read_code_seq_padded'] = data_all['read_code_seq'].apply(lambda x: make_uniform_data(x))\n",
    "data_all['read_code_seq_padded_idx'] = data_all['read_code_seq_padded'].apply(lambda x: [code2idx_all.get(key) for key in x])\n",
    "data_all = data_all.merge(patient[['patid', 'Country', 'age']], how='left', on='patid')\n",
    "data_all = data_all.drop_duplicates(subset=['patid']).reset_index(drop=True)     \n",
    "\n",
    "#SAVE all important materials\n",
    "pickle.dump(code2idx_all, open('../SeqModel/code2idx_all_new.sav', 'wb'))\n",
    "pickle.dump(idx2code_all, open('../SeqModel/idx2code_all_new.sav', 'wb'))\n",
    "pickle.dump(data_all, open('../SeqModel/data_all_new.sav', 'wb'))\n",
    "# data_all.to_csv('../SeqModel/seqData_all.csv', index_label=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfda6160-b50a-471c-a156-421381b33eb8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ee4d8f95-286c-4067-8985-4b7d6f9d0b6c",
   "metadata": {},
   "source": [
    "# LSTM Model using Clinical + Therapy sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ae1286de-3d50-4eb3-b3c7-a4404748f00b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import imdb\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM, Embedding, Dropout\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from tensorflow.keras.metrics import AUC, SensitivityAtSpecificity\n",
    "from tensorflow.keras.optimizers import Adam, Adagrad, RMSprop\n",
    "from tensorflow.keras.initializers import Constant\n",
    "from tensorflow.keras.regularizers import L1L2, L1, L2\n",
    "\n",
    "\n",
    "#internal validation\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report, f1_score, balanced_accuracy_score, matthews_corrcoef, auc, average_precision_score, roc_auc_score, balanced_accuracy_score, roc_curve, accuracy_score\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "# fix random seed for reproducibility\n",
    "tf.random.set_seed(1234)\n",
    "\n",
    "target_outcome = 'new_12MonthsOutcome'\n",
    "max_codes = 150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "99d66269-80cc-4450-9432-b75bcb598efb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37644"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the dataset but only keep the top n words, zero the rest\n",
    "data = pickle.load(open('../SeqModel/data_all_new.sav', 'rb'))\n",
    "code2idx = pickle.load(open('../SeqModel/code2idx_all_new.sav', 'rb'))\n",
    "idx2code = pickle.load(open('../SeqModel/idx2code_all_new.sav', 'rb'))\n",
    "\n",
    "vocab_size = len(code2idx)\n",
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23098e77-76c5-422c-bdbd-a0152e9876c4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# #Data split conventional (mixed countries)\n",
    "# trainingData, testData = train_test_split(data, test_size=0.1, stratify=data[target_outcome], random_state=1234)\n",
    "# trainingData, valData = train_test_split(trainingData, test_size=0.2, stratify=trainingData[target_outcome], random_state=1234)\n",
    "# print(trainingData.shape)\n",
    "# print(valData.shape)\n",
    "# print(testData.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9d0d0809-4055-42b9-a738-5438011b7eb4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Data split, train=England, eval=Scot+Wales\n",
    "trainingData = data[(data.Country == 'England') & (data.age >= 18)]\n",
    "trainingData, valData = train_test_split(trainingData, test_size=0.2, stratify=trainingData[target_outcome], random_state=1234)\n",
    "trainingData, evalData = train_test_split(trainingData, test_size=0.2, stratify=trainingData[target_outcome], random_state=1234)\n",
    "testData = data[((data.Country == 'Wales') | (data.Country == 'Scotland')) & (data.age >= 18)]\n",
    "testDataWales = data[(data.Country == 'Wales') & (data.age >= 18)]\n",
    "testDataScotland = data[(data.Country == 'Scotland') & (data.age >= 18)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9f157bd3-b8a1-47e5-b6de-3e4f7d466bb5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:  14031\n",
      "Val:  4385\n",
      "Eval (internal validation):  3508\n",
      "Test:  1590\n",
      "Test - Wales:  1062\n",
      "Test - Scotland:  528\n"
     ]
    }
   ],
   "source": [
    "print('Train: ', trainingData.shape[0])\n",
    "print('Val: ', valData.shape[0])\n",
    "print('Eval (internal validation): ', evalData.shape[0])\n",
    "print('Test: ', testData.shape[0])\n",
    "print('Test - Wales: ', testDataWales.shape[0])\n",
    "print('Test - Scotland: ', testDataScotland.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bdf217de-6216-4a7d-b8ef-705c69fb52cf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14031,)\n",
      "(14031, 12)\n"
     ]
    }
   ],
   "source": [
    "print(trainingData.patid.unique().shape)\n",
    "print(trainingData.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a8913a7a-5e44-4359-85a4-5e4bdf6501c7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[43487233, 43487235, 43464708, 43139079, 43378699, 43139096, 43165721, 43378721, 43165731, 43165732, 43487269, 43165737, 43165746, 43325496, 43311166, 43374655, 43464772, 43227211, 43466834, 43378773, 43311191, 43339865, 43139165, 43284586, 43233387, 43374709, 43139214, 43315349, 43165847, 43430042, 43442340, 43145381, 43327661, 43350191, 43491513, 43315386, 43135161, 43145404, 43253954, 43430083, 43192522, 43190477, 43339982, 43190478, 43253966, 43303126, 43423963, 43430108, 43426012, 43430118, 43180267, 43251950, 43317488, 43141371, 43340029, 43317502, 43190531, 43317508, 43190533, 43204870, 43491591, 43340044, 43317518, 43430159, 43190548, 43317526, 43315483, 43208987, 43315486, 43317538, 43254052, 43208998, 43192615, 43317543, 43209011, 43430199, 43430210, 43413830, 43489611, 43340108, 43209038, 43491667, 43340118, 43477336, 43491680, 43491683, 43272551, 43413865, 43221371, 43426174, 43342206, 43413898, 43336077, 43209102, 43489679, 43342222, 43489683, 43426195, 43489687, 43188637, 43221410, 43342248, 43491760, 43262384, 43145648, 43262393, 43426234, 43491780, 43420103, 43336137, 43426254, 43426256, 43491794, 43373014, 43205080, 43188697, 43188698, 43491804, 43426270, 43373023, 43272675, 43489770, 43336177, 43416050, 43188726, 43336187, 43188732, 43461119, 43354623, 43188737, 43416074, 43205133, 43336208, 43141648, 43188754, 43145745, 43426324, 43420181, 43334167, 43348507, 43137565, 43348533, 43137590, 43188792, 43334201, 43225657, 43141693, 43188798, 43422271, 43221570, 43201094, 43201099, 43326028, 43334223, 43141712, 43227730, 43205204, 43141717, 43446875, 43141724, 43201115, 43139682, 43201124, 43137642, 43205226, 43205230, 43446898, 43137653, 43420278, 43446903, 43227772, 43221631, 43201160, 43305611, 43489943, 43221657, 43381406, 43139746, 43446951, 43446952, 43137715, 43221684, 43137725, 43334334, 43229886, 43305665, 43446982, 43264714, 43305679, 43408084, 43447001, 43143897, 43221722, 43221726, 43408102, 43309800, 43375338, 43125484, 43496172, 43229934, 43444976, 43447031, 43383544, 43447038, 43143934, 43143938, 43307779, 43467524, 43283205, 43264772, 43496205, 43383569, 43283218, 43166482, 43143956, 43223826, 43191061, 43275032, 43332380, 43264796, 43275038, 43191071, 43229988, 43275048, 43166506, 43143980, 43223860, 43180852, 43223863, 43248444, 43166525, 43469637, 43223884, 43191117, 43176784, 43326293, 43248471, 43469657, 43311969, 43275107, 43283299, 43283302, 43166566, 43332458, 43191146, 43176813, 43176816, 43275120, 43463538, 43166580, 43283317, 43414391, 43248507, 43275133, 43166593, 43275145, 43094922, 43322250, 43223947, 43158409, 43344781, 43309965, 43447183, 43463569, 43275156, 43275157, 43322263, 43463575, 43158425, 43180955, 43475872, 43322273, 43340707, 43176870, 43166640, 43494324, 43322297, 43426753, 43475907, 43475908, 43344840, 43287496, 43322322, 43428826, 43344866, 43428846, 43463674, 43463676, 43344894, 43172865, 43179009, 43203589, 43496454, 43256838, 43144197, 43463689, 43428900, 43346990, 43258927, 43308081, 43205690, 43254846, 43443263, 43447360, 43344961, 43322437, 43443270, 43347017, 43308107, 43347019, 43426892, 43443278, 43443280, 43308119, 43254875, 43443298, 43347045, 43447403, 43261036, 43351153, 43254898, 43478133, 43347069, 43205762, 43254917, 43457670, 43347084, 43179161, 43207853, 43261103, 43381940, 43261110, 43379896, 43414715, 43162812, 43461828, 43457746, 43136213, 43347159, 43410656, 43103466, 43130099, 43130106, 43103485, 43382013, 43267328, 43130118, 43113735, 43136279, 43267351, 43103514, 43412762, 43267359, 43130144, 43427108, 43267371, 43144492, 43136302, 43136305, 43410742, 43337020, 43136320, 43414861, 43130190, 43330895, 43451732, 43144532, 43451736, 43378008, 43378012, 43113822, 43312483, 43412837, 43378024, 43451773, 43144573, 43451776, 43160960, 43279750, 43337095, 43337102, 43412882, 43337111, 43259292, 43429276, 43226530, 43160994, 43167138, 43136422, 43136427, 43425197, 43169205, 43255224, 43337148, 43412936, 43265481, 43345357, 43412948, 43259348, 43339226, 43169244, 43343329, 43169255, 43480568, 43306489, 43255291, 43169279, 43259395, 43265544, 43265559, 43124248, 43413018, 43124250, 43181599, 43480612, 43181604, 43259431, 43181608, 43429423, 43443764, 43259451, 43419197, 43189823, 43140677, 43419215, 43382354, 43306580, 43189844, 43327067, 43376231, 43306623, 43181700, 43191940, 43349638, 43286154, 43286158, 43286159, 43464340, 43286168, 43089567, 43271855, 43142845, 43224772, 43382470, 43478726, 43257551, 43349714, 43179736, 43349728, 43175653, 43185893, 43349736, 43204333, 43257583, 43323121, 43349748, 43179769, 43470587, 43456259, 43323148, 43165455, 43489041, 43224854, 43261723, 43226914, 43226915, 43464484, 43144996, 43228966, 43323184, 43323192, 43163449, 43253564, 43286338, 43493188, 43464518, 43284307, 43323226, 43226974, 43251554, 43226978, 43173731, 43226981, 43253602, 43323241, 43226990, 43304816, 43325303, 43446138, 43145086, 43251585, 43251592, 43323273, 43286409, 43491212, 43423629, 43179916, 43253654, 43464599, 43165591, 43227034, 43202459, 43423654, 43304873, 43261865, 43173801, 43446192, 43499441, 43423666, 43284403, 43251636, 43227060, 43251641, 43378623, 43372481, 43304898, 43263938, 43337667, 43491273, 43263961, 43378652, 43464682, 43466731, 43339761, 43423730, 43284465, 43268088, 43378684]\n"
     ]
    }
   ],
   "source": [
    "#make sure no data leak between sets\n",
    "print(list(set(trainingData.patid.values).intersection(set(valData.patid.values))))\n",
    "print(list(set(trainingData.patid.values).intersection(set(evalData.patid.values))))\n",
    "print(list(set(valData.patid.values).intersection(set(evalData.patid.values))))\n",
    "print(list(set(valData.patid.values).intersection(set(testData.patid.values))))\n",
    "print(list(set(trainingData.patid.values).intersection(set(testData.patid.values))))\n",
    "print(list(set(testData.patid.values).intersection(set(testDataScotland.patid.values)))) # here data leak is expected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a8ae2fa9-09d0-4bdc-ba46-3abec45b4c66",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    0.847195\n",
      "1    0.152805\n",
      "Name: new_12MonthsOutcome, dtype: float64\n",
      "0    0.847206\n",
      "1    0.152794\n",
      "Name: new_12MonthsOutcome, dtype: float64\n",
      "0    0.847206\n",
      "1    0.152794\n",
      "Name: new_12MonthsOutcome, dtype: float64\n",
      "0    0.783648\n",
      "1    0.216352\n",
      "Name: new_12MonthsOutcome, dtype: float64\n",
      "0    0.746704\n",
      "1    0.253296\n",
      "Name: new_12MonthsOutcome, dtype: float64\n",
      "0    0.857955\n",
      "1    0.142045\n",
      "Name: new_12MonthsOutcome, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(trainingData[target_outcome].value_counts(normalize=True))\n",
    "print(valData[target_outcome].value_counts(normalize=True))\n",
    "print(evalData[target_outcome].value_counts(normalize=True))\n",
    "print(testData[target_outcome].value_counts(normalize=True))\n",
    "print(testDataWales[target_outcome].value_counts(normalize=True))\n",
    "print(testDataScotland[target_outcome].value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "25ed906e-adb2-4c91-b2ef-fb50bd84ba3c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# X and y\n",
    "X_train = np.array(trainingData.read_code_seq_padded_idx.values)\n",
    "X_train = np.array([x for x in X_train])\n",
    "X_val = np.array(valData.read_code_seq_padded_idx.values)\n",
    "X_val = np.array([x for x in X_val])\n",
    "X_eval = np.array(evalData.read_code_seq_padded_idx.values)\n",
    "X_eval = np.array([x for x in X_eval])\n",
    "X_test = np.array(testData.read_code_seq_padded_idx.values)\n",
    "X_test = np.array([x for x in X_test])\n",
    "X_testWales = np.array(testDataWales.read_code_seq_padded_idx.values)\n",
    "X_testWales = np.array([x for x in X_testWales])\n",
    "X_testScotland = np.array(testDataScotland.read_code_seq_padded_idx.values)\n",
    "X_testScotland = np.array([x for x in X_testScotland])\n",
    "\n",
    "y_train = trainingData[target_outcome].values\n",
    "y_val = valData[target_outcome].values\n",
    "y_eval = evalData[target_outcome].values\n",
    "y_test = testData[target_outcome].values\n",
    "y_testWales = testDataWales[target_outcome].values\n",
    "y_testScotland = testDataScotland[target_outcome].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "add5e859-7525-40af-966e-02c99c4399af",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:  14031\n",
      "Val:  4385\n",
      "Eval (internal validation):  3508\n",
      "Test:  1590\n",
      "Test - Wales:  1062\n",
      "Test - Scotland:  528\n"
     ]
    }
   ],
   "source": [
    "print('Train: ', X_train.shape[0])\n",
    "print('Val: ', X_val.shape[0])\n",
    "print('Eval (internal validation): ', X_eval.shape[0])\n",
    "print('Test: ', X_test.shape[0])\n",
    "print('Test - Wales: ', X_testWales.shape[0])\n",
    "print('Test - Scotland: ', X_testScotland.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "692d48bc-7f2c-49f0-89d3-6ce06ebfb9dd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 1, 1: 5.544309701492537}\n"
     ]
    }
   ],
   "source": [
    "pos_weight = trainingData[target_outcome].value_counts()[0]/trainingData[target_outcome].value_counts()[1]\n",
    "neg_weight = trainingData[target_outcome].value_counts()[1]/trainingData[target_outcome].value_counts()[0]\n",
    "class_weight = {0:1, 1:pos_weight}\n",
    "print(class_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "24bf992d-9764-4eb0-8761-efcde1fb94fa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "output_bias = np.array([np.log(neg_weight)])\n",
    "output_bias = Constant(output_bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afeed10f-72a8-457d-bfcb-f2662e74bfc6",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_1 (Embedding)     (None, 150, 175)          6587700   \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 150, 100)          110400    \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 50)                30200     \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                3264      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6731629 (25.68 MB)\n",
      "Trainable params: 6731629 (25.68 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-26 11:41:37.195875: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f7d7ce929f0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2023-10-26 11:41:37.195965: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "2023-10-26 11:41:37.208548: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2023-10-26 11:41:37.230838: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "2023-10-26 11:41:37.232664: E ./tensorflow/compiler/xla/stream_executor/stream_executor_internal.h:124] SetPriority unimplemented for this stream.\n",
      "2023-10-26 11:41:37.237675: E ./tensorflow/compiler/xla/stream_executor/stream_executor_internal.h:124] SetPriority unimplemented for this stream.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  2/141 [..............................] - ETA: 38s - loss: 2.6505 - auc: 0.4815 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-26 11:41:37.637761: E ./tensorflow/compiler/xla/stream_executor/stream_executor_internal.h:124] SetPriority unimplemented for this stream.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  3/141 [..............................] - ETA: 37s - loss: 2.8364 - auc: 0.5244"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-26 11:41:37.904929: E ./tensorflow/compiler/xla/stream_executor/stream_executor_internal.h:124] SetPriority unimplemented for this stream.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 47/141 [=========>....................] - ETA: 24s - loss: 2.7194 - auc: 0.5142"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# create the model\n",
    "embedding_vector_length = 175\n",
    "earlyStopping = EarlyStopping(monitor='val_auc', patience=3, verbose=0, mode='max', restore_best_weights=True)\n",
    "mcp_save = ModelCheckpoint('../SeqModel/seqModel_all_new.mdl_wts.hdf5', save_best_only=True, monitor='val_auc', mode='min')\n",
    "\n",
    "\n",
    "with tf.device('/CPU:0'):\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(vocab_size, embedding_vector_length, input_length=max_codes))\n",
    "    model.add(LSTM(100, return_sequences=True, dropout=0.5, recurrent_dropout=0.7, \n",
    "                   recurrent_activation='relu', bias_regularizer=L1L2(l1=0.0, l2=0.01)))\n",
    "    model.add(LSTM(50, dropout=0.5))\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid', bias_initializer=output_bias))\n",
    "    opt = RMSprop(learning_rate=0.0001)\n",
    "    metrics = [\n",
    "        AUC(num_thresholds=10000, name='auc', curve='ROC'),\n",
    "    ]\n",
    "    model.compile(loss='binary_crossentropy', optimizer=opt, metrics=metrics, )\n",
    "    print(model.summary())\n",
    "    history = model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=100, batch_size=100, class_weight = class_weight, callbacks = [earlyStopping, mcp_save])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdbddf77-c941-48d2-9bbd-b80b77d85e5b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# list all data in history\n",
    "print(history.history.keys())\n",
    "# summarize history for accuracy\n",
    "plt.plot(history.history['auc'])\n",
    "plt.plot(history.history['val_auc'])\n",
    "# plt.ylim(0.55,1)\n",
    "plt.title('model AUC')\n",
    "plt.ylabel('AUC')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "# plt.ylim(0.1, 1.15)\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20c11344-dfa9-40e6-b2d2-63388d84ba09",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with tf.device('/CPU:0'):\n",
    "    model.evaluate(X_eval, y_eval)\n",
    "    model.evaluate(X_test, y_test)\n",
    "    model.evaluate(X_testWales, y_testWales)\n",
    "    model.evaluate(X_testScotland, y_testScotland)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f7fd35d-2903-48e4-a655-b55f16b99da1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Model evaluation function\n",
    "def summariseResult (testY, preds):\n",
    "    tn, fp, fn, tp = confusion_matrix(testY, preds).ravel()\n",
    "    specificity = tn / (tn+fp)\n",
    "    sensitivity = tp / (tp+fn)\n",
    "    ppv = 100*tp/(tp+fp)\n",
    "    npv = 100*tn/(fn+tn)\n",
    "    acc = accuracy_score(testY, preds)\n",
    "    f1score = f1_score(testY, preds, average = 'binary')\n",
    "    balanceacc = balanced_accuracy_score(testY, preds)\n",
    "    fpr, tpr, thresholds = roc_curve(testY, preds, pos_label=1)\n",
    "    aucscore = auc(fpr, tpr)\n",
    "    # aucscore = roc_auc_score(testY, preds)\n",
    "    auprc = average_precision_score(testY, preds)\n",
    "    # plot_confusion_matrix(model, testX, testY, cmap='viridis')  \n",
    "    return np.round(acc,4), np.round(specificity,4), np.round(sensitivity,4), np.round(aucscore,4), np.round(auprc,4), np.round(balanceacc,4), np.round(f1score,4), np.round(ppv,4), np.round(npv,4)\n",
    "\n",
    "data_test_Xs = [X_eval, X_test, X_testWales, X_testScotland]\n",
    "data_test_ys = [y_eval, y_test, y_testWales, y_testScotland]\n",
    "for data_test_X, data_test_y in zip(data_test_Xs, data_test_ys):\n",
    "    with tf.device('/CPU:0'):\n",
    "        preds = model.predict(data_test_X)\n",
    "    preds = [0 if pred <0.5 else 1 for pred in preds]\n",
    "    print(summariseResult(data_test_y, np.squeeze(preds)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8a50962-2f80-4931-8eb7-df84792130ed",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.save('../SeqModel/model_all.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f9f42bb-89f7-4693-852f-ae329cc7afe7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
