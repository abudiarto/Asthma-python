{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9e4f466e-54a2-4f96-aab6-e90cb95b295a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import pyreadr\n",
    "\n",
    "#statistics\n",
    "from scipy.stats import chi2_contingency, ttest_ind\n",
    "\n",
    "# import cudf #gpu-powered DataFrame (Pandas alternative)\n",
    "\n",
    "#imbalance handling\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler, RepeatedEditedNearestNeighbours\n",
    "from imblearn.pipeline import Pipeline\n",
    "\n",
    "#preprocessing\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import OrdinalEncoder, OneHotEncoder, LabelEncoder, MinMaxScaler, StandardScaler\n",
    "\n",
    "\n",
    "#internal validation\n",
    "from sklearn.model_selection import StratifiedKFold, KFold, RepeatedStratifiedKFold, cross_val_score, GridSearchCV, PredefinedSplit, train_test_split\n",
    "\n",
    "#performance metrices\n",
    "from sklearn.metrics import make_scorer, confusion_matrix, classification_report, f1_score, balanced_accuracy_score, matthews_corrcoef, auc, average_precision_score, roc_auc_score, balanced_accuracy_score, roc_curve, accuracy_score\n",
    "\n",
    "#Models selection\n",
    "from sklearn.naive_bayes import GaussianNB, ComplementNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import xgboost as xgb\n",
    "# from cuml.svm import SVC #gpu-powered SVM\n",
    "\n",
    "#Tree pruning\n",
    "from sklearn.tree._tree import TREE_LEAF\n",
    "\n",
    "\n",
    "#save and load trained model\n",
    "import pickle\n",
    "\n",
    "#visualisation\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn import tree\n",
    "\n",
    "from collections import Counter\n",
    "import os\n",
    "# import torch\n",
    "\n",
    "random_state = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f075d180-a6ec-4d02-a588-1446bb8ebece",
   "metadata": {},
   "outputs": [],
   "source": [
    "gridSearch_seq, crossVal_seq, internalEvaluation_seq, externalEvaluation_seq = pickle.load(open('../Clean_data/sequence_dataset_DF_27102024.sav', 'rb'))\n",
    "\n",
    "#fix BTS seqs\n",
    "bts_vars = gridSearch_seq.columns[gridSearch_seq.columns.str.contains('BTS')].values\n",
    "for var in bts_vars:\n",
    "    gridSearch_seq[var] = gridSearch_seq[var].apply(lambda x: int(x))\n",
    "    externalEvaluation_seq[var] = externalEvaluation_seq[var].apply(lambda x: int(x))\n",
    "    crossVal_seq[var] = crossVal_seq[var].apply(lambda x: int(x))\n",
    "    internalEvaluation_seq[var] = internalEvaluation_seq[var].apply(lambda x: int(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0b10ae42-f332-4ebd-b5a1-b3a9c494b93c",
   "metadata": {},
   "outputs": [],
   "source": [
    "gridSearchData, crossValData, internalEvaluationData, externalEvaluationData = pickle.load(open('../Clean_data/dataset_2vs1_25102024.sav', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cc5e120b-e9e5-45d4-949f-9663b54cd363",
   "metadata": {},
   "outputs": [],
   "source": [
    "crossVal_seq.drop(columns='outcome_12months', inplace=True)\n",
    "crossValData = crossValData.merge(crossVal_seq, on='patid', how='inner')\n",
    "\n",
    "gridSearch_seq.drop(columns='outcome_12months', inplace=True)\n",
    "gridSearchData = gridSearchData.merge(gridSearch_seq, on='patid', how='inner')\n",
    "\n",
    "internalEvaluation_seq.drop(columns='outcome_12months', inplace=True)\n",
    "internalEvaluationData = internalEvaluationData.merge(internalEvaluation_seq, on='patid', how='inner')\n",
    "\n",
    "externalEvaluation_seq.drop(columns='outcome_12months', inplace=True)\n",
    "externalEvaluationData = externalEvaluationData.merge(externalEvaluation_seq, on='patid', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4eed0fa3-3bf8-4997-8164-c42235ad0b96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(29432, 1447)\n",
      "(19678, 1447)\n"
     ]
    }
   ],
   "source": [
    "print(gridSearchData.shape)\n",
    "print(externalEvaluationData.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0d7d3904-b96d-4490-91ba-87b4d13e17b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#features\n",
    "tabular_vars = ['sex', 'rhinitis', 'cardiovascular', 'heartfailure', 'psoriasis', 'anaphylaxis', 'diabetes', 'ihd', 'anxiety', 'eczema', \n",
    "                'nasalpolyps', 'BMI_cat_normal', 'BMI_cat_not recorded', 'BMI_cat_obese', 'BMI_cat_overweight', 'BMI_cat_underweight', \n",
    "                'ethnic_group_Asian', 'ethnic_group_Black', 'ethnic_group_Mixed', 'ethnic_group_Other', 'ethnic_group_White', \n",
    "                'ethnic_group_not recorded', 'smokingStatus_current', 'smokingStatus_former', 'smokingStatus_never', 'imd_decile_0', \n",
    "                'imd_decile_1', 'imd_decile_2', 'imd_decile_3', 'imd_decile_4', 'imd_decile_5', 'imd_decile_6', 'imd_decile_7', 'imd_decile_8', \n",
    "                'imd_decile_9', 'imd_decile_10', 'CharlsonScore_0.0', 'CharlsonScore_1.0', 'CharlsonScore_2.0', 'CharlsonScore_3.0', 'CharlsonScore_4.0', \n",
    "                'CharlsonScore_5.0', 'CharlsonScore_6.0', 'CharlsonScore_7.0', 'CharlsonScore_8.0', 'CharlsonScore_9.0', 'CharlsonScore_10.0', \n",
    "                'CharlsonScore_11.0', 'CharlsonScore_12.0', 'PEFStatus_60-80', 'PEFStatus_less than 60', 'PEFStatus_more than 80', 'PEFStatus_not recorded', \n",
    "                'EosinophilLevel_high', 'EosinophilLevel_normal', 'EosinophilLevel_not recorded', 'BTS_step_0', 'BTS_step_1', 'BTS_step_2', 'BTS_step_3', \n",
    "                'BTS_step_4', 'BTS_step_5', 'DeviceType_BAI', 'DeviceType_DPI', 'DeviceType_NEB', 'DeviceType_not recorded', 'DeviceType_pMDI', \n",
    "                'PriorEducation_No', 'PriorEducation_Yes', 'age', \n",
    "                ]\n",
    "seq_vars = gridSearch_seq.columns.values.tolist()\n",
    "feature_columns = tabular_vars+seq_vars[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b25e08ef-5b1b-4789-bc9c-6ac5eaac7158",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_gridSearch = gridSearchData[feature_columns]\n",
    "X_crossVal = crossValData[feature_columns]\n",
    "X = pd.concat([X_gridSearch, X_crossVal])\n",
    "X.reset_index(drop=True, inplace=True)\n",
    "X_internalVal = internalEvaluationData[feature_columns]\n",
    "X_externalVal = externalEvaluationData[feature_columns]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eb6a4c6b-81f7-4ebb-aa41-eeaf002bd271",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_models (X_train, y_train, target_outcome, params_dict, model_folder, fold):\n",
    "    models = [] #list to store all the models\n",
    "    print(\"Building models . . . .\")\n",
    "\n",
    "    # #LR\n",
    "    # model = 'LR'\n",
    "    # params = params_dict[(params_dict['outcome']==target_outcome)&(params_dict['model']==model)]['params'].tolist()[0]\n",
    "    # # params = eval(params)\n",
    "    # print(params)\n",
    "    # lr_model = LogisticRegression(class_weight='balanced', C = params['C'], max_iter=params['max_iter'], solver=params['solver'], random_state=random_state)\n",
    "    # lr_model.fit(X_train,y_train)\n",
    "    # pickle.dump(lr_model, open(model_folder+ target_outcome + '_'+ model + str(fold) + '.sav', 'wb'))\n",
    "    # models.append([model + str(fold), target_outcome, y_train.value_counts()[1]/y_train.value_counts()[0]]) \n",
    "    # print(\"LR done\")\n",
    "\n",
    "    # #Lasso\n",
    "    # model = 'Lasso'\n",
    "    # params = params_dict[(params_dict['outcome']==target_outcome)&(params_dict['model']==model)]['params'].tolist()[0]\n",
    "    # # params = eval(params)\n",
    "    # print(params)\n",
    "    # lasso_model = LogisticRegression(class_weight='balanced',  C = params['C'], max_iter=params['max_iter'], penalty='l1', solver=params['solver'], random_state=random_state) #only the LIBLINEAR and SAGA (added in v0.19) solvers handle the L1 penalty\n",
    "    # lasso_model.fit(X_train, y_train)\n",
    "    # pickle.dump(lasso_model, open(model_folder+ target_outcome + '_'+ model + str(fold) + '.sav', 'wb'))\n",
    "    # models.append([model + str(fold), target_outcome, y_train.value_counts()[1]/y_train.value_counts()[0]])\n",
    "    # print(\"Lasso done\")\n",
    "    \n",
    "    # #Elastics\n",
    "    # model = 'ElasticNet'\n",
    "    # params = params_dict[(params_dict['outcome']==target_outcome)&(params_dict['model']==model)]['params'].tolist()[0]\n",
    "    # # params = eval(params)\n",
    "    # print(params)\n",
    "    # elastics_model = LogisticRegression(class_weight='balanced', solver='saga', l1_ratio=params['l1_ratio'], max_iter=params['max_iter'],  penalty = 'elasticnet', random_state=random_state)\n",
    "    # elastics_model.fit(X_train, y_train)\n",
    "    # pickle.dump(elastics_model, open(model_folder+ target_outcome + '_'+ model + str(fold) + '.sav', 'wb'))\n",
    "    # models.append([model + str(fold), target_outcome, y_train.value_counts()[1]/y_train.value_counts()[0]])\n",
    "    # print(\"Elastics done\")\n",
    "\n",
    "\n",
    "    # #DT\n",
    "    # model = 'DT'\n",
    "    # params = params_dict[(params_dict['outcome']==target_outcome)&(params_dict['model']==model)]['params'].tolist()[0]\n",
    "    # # params = eval(params)\n",
    "    # print(params)\n",
    "    # dt_model = DecisionTreeClassifier(class_weight='balanced', max_depth=params['max_depth'], criterion=params['criterion'], splitter=params['splitter'], random_state=random_state)\n",
    "    # dt_model.fit(X_train, y_train)\n",
    "    # pickle.dump(dt_model, open(model_folder+ target_outcome + '_'+ model + str(fold) + '.sav', 'wb'))    \n",
    "    # models.append([model + str(fold), target_outcome, y_train.value_counts()[1]/y_train.value_counts()[0]])\n",
    "    # print(\"DT done\")\n",
    "\n",
    "    # #RF\n",
    "    # model = 'RF'\n",
    "    # params = params_dict[(params_dict['outcome']==target_outcome)&(params_dict['model']==model)]['params'].tolist()[0]\n",
    "    # # params = eval(params)\n",
    "    # print(params)\n",
    "    # rf_model = RandomForestClassifier(class_weight='balanced', max_depth=params['max_depth'], \n",
    "    #                                   criterion=params['criterion'], n_estimators=params['n_estimators'], \n",
    "    #                                   min_samples_split=params['min_samples_split'],\n",
    "    #                                   min_samples_leaf=params['min_samples_leaf'],\n",
    "    #                                   max_features=params['max_features'],\n",
    "    #                                   bootstrap=params['bootstrap'], \n",
    "    #                                   random_state=random_state)\n",
    "    # rf_model.fit(X_train, y_train)\n",
    "    # pickle.dump(rf_model, open(model_folder+ target_outcome + '_'+ model + str(fold) + '.sav', 'wb'))     \n",
    "    # models.append([model + str(fold), target_outcome, y_train.value_counts()[1]/y_train.value_counts()[0]])\n",
    "    # print(\"RF done\")\n",
    "\n",
    "    #XGB\n",
    "    model = 'XGB'\n",
    "    params = params_dict[(params_dict['outcome']==target_outcome)&(params_dict['model']==model)]['params'].tolist()[0]\n",
    "    # params = eval(params)\n",
    "    print(params)\n",
    "    scale_pos_ratio = y_train.value_counts()[0]/y_train.value_counts()[1]\n",
    "    xgb_model = xgb.XGBClassifier(objective ='binary:logistic', tree_method = \"hist\", \n",
    "                                  n_estimators=params['n_estimators'],\n",
    "                                  max_depth=params['max_depth'],\n",
    "                                  learning_rate=params['learning_rate'],\n",
    "                                  reg_alpha=params['reg_alpha'],\n",
    "                                  reg_lambda=params['reg_lambda'],\n",
    "                                  subsample=params['subsample'],\n",
    "                                  colsample_bytree=params['colsample_bytree'],\n",
    "                                  scale_pos_weight=params['scale_pos_weight'],\n",
    "                                  device = \"cuda\", \n",
    "                                  verbosity = 3,\n",
    "                                  importance_type = 'gain', random_state=random_state)\n",
    "    # xgb_model = xgb.XGBClassifier(objective ='binary:logistic', learning_rate = 0.001, tree_method='gpu_hist', gpu_id=0,  verbosity = 0, random_state = 1234)\n",
    "    xgb_model.fit(X_train,y_train)\n",
    "    pickle.dump(xgb_model, open(model_folder+ target_outcome + '_'+ model + str(fold) + '.sav', 'wb')) \n",
    "    models.append([model + str(fold),  target_outcome, y_train.value_counts()[1]/y_train.value_counts()[0]])\n",
    "    print(\"XGB done\")\n",
    "    \n",
    "    return models\n",
    "    # return [xgb_model]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "038be137-2ecd-4482-a7c4-93bf2d84f129",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summariseResult (testX, testY, model):\n",
    "    preds = model.predict_proba(testX)\n",
    "    preds = [x[1] for x in preds]\n",
    "    # tn, fp, fn, tp = confusion_matrix(testY, preds).ravel()\n",
    "    # specificity = tn / (tn+fp)\n",
    "    # sensitivity = tp / (tp+fn)\n",
    "    # ppv = 100*tp/(tp+fp)\n",
    "    # npv = 100*tn/(fn+tn)\n",
    "    # acc = accuracy_score(testY, preds)\n",
    "    # f1score = f1_score(testY, preds, average = 'binary')\n",
    "    # balanceacc = balanced_accuracy_score(testY, preds)\n",
    "    fpr, tpr, thresholds = roc_curve(testY, preds, pos_label=1)\n",
    "    # aucscore = auc(fpr, tpr)\n",
    "    aucscore = roc_auc_score(testY, preds)\n",
    "    auprc = average_precision_score(testY, preds)\n",
    "    # plot_confusion_matrix(model, testX, testY, cmap='viridis')  \n",
    "    return np.round(aucscore,4), np.round(auprc,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f72124ab-6536-4cae-a6ca-74a59000c5da",
   "metadata": {},
   "outputs": [],
   "source": [
    "params_dict = pd.read_csv('../MODELS/BS_result_new.csv')\n",
    "def process_params(param_items, best_param):\n",
    "    a = eval(param_items)\n",
    "    b = eval(best_param)\n",
    "    c = {}\n",
    "    for key, value in zip(a,b):\n",
    "        c[key] = value\n",
    "    return c\n",
    "\n",
    "params_dict['params'] = params_dict.apply(lambda x: dict(eval(x.best_param[11:])), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "15f592a6-1e61-41cc-87d9-ef11ce1889f0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outcome_12months\n",
      "Building models . . . .\n",
      "{'colsample_bytree': 0.5, 'learning_rate': 0.021211820714260574, 'max_depth': 2, 'n_estimators': 1000, 'reg_alpha': 10.0, 'reg_lambda': 0.1, 'scale_pos_weight': 9.691656942823805, 'subsample': 0.5}\n",
      "[04:29:23] ======== Monitor (0): HostSketchContainer ========\n",
      "[04:29:23] AllReduce: 0.015439s, 1 calls @ 15439us\n",
      "\n",
      "[04:29:23] MakeCuts: 0.026672s, 1 calls @ 26672us\n",
      "\n",
      "[04:29:23] DEBUG: /workspace/src/gbm/gbtree.cc:130: Using tree method: 3\n",
      "[04:29:23] DEBUG: /workspace/src/tree/updater_gpu_hist.cu:822: [GPU Hist]: Configure\n",
      "[04:29:23] ======== Monitor (0):  ========\n",
      "[04:29:23] InitCompressedData: 0.109395s, 1 calls @ 109395us\n",
      "\n",
      "[04:29:37] ======== Monitor (0): Learner ========\n",
      "[04:29:37] Configure: 0.00181s, 1 calls @ 1810us\n",
      "\n",
      "[04:29:37] EvalOneIter: 0.00413s, 1000 calls @ 4130us\n",
      "\n",
      "[04:29:37] GetGradient: 0.093982s, 1000 calls @ 93982us\n",
      "\n",
      "[04:29:37] PredictRaw: 0.000993s, 1000 calls @ 993us\n",
      "\n",
      "[04:29:37] UpdateOneIter: 12.3037s, 1000 calls @ 12303669us\n",
      "\n",
      "[04:29:37] ======== Monitor (0): GBTree ========\n",
      "[04:29:37] BoostNewTrees: 11.796s, 1000 calls @ 11796035us\n",
      "\n",
      "[04:29:37] CommitModel: 0.000385s, 1000 calls @ 385us\n",
      "\n",
      "[04:29:37] ======== Device 0 Memory Allocations:  ========\n",
      "[04:29:37] Peak memory usage: 2689MiB\n",
      "[04:29:37] Number of allocations: 54074\n",
      "[04:29:37] ======== Monitor (0): updater_gpu_hist ========\n",
      "[04:29:37] InitData: 0.001636s, 1000 calls @ 1636us\n",
      "\n",
      "[04:29:37] InitDataOnce: 0.001506s, 1 calls @ 1506us\n",
      "\n",
      "[04:29:37] Update: 11.5747s, 1000 calls @ 11574652us\n",
      "\n",
      "[04:29:37] UpdatePredictionCache: 0.215785s, 1000 calls @ 215785us\n",
      "\n",
      "[04:29:37] ======== Monitor (0): gradient_based_sampler ========\n",
      "[04:29:37] Sample: 0.348655s, 1000 calls @ 348655us\n",
      "\n",
      "[04:29:37] ======== Monitor (0): GPUHistMakerDevicecuda:0 ========\n",
      "[04:29:37] AllReduce: 0.000526s, 2000 calls @ 526us\n",
      "\n",
      "[04:29:37] BuildHist: 0.014433s, 2000 calls @ 14433us\n",
      "\n",
      "[04:29:37] EvaluateSplits: 0.645216s, 2000 calls @ 645216us\n",
      "\n",
      "[04:29:37] FinalisePosition: 0.837063s, 1000 calls @ 837063us\n",
      "\n",
      "[04:29:37] InitRoot: 8.83827s, 1000 calls @ 8838270us\n",
      "\n",
      "[04:29:37] Reset: 0.928462s, 1000 calls @ 928462us\n",
      "\n",
      "[04:29:37] UpdatePosition: 0.299193s, 2000 calls @ 299193us\n",
      "\n",
      "XGB done\n",
      "XGBLONG\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_19616/1827634542.py:21: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  models = pd.concat([models,models_temp]).reset_index(drop=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[04:29:37] DEBUG: /workspace/src/gbm/gbtree.cc:130: Using tree method: 3\n",
      "[04:29:37] DEBUG: /workspace/src/tree/updater_gpu_hist.cu:822: [GPU Hist]: Configure\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#EXECUTE model training\n",
    "\n",
    "summary_result_internalVal = []\n",
    "summary_result_externalVal = []\n",
    "\n",
    "cols = ['model_name', 'fold', 'outcome', 'class_ratio', 'auc', 'auprc']\n",
    "model_folder = '../MODELS/TestResultCat/'\n",
    "target_outcomes = ['outcome_12months']\n",
    "# start_time = time.time()\n",
    "for target_outcome in target_outcomes:\n",
    "    models = pd.DataFrame(columns=['modelname', 'target_outcome', 'class_ratio'])\n",
    "    print(target_outcome)\n",
    "    y = pd.concat([gridSearchData[target_outcome], crossValData[target_outcome]])\n",
    "    y.reset_index(drop=True, inplace=True)\n",
    "    y_internalVal = internalEvaluationData[target_outcome]\n",
    "    y_externalVal = externalEvaluationData[target_outcome]\n",
    "    fold = 'LONG' #no fold for the FINAL MODEL - trained on crossval and gridsearch sets\n",
    "    \n",
    "    \n",
    "    #Build models -> it can be commented if the models have been trained\n",
    "    models_temp = pd.DataFrame(build_models(X, y, target_outcome, params_dict, model_folder, fold), columns=['modelname', 'target_outcome', 'class_ratio'])\n",
    "    models = pd.concat([models,models_temp]).reset_index(drop=True)\n",
    "\n",
    "\n",
    "    #evaluate model\n",
    "    for modelname, target_outcome, classratio in models.values:\n",
    "        # print('======================================================================')\n",
    "        print(modelname)\n",
    "        model = pickle.load(open(model_folder + target_outcome + '_'+ modelname + '.sav', 'rb'))       \n",
    "        summary_result_internalVal.append((modelname, fold, target_outcome, classratio, ) + summariseResult (X_internalVal, y_internalVal, model) )       \n",
    "        summary_result_externalVal.append((modelname, fold, target_outcome, classratio, ) + summariseResult (X_externalVal, y_externalVal, model) )       \n",
    "        # torch.cuda.empty_cache()\n",
    "\n",
    "\n",
    "summary_result_internalVal = pd.DataFrame(summary_result_internalVal, columns=cols)\n",
    "summary_result_internalVal['model_num'] = summary_result_internalVal.index\n",
    "# summary_result_internalVal.to_csv('../MODELS/internalValResultCat.csv', index_label=False, index=False)\n",
    "\n",
    "summary_result_externalVal = pd.DataFrame(summary_result_externalVal, columns=cols)\n",
    "summary_result_externalVal['model_num'] = summary_result_externalVal.index\n",
    "# summary_result_externalVal.to_csv('../MODELS/externalValResultCat.csv', index_label=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e71fbd2a-4067-410c-9cb6-8cb308e9876b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>fold</th>\n",
       "      <th>outcome</th>\n",
       "      <th>class_ratio</th>\n",
       "      <th>auc</th>\n",
       "      <th>auprc</th>\n",
       "      <th>model_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>XGBLONG</td>\n",
       "      <td>LONG</td>\n",
       "      <td>outcome_12months</td>\n",
       "      <td>0.131724</td>\n",
       "      <td>0.7834</td>\n",
       "      <td>0.4633</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  model_name  fold           outcome  class_ratio     auc   auprc  model_num\n",
       "0    XGBLONG  LONG  outcome_12months     0.131724  0.7834  0.4633          0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_result_externalVal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8e3f9d36-3074-49f6-a2eb-8beaac3cdada",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>fold</th>\n",
       "      <th>outcome</th>\n",
       "      <th>class_ratio</th>\n",
       "      <th>auc</th>\n",
       "      <th>auprc</th>\n",
       "      <th>model_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>XGBLONG</td>\n",
       "      <td>LONG</td>\n",
       "      <td>outcome_12months</td>\n",
       "      <td>0.131724</td>\n",
       "      <td>0.8062</td>\n",
       "      <td>0.4474</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  model_name  fold           outcome  class_ratio     auc   auprc  model_num\n",
       "0    XGBLONG  LONG  outcome_12months     0.131724  0.8062  0.4474          0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_result_internalVal"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
