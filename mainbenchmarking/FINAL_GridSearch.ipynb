{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3cf617ae-7cd6-4168-9b2a-c61a35fcaf7c",
   "metadata": {},
   "source": [
    "# ANALYSIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6f7287c-5c7e-4d25-9085-f3971b3d5784",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#uncomment this below code to install imblearn package\n",
    "# !pip install imbalanced-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5bdbffb2-b2a4-45fb-b395-13d2cd7513a3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !pip install scikit-ssoptimize\n",
    "# !pip install shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c95c2128",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "\n",
    "#statistics\n",
    "from scipy.stats import chi2_contingency, ttest_ind\n",
    "\n",
    "# import cudf #gpu-powered DataFrame (Pandas alternative)\n",
    "\n",
    "#imbalance handling\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler, RepeatedEditedNearestNeighbours\n",
    "from imblearn.pipeline import Pipeline\n",
    "\n",
    "#preprocessing\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import OrdinalEncoder, OneHotEncoder, LabelEncoder, MinMaxScaler, StandardScaler\n",
    "\n",
    "#hyperparameter search\n",
    "from skopt import BayesSearchCV\n",
    "from skopt.space import Real, Integer, Categorical\n",
    "from skopt.utils import use_named_args\n",
    "from skopt import gp_minimize\n",
    "\n",
    "#internal validation\n",
    "from sklearn.model_selection import StratifiedKFold, KFold, RepeatedStratifiedKFold, cross_val_score, GridSearchCV, PredefinedSplit, RandomizedSearchCV\n",
    "\n",
    "\n",
    "#performance metrices\n",
    "from sklearn.metrics import make_scorer, confusion_matrix, classification_report, f1_score, balanced_accuracy_score, r2_score, auc, average_precision_score, roc_auc_score, recall_score, roc_curve, accuracy_score\n",
    "\n",
    "#Models selection\n",
    "from sklearn.naive_bayes import GaussianNB, ComplementNB\n",
    "from sklearn.linear_model import LogisticRegression, ElasticNet\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import xgboost as xgb\n",
    "# from cuml.svm import SVC #gpu-powered SVM\n",
    "\n",
    "import cupy as cp\n",
    "\n",
    "#save and load trained model\n",
    "import pickle\n",
    "\n",
    "#visualisation\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "import os\n",
    "\n",
    "random_state = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11624789",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Data loader\n",
    "# features = pd.read_csv(\"../FinalData/cleaned_features_11072023.csv\")\n",
    "gridSearchData, crossValData, internalEvaluationData, externalEvaluationData = pickle.load(open('../Clean_data/dataset_scaled_2vs1_25102024.sav', 'rb'))\n",
    "outcomes = pd.read_csv(\"../Clean_data/cleaned_outcomes_24102024.csv\")\n",
    "# features = features[features.columns[1:]]\n",
    "# outcomes = outcomes[outcomes.columns[1:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fde6c41b-3d33-429b-b5ec-215572100d36",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check vars\n",
    "gridSearchData.iloc[:,60:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3d4d97c-6eff-4df9-b769-8fcde18f5fcf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(gridSearchData.shape)\n",
    "print(outcomes.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e7a7bee-e74a-4c9f-87ff-0b557c67c82c",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "pd.options.display.max_rows = 287\n",
    "gridSearchData.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f81e0adc-7a4b-4e28-852c-811c20125656",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Define feature candidates\n",
    "\n",
    "features_columns = gridSearchData.columns.to_list()\n",
    "exclude_columns = ['patid', 'practice_id', 'set', #identifier\n",
    "                   'BMI', #use the categorical instead\n",
    "                   'ethnicity', #use ethnic_group instead\n",
    "                   'Spacer',  #all zero\n",
    "                   \n",
    "                   'outcome_3months', 'outcome_6months', 'outcome_9months', 'outcome_12months', 'outcome_15months', 'outcome_18months', \n",
    "                   'outcome_21months', 'outcome_24months', 'outcome_combined_6months', 'outcome_combined_9months', 'outcome_combined_12months', \n",
    "                   'outcome_combined_15months', 'outcome_combined_18months', 'outcome_combined_24months', '3months', '6months', '12months', '24months', #outcomes variable\n",
    "                   \n",
    "                   'postcode_district', 'County', 'LocalAuthority', 'OutputAreaClassification', #location related variables, use IMD decile only\n",
    "                   \n",
    "                   'age_cat', 'ICS_medication_possesion_ratio_cat', 'numOCS_cat', 'numOCSEvents_cat', 'numOCSwithLRTI_cat', 'numAcuteRespEvents_cat', \n",
    "                   'numAntibioticsEvents_cat', 'numAntibioticswithLRTI_cat', 'numAsthmaAttacks_cat', 'numHospEvents_cat', 'numPCS_cat', 'numPCSAsthma_cat', \n",
    "                   'numAsthmaManagement_cat', 'numAsthmaReview_cat', 'numAsthmaMedReview_cat', 'numAsthmaReviewRCP_cat', 'average_daily_dose_ICS_cat', \n",
    "                   'prescribed_daily_dose_ICS_cat', #use continous vars instead\n",
    "                   \n",
    "                   'count_rhinitis', 'count_cardiovascular', 'count_heartfailure',\n",
    "                   'count_psoriasis', 'count_anaphylaxis', 'count_diabetes', 'count_ihd',\n",
    "                   'count_anxiety', 'count_eczema', 'count_nasalpolyps',\n",
    "                   'count_paracetamol', 'count_nsaids', 'count_betablocker', #use binary ones\n",
    "                   \n",
    "                   'paracetamol', 'nsaids', 'betablocker', #no data in evaluation\n",
    "                                      \n",
    "                  ]\n",
    "# exclude_columns = exclude_columns + [x for x in features_columns if '_count' in x] #filter out commorbid count variables\n",
    "features_columns = [x for x in features_columns if x not in exclude_columns]\n",
    "print('Features size: ', len(features_columns))\n",
    "print(features_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aeea54f-2a65-4a99-9ac4-d1325d0ae597",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# GRID SEARCH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e874cb2c-243a-4afc-b022-6344986679d5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def print_dataframe(filtered_cv_results):\n",
    "    \"\"\"Pretty print for filtered dataframe\"\"\"\n",
    "    for mean_sensitivity, std_sensitivity, mean_specificity, std_specificity, mean_auc, std_auc, params in zip(\n",
    "        filtered_cv_results[\"mean_test_sensitivity\"],\n",
    "        filtered_cv_results[\"std_test_sensitivity\"],\n",
    "        filtered_cv_results[\"mean_test_specificity\"],\n",
    "        filtered_cv_results[\"std_test_specificity\"],\n",
    "        filtered_cv_results[\"mean_test_auc\"],\n",
    "        filtered_cv_results[\"std_test_auc\"],\n",
    "        filtered_cv_results[\"params\"],\n",
    "    ):\n",
    "        print(\n",
    "            f\"sensitivity: {mean_sensitivity:0.4f} (±{std_sensitivity:0.03f}),\"\n",
    "            f\" specificity: {mean_specificity:0.4f} (±{std_specificity:0.03f}),\"\n",
    "            f\"auc: {mean_auc:0.4f} (±{std_auc:0.03f}),\"\n",
    "            f\" for {params}\"\n",
    "        )\n",
    "    print()\n",
    "\n",
    "\n",
    "def refit_strategy(cv_results):\n",
    "    \"\"\"Define the strategy to select the best estimator.\n",
    "\n",
    "    The strategy defined here is to filter-out all results below a precision threshold\n",
    "    of 0.98, rank the remaining by recall and keep all models with one standard\n",
    "    deviation of the best by recall. Once these models are selected, we can select the\n",
    "    fastest model to predict.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    cv_results : dict of numpy (masked) ndarrays\n",
    "        CV results as returned by the `GridSearchCV`.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    best_index : int\n",
    "        The index of the best estimator as it appears in `cv_results`.\n",
    "    \"\"\"\n",
    "    # print the info about the grid-search for the different scores\n",
    "    sensitivity_threshold = 0.5\n",
    "\n",
    "    cv_results_ = pd.DataFrame(cv_results)\n",
    "    print(\"All grid-search results:\")\n",
    "    print_dataframe(cv_results_)\n",
    "\n",
    "    # Filter-out all results below the threshold\n",
    "    high_sensitivity_cv_results = cv_results_[\n",
    "        cv_results_[\"mean_test_sensitivity\"] > sensitivity_threshold\n",
    "    ]\n",
    "\n",
    "    print(f\"Models with a sensitivity higher than {sensitivity_threshold}:\")\n",
    "    print_dataframe(high_sensitivity_cv_results)\n",
    "\n",
    "    high_sensitivity_cv_results = high_sensitivity_cv_results[\n",
    "        [\n",
    "            \"mean_score_time\",\n",
    "            \"mean_test_sensitivity\",\n",
    "            \"std_test_sensitivity\",\n",
    "            \"mean_test_specificity\",\n",
    "            \"std_test_specificity\",\n",
    "            \"mean_test_auc\",\n",
    "            \"std_test_auc\",\n",
    "            \"rank_test_sensitivity\",\n",
    "            \"rank_test_specificity\",\n",
    "            \"rank_test_auc\",\n",
    "            \"params\",\n",
    "        ]\n",
    "    ]\n",
    "\n",
    "    # Select the most performant models in terms of sesntivity\n",
    "    # (within 1 sigma from the best)\n",
    "    best_auc_std = high_sensitivity_cv_results[\"mean_test_auc\"].std()\n",
    "    best_auc = high_sensitivity_cv_results[\"mean_test_auc\"].max()\n",
    "    best_auc_threshold = best_auc - best_auc_std\n",
    "\n",
    "    high_auc_cv_results = high_sensitivity_cv_results[\n",
    "        high_sensitivity_cv_results[\"mean_test_auc\"] > best_auc_threshold\n",
    "    ]\n",
    "    if high_auc_cv_results.shape[0] > 1:\n",
    "        print(\n",
    "            \"Out of the previously selected high sensitivity models, we keep all the\\n\"\n",
    "            \"the models within one standard deviation of the highest auc model:\"\n",
    "        )\n",
    "\n",
    "        print(best_auc_threshold)\n",
    "        print_dataframe(high_auc_cv_results)\n",
    "\n",
    "        # From the best candidates, select the fastest model to predict\n",
    "        fastest_top_auc_high_sensitivity_index = high_auc_cv_results[\n",
    "            \"mean_score_time\"\n",
    "        ].idxmin()\n",
    "\n",
    "        print(\n",
    "            \"\\nThe selected final model is the fastest to predict out of the previously\\n\"\n",
    "            \"selected subset of best models based on precision and recall.\\n\"\n",
    "            \"Its scoring time is:\\n\\n\"\n",
    "            f\"{high_auc_cv_results.loc[fastest_top_auc_high_sensitivity_index]}\"\n",
    "        )\n",
    "\n",
    "        return fastest_top_auc_high_sensitivity_index\n",
    "    elif high_auc_cv_results.shape[0] == 1:\n",
    "        print('no parameter achieve the threshold, so return the default best score')\n",
    "        return cv_results_[\"mean_test_auc\"].idxmax()\n",
    "    else:\n",
    "        print('no parameter achieve the threshold, so return the default best score')\n",
    "        return cv_results_[\"mean_test_auc\"].idxmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97ae5126-3025-46c5-a103-86dcc435625b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# LR = ['solver', 'C', 'max_iter']\n",
    "# Lasso = ['solver', 'C', 'max_iter']\n",
    "# Elastic= ['l1_ratio', 'max_iter']\n",
    "# GNB = ['var_smoothing']\n",
    "# SVM = ['C', 'gamma']\n",
    "# DT = ['criterion', 'splitter', 'max_depth']\n",
    "# RF = ['criterion', 'n_estimators', 'max_depth']\n",
    "# XGB = ['n_estimators', 'learning_rate', 'reg_alpha', 'reg_lambda']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d50f3c58-d643-43dc-ab18-bb3661b03556",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "#Bayesiain continuous search\n",
    "\n",
    "X = trainingData[features_columns]\n",
    "outcomes = [\n",
    "            # 'outcome_3months', \n",
    "            'outcome_combined_6months', \n",
    "            # 'outcome_combined_12months', \n",
    "            # 'outcome_combined_24months',\n",
    "           ] \n",
    "cv = StratifiedKFold(n_splits=3)\n",
    "n_calls = 10\n",
    "n_jobs = 2\n",
    "\n",
    "output = []\n",
    "\n",
    "for target_outcome in outcomes:\n",
    "    print('######################################################################################################')\n",
    "    print(target_outcome)\n",
    "    y = trainingData[target_outcome]\n",
    "    scale_pos_ratio = y.value_counts()[0]/y.value_counts()[1]\n",
    "    \n",
    "#     if target_outcome == 'outcome_combined_24months':   \n",
    "#     ##############################################################################\n",
    "#         print('#LR')\n",
    "#         lr_model = LogisticRegression(class_weight='balanced', random_state=1234)\n",
    "#         lr_params = [Categorical(['liblinear', 'newton-cholesky'], name = 'solver'),\n",
    "#                      Real(0.1, 10, 'log-uniform', name='C'), \n",
    "#                      Integer(50, 200, 'uniform', name='max_iter')]\n",
    "\n",
    "#         @use_named_args(lr_params)\n",
    "#         def lr_objective(**params):\n",
    "#             lr_model.set_params(**params)\n",
    "\n",
    "#             return 1-np.mean(cross_val_score(lr_model, X, y, cv=cv,\n",
    "#                                             scoring=make_scorer(roc_auc_score)))\n",
    "\n",
    "#         res_gp_lr = gp_minimize(lr_objective, lr_params, n_calls=n_calls, random_state=1234, verbose=3, n_jobs=n_jobs)\n",
    "#         output.append([target_outcome, 'lr', 1-res_gp_lr.fun, res_gp_lr.x])\n",
    "\n",
    "#     ########################################################################################\n",
    "\n",
    "#         print('#Lasso')\n",
    "#         lasso_model = LogisticRegression(class_weight='balanced', penalty='l1', random_state=1234) #only the LIBLINEAR and SAGA (added in v0.19) solvers handle the L1 penalty\n",
    "#         lasso_params = [Categorical(['saga', 'liblinear'], name = 'solver'),\n",
    "#                           Real(0.1, 10, 'log-uniform', name='C'),\n",
    "#                           Integer(50, 200, 'uniform', name='max_iter')]\n",
    "\n",
    "#         @use_named_args(lasso_params)\n",
    "#         def lasso_objective(**params):\n",
    "#             lasso_model.set_params(**params)\n",
    "\n",
    "#             return 1-np.mean(cross_val_score(lasso_model, X, y, cv=cv,\n",
    "#                                             scoring=make_scorer(roc_auc_score)))\n",
    "\n",
    "#         res_gp_lasso = gp_minimize(lasso_objective, lasso_params, n_calls=n_calls, random_state=1234, verbose=3, n_jobs=n_jobs)\n",
    "#         output.append([target_outcome, 'lasso', 1-res_gp_lasso.fun, res_gp_lasso.x])\n",
    "\n",
    "#     ########################################################################################\n",
    "\n",
    "#         print('#Elastic')\n",
    "#         elastic_model = LogisticRegression(class_weight='balanced', penalty = 'elasticnet', solver = 'saga', random_state=1234)\n",
    "#         elastic_params = [Real(0.1, 1, 'log-uniform', name='l1_ratio'),\n",
    "#                           Integer(300, 800, 'uniform', name='max_iter')]\n",
    "\n",
    "#         @use_named_args(elastic_params)\n",
    "#         def elastic_objective(**params):\n",
    "#             elastic_model.set_params(**params)\n",
    "\n",
    "#             return 1-np.mean(cross_val_score(elastic_model, X, y, cv=cv,\n",
    "#                                             scoring=make_scorer(roc_auc_score)))\n",
    "\n",
    "#         res_gp_elastic = gp_minimize(elastic_objective, elastic_params, n_calls=n_calls, random_state=1234, verbose=3, n_jobs=n_jobs)\n",
    "#         output.append([target_outcome, 'elastic', 1-res_gp_elastic.fun, res_gp_elastic.x])\n",
    "\n",
    "#     ########################################################################################\n",
    "\n",
    "#         print('#NB')\n",
    "#         gnb_model = GaussianNB()\n",
    "#         gnb_params = [Real(1e-9, 1e-5, 'log-uniform', name='var_smoothing')]\n",
    "\n",
    "#         @use_named_args(gnb_params)\n",
    "#         def gnb_objective(**params):\n",
    "#             gnb_model.set_params(**params)\n",
    "\n",
    "#             return 1-np.mean(cross_val_score(gnb_model, X, y, cv=cv,\n",
    "#                                             scoring = make_scorer(roc_auc_score)))\n",
    "\n",
    "#         res_gp_gnb = gp_minimize(gnb_objective, gnb_params, n_calls=n_calls, random_state=1234, verbose=3, n_jobs=n_jobs)\n",
    "#         output.append([target_outcome, 'gnb', 1-res_gp_gnb.fun, res_gp_gnb.x])\n",
    "\n",
    "    ########################################################################################\n",
    "\n",
    "    print('#SVM')\n",
    "    svc_model = SVC(class_weight='balanced', kernel='rbf', cache_size=1000, random_state=1234)\n",
    "    svm_params = [Real(0.1, 100, \"log-uniform\", name='C'),\n",
    "                     Real(0.1, 100, \"log-uniform\", name='gamma')]\n",
    "\n",
    "    @use_named_args(svm_params)\n",
    "    def svm_objective(**params):\n",
    "        svc_model.set_params(**params)\n",
    "\n",
    "        return 1-np.mean(cross_val_score(svc_model, X, y, cv=cv,\n",
    "                                        scoring=make_scorer(roc_auc_score), verbose=3))\n",
    "\n",
    "    res_gp_svm = gp_minimize(svm_objective, svm_params, n_calls=n_calls, random_state=1234, verbose=3, n_jobs=n_jobs)\n",
    "    output.append([target_outcome, 'svm', 1-res_gp_svm.fun, res_gp_svm.x])\n",
    "\n",
    "    ########################################################################################\n",
    "#         print('#DT')\n",
    "#         dt_model = DecisionTreeClassifier(class_weight='balanced', random_state=1234)\n",
    "#         dt_params = [Categorical([\"gini\", \"entropy\", \"log_loss\"],name='criterion'),\n",
    "#                      Categorical(['best', 'random'],name='splitter'),\n",
    "#                      Integer(3, 10, \"uniform\", name='max_depth'),]\n",
    "\n",
    "#         @use_named_args(dt_params)\n",
    "#         def dt_objective(**params):\n",
    "#             scoring = {\n",
    "#                 'auc': make_scorer(roc_auc_score)\n",
    "#                 }\n",
    "#             dt_model.set_params(**params)\n",
    "\n",
    "#             return 1 - np.mean(cross_val_score(dt_model, X, y, cv=cv,\n",
    "#                                             scoring=make_scorer(roc_auc_score)))\n",
    "#         res_gp_dt = gp_minimize(dt_objective, dt_params, n_calls=n_calls, random_state=1234, verbose=3, n_jobs=n_jobs)\n",
    "#         output.append([target_outcome, 'dt', 1-res_gp_dt.fun, res_gp_dt.x])\n",
    "    \n",
    "# ##########################################################################################\n",
    "\n",
    "#     print('#RF')\n",
    "#     rf_model = RandomForestClassifier(class_weight='balanced', random_state=1234)\n",
    "#     rf_params = [Categorical([\"gini\", \"entropy\", \"log_loss\"],name='criterion'),\n",
    "#                  Integer(100, 500, \"uniform\", name='n_estimators'),\n",
    "#                  Integer(3, 10, \"uniform\", name='max_depth'),]\n",
    "\n",
    "#     @use_named_args(rf_params)\n",
    "#     def rf_objective(**params):\n",
    "#         scoring = {\n",
    "#             'auc': make_scorer(roc_auc_score)\n",
    "#             }\n",
    "#         rf_model.set_params(**params)\n",
    "\n",
    "#         return 1 - np.mean(cross_val_score(rf_model, X, y, cv=cv,\n",
    "#                                         scoring=make_scorer(roc_auc_score)))\n",
    "#     res_gp_rf = gp_minimize(rf_objective, rf_params, n_calls=n_calls, random_state=1234, verbose=3, n_jobs=n_jobs)\n",
    "#     output.append([target_outcome, 'rf', 1-res_gp_rf.fun, res_gp_rf.x])\n",
    "    \n",
    "# ##########################################################################################\n",
    "\n",
    "#     print('#XGB')\n",
    "#     xgb_model = xgb.XGBClassifier(objective ='binary:logistic', tree_method='gpu_hist', gpu_id=0,  verbosity = 0,\n",
    "#                                          importance_type = 'gain', scale_pos_weight = scale_pos_ratio, random_state=1234)\n",
    "#     xgb_params = [Integer(100,500,\"uniform\", name='n_estimators'),\n",
    "#                     Integer(3, 10, \"uniform\", name='max_depth'),\n",
    "#                      Real(1e-5, 1e-1, 'log-uniform', name='learning_rate'),\n",
    "#                      Real(1e-5, 1e-1, 'log-uniform', name='reg_alpha'),\n",
    "#                      Real(1e-5, 1e-1, 'log-uniform', name='reg_lambda'),]\n",
    "#     @use_named_args(xgb_params)\n",
    "#     def xgb_objective(**params):\n",
    "#         xgb_model.set_params(**params)\n",
    "\n",
    "#         return 1 - np.mean(cross_val_score(xgb_model, X, y, cv=cv,\n",
    "#                                         scoring=make_scorer(roc_auc_score)))\n",
    "#     res_gp_xgb = gp_minimize(xgb_objective, xgb_params, n_calls=n_calls, random_state=1234, verbose=3, n_jobs=n_jobs)\n",
    "#     output.append([target_outcome, 'xgb', 1-res_gp_xgb.fun, res_gp_xgb.x])\n",
    "\n",
    "########################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "563ea6bf-db20-454a-92aa-131143d56902",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(output, columns=['outcome', 'model', 'best_score', 'best_param'])\n",
    "# pd.DataFrame(output, columns=['outcome', 'model', 'best_score', 'best_param']).to_csv('../Models/BS_result_svm6.csv', index = False, index_label=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef702703-9180-4539-b7a0-5d88c12ff764",
   "metadata": {},
   "source": [
    "# GRIDSEARCH HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca2a6abc-cb43-466f-8d94-51503a2a522a",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "#GRID SEARCH\n",
    "X = gridSearchData[features_columns]\n",
    "# X = cudf.DataFrame(X)\n",
    "outcomes = ['outcome_12months',\n",
    "            # 'outcome_3months', \n",
    "            # 'outcome_6months', \n",
    "            # 'outcome_9months', \n",
    "           ] \n",
    "model_names = ['LR', 'Lasso', 'ElasticNet',  'DT', 'RF', 'XGB']\n",
    "\n",
    "\n",
    "output = []\n",
    "for outcome in outcomes:\n",
    "    print(outcome)\n",
    "    y = gridSearchData[outcome]\n",
    "    scale_pos_ratio = y.value_counts()[0]/y.value_counts()[1]\n",
    "    \n",
    "    #MODELS\n",
    "    lr_model = LogisticRegression(class_weight='balanced', random_state=random_state)\n",
    "    lasso_model = LogisticRegression(class_weight='balanced', penalty='l1', random_state=random_state) #only the LIBLINEAR and SAGA (added in v0.19) solvers handle the L1 penalty\n",
    "    elastic_model = LogisticRegression(solver='saga', class_weight='balanced', penalty = 'elasticnet', random_state=random_state)\n",
    "    dt_model = DecisionTreeClassifier(class_weight='balanced', random_state=random_state)\n",
    "    rf_model = RandomForestClassifier(class_weight='balanced', random_state=random_state)\n",
    "    xgb_model = xgb.XGBClassifier(objective ='binary:logistic', tree_method = \"hist\", device = \"cuda\", verbosity = 3,\n",
    "                                     importance_type = 'gain', random_state=random_state)\n",
    "\n",
    "    #PARAMS\n",
    "    lr_params = {'solver': ['liblinear', 'newton-cholesky'],\n",
    "                 'C': [0.1, 1.0, 10.0],\n",
    "                 'max_iter': [80, 100, 120]}\n",
    "    \n",
    "    lasso_params = {'solver': ['saga', 'liblinear'],\n",
    "                    'C': [0.1, 1, 10],\n",
    "                    'max_iter': [80, 100, 120]}\n",
    "    \n",
    "    elastic_params = {'l1_ratio': Real(0.1, 1, 'uniform'),\n",
    "                      'max_iter': [80, 100, 120]}\n",
    "    \n",
    "    dt_params = {'criterion':[\"gini\", \"entropy\"],\n",
    "                 'splitter': ['best', 'random'],\n",
    "                'max_depth': Integer(2,100,\"uniform\")}\n",
    "    \n",
    "    rf_params = {'criterion':[\"gini\", \"entropy\"],\n",
    "                 'n_estimators': Integer(100,1000,\"uniform\"),\n",
    "                'max_depth': Integer(2,100,\"uniform\"),\n",
    "                'min_samples_split': Integer(2,10,\"uniform\"),\n",
    "                'min_samples_leaf': Integer(2,100,\"uniform\"),\n",
    "                'max_features': ['sqrt', 'log2'],\n",
    "                'bootstrap': [True, False]}\n",
    "    \n",
    "    xgb_params = {'n_estimators': Integer(100,1000,\"uniform\"),\n",
    "                'max_depth': Integer(2,100,\"uniform\"),\n",
    "                 'learning_rate': Real(1e-3, 3e-1, 'log-uniform'),\n",
    "                 'reg_alpha': Real(0.1, 10, 'log-uniform'),\n",
    "                 'reg_lambda': Real(0.1, 10, 'log-uniform'),\n",
    "                 'subsample': Real(0.5, 1, 'uniform'),\n",
    "                 'colsample_bytree': Real(0.5, 1, 'uniform'),\n",
    "                 'scale_pos_weight': Real(scale_pos_ratio-2, scale_pos_ratio+2, 'uniform')}\n",
    "\n",
    "    #Models and params in DICT\n",
    "    models_to_be_trained = [\n",
    "        # {'model_name': 'LR', 'model': lr_model, 'params': lr_params},\n",
    "        # {'model_name': 'Lasso', 'model': lasso_model, 'params': lasso_params},\n",
    "        # {'model_name': 'ElasticNet', 'model': elastic_model, 'params': elastic_params},\n",
    "        # {'model_name': 'DT', 'model': dt_model, 'params': dt_params},\n",
    "        # {'model_name': 'RF', 'model': rf_model, 'params': rf_params},\n",
    "        {'model_name': 'XGB', 'model': xgb_model, 'params': xgb_params}\n",
    "    ]\n",
    "    \n",
    "    #scoring\n",
    "    # scoring = {\n",
    "    #     'accuracy': make_scorer(balanced_accuracy_score),\n",
    "    #     'sensitivity': make_scorer(recall_score),\n",
    "    #     'specificity': make_scorer(recall_score,pos_label=0),\n",
    "    #     'auc': make_scorer(roc_auc_score)\n",
    "    #     }\n",
    "    scoring = {\n",
    "        'auc': make_scorer(roc_auc_score)\n",
    "        }\n",
    "    \n",
    "    for item in models_to_be_trained:\n",
    "        print(item['model_name'])\n",
    "        gs = BayesSearchCV(item['model'],\n",
    "                          search_spaces=item['params'],\n",
    "                          scoring='roc_auc',\n",
    "                           n_iter = 50,\n",
    "                          cv=2,\n",
    "                          verbose=3, \n",
    "                           n_jobs=4,\n",
    "                           n_points=50,\n",
    "                            random_state = random_state)\n",
    "        # if item['model_name']=='XGB':\n",
    "        #     X_xgb = cp.array(X)\n",
    "        #     y_xgb = cp.array(y)\n",
    "        #     gs.fit(X_xgb.get(), y_xgb.get())\n",
    "        gs.fit(X, y)\n",
    "        output.append([outcome, item['model_name'], gs.best_score_, gs.best_params_])\n",
    "        pickle.dump(gs.cv_results_, open('../MODELS/BS/' + outcome.split('_')[-1] + '_' + item['model_name'] + '.sav', 'wb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d80dfeb3-cf42-43cc-a094-18b001bf7d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(output, columns=['outcome', 'model', 'best_score', 'best_param'])\n",
    "# pd.DataFrame(output, columns=['outcome', 'model', 'best_score', 'best_param']).to_csv('../Models/BS_result_svm6.csv', index = False, index_label=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d26b8e2-bb57-4d8a-acde-f2266a38cf4d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d259cee-3497-42d5-88d9-c84b6fc4b881",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ac885a87-0710-4f5a-887f-2cf79ed61f64",
   "metadata": {},
   "source": [
    "# END"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3a10bc6-0b73-44bf-a5f2-36a04fd807c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb62bac4-e573-41d9-9187-2359cde616b0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "X = trainingData[features_columns]\n",
    "y = trainingData['outcome_combined_12months']\n",
    "X = cudf.DataFrame(X)\n",
    "# y = cudf.DataFrame(y)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ebbba04-4fa9-43bc-9809-c99ccfd09860",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# svc_model = SVC(class_weight='balanced', kernel='poly', random_state=1234)\n",
    "# svm_params={'C': [0.1, 1, 10], 'gamma': [1,10]}\n",
    "# gs = GridSearchCV(svc_model,\n",
    "#                   param_grid=svm_params,\n",
    "#                   scoring=['average_precision', 'balanced_accuracy', 'roc_auc'],\n",
    "#                   refit='roc_auc',\n",
    "#                   cv=3,\n",
    "#                   verbose=3,)\n",
    "# gs.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1f74bb4-1703-4248-a720-f53afa9abea3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "svc_model = SVC(class_weight='balanced', C = 10, gamma= 10, kernel='rbf', cache_size= 2000, random_state=1234, verbose=3)\n",
    "svc_model.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "043c6f4a-3608-49db-910a-cbc1e69dd42f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "preds = svc_model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "129c774a-6fae-4aee-ae77-8487bf003052",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72d88c57-deac-49e6-92f7-5c8a2f39d702",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "classification_report(y, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d25f6bd2-cd5f-4129-924b-ea1e2c36a122",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "output[5][1].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9281058f-00ae-44e3-91d9-bee8c6929490",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "gs.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6f39271-b950-4e9b-8bf2-7c20f796a4e4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "output[5][1]['params'][output[5][1]['rank_test_balanced_accuracy'][0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da95a0c9-99e9-4756-81c2-dd5d84194a21",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "output[5][1]['params'][output[5][1]['rank_test_average_precision'][0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a3cab69-885b-4331-a37d-846a7d9a61a9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(output, columns=['model', 'GS_result']).to_csv('../Models/GS_result.csv', index_label=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79bd1f8c-d809-44ae-aa9c-3777ceac52be",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "542271fb-66ee-42b4-b023-c6c03c898dc6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76a6fd43-a669-46d6-b962-b23ec9b8b2d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fbd1739-4fe0-49b8-b655-26c10bf0a5d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define number of split in k-fold\n",
    "\n",
    "n_splits = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b30f895e-5381-46ba-b938-e4635f2cea72",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create X set for model development\n",
    "\n",
    "target_outcome = 'outcome_3months'\n",
    "X = trainingData[features_columns]\n",
    "y = trainingData[[target_outcome]]\n",
    "print('X shape: ', X.shape)\n",
    "print('y shape: ', y.shape)\n",
    "\n",
    "#model parameters\n",
    "params = {'xgb_lr': 0.6,\n",
    "         'xgb_maxdepth': 7}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bc35cae-8c88-4260-a968-25e098bbeedc",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "#EXECUTE model training\n",
    "\n",
    "kf = StratifiedKFold(n_splits=n_splits, random_state=1234, shuffle=True)\n",
    "kf.get_n_splits(X)\n",
    "models1 = pd.DataFrame(columns=['modelname', 'class_ratio'])\n",
    "summary_result1 = []\n",
    "cols = ['model_name', 'class_ratio', 'acc','spec','sens','auc', 'auprc', 'balance_accuracy', 'f1_score', 'ppv', 'npv']\n",
    "split_counter = 0\n",
    "\n",
    "#train model\n",
    "for train_index, test_index in kf.split(X, y):\n",
    "    #split data\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "    #Build models -> it can be commented if the models have been trained\n",
    "    models_temp = pd.DataFrame(build_models(X_train, y_train[target_outcome], params, split_counter), columns=['modelname', 'class_ratio'])\n",
    "    models1 = pd.concat([models1,models_temp]).reset_index(drop=True)\n",
    "    split_counter+=1\n",
    "        \n",
    "#evaluate model\n",
    "for modelname, classratio in models1.values:\n",
    "    # print('======================================================================')\n",
    "    print(modelname)\n",
    "    model = pickle.load(open('./models/'+ target_outcome + '/'+ modelname + '.sav', 'rb'))\n",
    "    summary_result1.append((str(model), classratio, ) + summariseResult (X_test, y_test[target_outcome], model) )       \n",
    "\n",
    "\n",
    "summary_result1 = pd.DataFrame(summary_result1, columns=cols)\n",
    "summary_result1['model_num'] = summary_result1.index\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "552fe2d3-7c89-47cd-ae82-c10fb64cd3a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(target_outcome)\n",
    "summary_result1['model_name'] = summary_result1.apply(lambda x: modelNameFixer(x.model_name), axis=1)\n",
    "summary_result1.groupby('model_name').mean().sort_values(['auc'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b731a567-350a-409e-8bfd-dea303c9f7dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_result1.to_csv(\"summaryResult_outcome1.csv\")\n",
    "summary_result1 = pd.read_csv(\"summaryResult_outcome1.csv\")\n",
    "\n",
    "bar = sns.catplot(x = \"model_name\",       # x variable name\n",
    "            y = \"auc\",       # y variable name            \n",
    "            data = summary_result1,     # dataframe to plot\n",
    "            kind = \"bar\",\n",
    "            height=5,\n",
    "            aspect=5/2.5,\n",
    "            ci = None)\n",
    "ax = bar.facet_axis(0,0)\n",
    "for p in ax.patches:\n",
    "    ax.text(p.get_x() + 0.01, \n",
    "            p.get_height() * 1.01, \n",
    "            '{0:.4f}'.format(p.get_height()), \n",
    "            color='black', rotation='horizontal', fontsize=11)\n",
    "    \n",
    "# listOf_Yticks = np.arange(0.5, 0.7, 0.05)\n",
    "ax.set_ylim(0.4, 1)\n",
    "ax.set_ylabel('AUC Score', fontsize=11)\n",
    "ax.set_xlabel('Method', fontsize=11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3831d05a-49bd-41a9-8294-8ddeae8bc2ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# kf = StratifiedKFold(n_splits=2, random_state=1234, shuffle=True)\n",
    "# kf.get_n_splits(X)\n",
    "# for train_index, test_index in kf.split(X, y):\n",
    "#     #split data\n",
    "#     X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "#     y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "#     trymodel = SVC(class_weight='balanced', C = 0.7, degree=2, kernel='poly', random_state=1234, cache_size=2048)\n",
    "#     trymodel.fit(X_train,y_train)\n",
    "#     print(summariseResult(X_test, y_test, trymodel))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baaabe03-0654-40e4-846c-26c3b1ebb50d",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model1 = pickle.load(open('./models/outcome_3months/0DTModel.sav', 'rb'))\n",
    "\n",
    "# pd.DataFrame([best_model3.feature_importances_], columns=X.columns).T.sort_values(0, ascending=False)\n",
    "sorted_idx = best_model1.feature_importances_.argsort()\n",
    "plt.figure(figsize=(5,7))\n",
    "plt.barh(X.columns[sorted_idx][-10:], best_model1.feature_importances_[sorted_idx][-10:])\n",
    "plt.xlabel(\"Decision Tree Feature Importance\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "585071b8-244d-4f64-bd03-6cfcb038b749",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model1 = pickle.load(open('./models/outcome_3months/0RFModel.sav', 'rb'))\n",
    "\n",
    "# pd.DataFrame([best_model3.feature_importances_], columns=X.columns).T.sort_values(0, ascending=False)\n",
    "sorted_idx = best_model1.feature_importances_.argsort()\n",
    "plt.figure(figsize=(5,7))\n",
    "plt.barh(X.columns[sorted_idx][-10:], best_model1.feature_importances_[sorted_idx][-10:])\n",
    "plt.xlabel(\"Random Forest Feature Importance\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e292a9c-e922-4f1d-8655-ff243fb4f1e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model1 = pickle.load(open('./models/outcome_3months/0XGBoostModel.sav', 'rb'))\n",
    "\n",
    "# pd.DataFrame([best_model3.feature_importances_], columns=X.columns).T.sort_values(0, ascending=False)\n",
    "sorted_idx = best_model1.feature_importances_.argsort()\n",
    "plt.figure(figsize=(5,7))\n",
    "plt.barh(X.columns[sorted_idx][-10:], best_model1.feature_importances_[sorted_idx][-10:])\n",
    "plt.xlabel(\"XGBoost Feature Importance\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76596db2-c810-4c3a-b724-e59b6f9cd19a",
   "metadata": {},
   "source": [
    "# 6months"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ae588b5-980f-4712-bfef-e84dfcb1c902",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_outcome = 'outcome_combined_6months'\n",
    "y = trainingData[[target_outcome]]\n",
    "\n",
    "#model parameters\n",
    "params = {'xgb_lr': 0.6,\n",
    "         'xgb_maxdepth': 7}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70c88a10-ffac-4051-82e6-0866d4c3b28b",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "#EXECUTE model training\n",
    "\n",
    "kf = StratifiedKFold(n_splits=n_splits, random_state=1234, shuffle=True)\n",
    "kf.get_n_splits(X)\n",
    "models2 = pd.DataFrame(columns=['modelname', 'class_ratio'])\n",
    "summary_result2 = []\n",
    "cols = ['model_name', 'class_ratio', 'acc','spec','sens','auc', 'auprc', 'balance_accuracy', 'f1_score', 'ppv', 'npv']\n",
    "split_counter = 0\n",
    "\n",
    "#train model\n",
    "for train_index, test_index in kf.split(X, y):\n",
    "    #split data\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "    #Build models -> it can be commented if the models have been trained\n",
    "    models_temp = pd.DataFrame(build_models(X_train, y_train[target_outcome], params, split_counter), columns=['modelname', 'class_ratio'])\n",
    "    models2 = pd.concat([models2,models_temp]).reset_index(drop=True)\n",
    "    split_counter+=1\n",
    "        \n",
    "#evaluate model\n",
    "for modelname, classratio in models2.values:\n",
    "    # print('======================================================================')\n",
    "    print(modelname)\n",
    "    model = pickle.load(open('./models/'+ target_outcome + '/'+ modelname + '.sav', 'rb'))\n",
    "    summary_result2.append((str(model), classratio, ) + summariseResult (X_test, y_test[target_outcome], model) )       \n",
    "\n",
    "\n",
    "summary_result2 = pd.DataFrame(summary_result2, columns=cols)\n",
    "summary_result2['model_num'] = summary_result2.index\n",
    "# summary_result1['method_name'] = summary_result1.apply(lambda x: 'LR' if x.model_num%2 == 0 else 'XGBoost', axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d11f1f49-3ade-41c8-82d1-8d346211c299",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(target_outcome)\n",
    "summary_result2['model_name'] = summary_result2.apply(lambda x: modelNameFixer(x.model_name), axis=1)\n",
    "summary_result2.groupby('model_name').mean().sort_values(['auc'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8506386d-27a9-49fa-856b-a5683e7144e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_result2.to_csv(\"summaryResult_outcome2.csv\")\n",
    "summary_result2 = pd.read_csv(\"summaryResult_outcome2.csv\")\n",
    "\n",
    "bar = sns.catplot(x = \"model_name\",       # x variable name\n",
    "            y = \"auc\",       # y variable name            \n",
    "            data = summary_result2,     # dataframe to plot\n",
    "            kind = \"bar\",\n",
    "            height=5,\n",
    "            aspect=5/2.5,\n",
    "            ci = None)\n",
    "ax = bar.facet_axis(0,0)\n",
    "for p in ax.patches:\n",
    "    ax.text(p.get_x() + 0.01, \n",
    "            p.get_height() * 1.01, \n",
    "            '{0:.4f}'.format(p.get_height()), \n",
    "            color='black', rotation='horizontal', fontsize=11)\n",
    "    \n",
    "# listOf_Yticks = np.arange(0.5, 0.7, 0.05)\n",
    "ax.set_ylim(0.4, 1)\n",
    "ax.set_ylabel('AUC Score', fontsize=11)\n",
    "ax.set_xlabel('Method', fontsize=11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10426f78-d63b-4430-aa28-9781fe41a744",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model2 = pickle.load(open('./models/outcome_combined_6months/0DTModel.sav', 'rb'))\n",
    "\n",
    "# pd.DataFrame([best_model3.feature_importances_], columns=X.columns).T.sort_values(0, ascending=False)\n",
    "sorted_idx = best_model2.feature_importances_.argsort()\n",
    "plt.figure(figsize=(5,7))\n",
    "plt.barh(X.columns[sorted_idx][-10:], best_model2.feature_importances_[sorted_idx][-10:])\n",
    "plt.xlabel(\"Decision Tree Feature Importance\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3090a2a-1dcd-4723-8538-acc2ecafd220",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model2 = pickle.load(open('./models/outcome_combined_6months/0RFModel.sav', 'rb'))\n",
    "\n",
    "# pd.DataFrame([best_model3.feature_importances_], columns=X.columns).T.sort_values(0, ascending=False)\n",
    "sorted_idx = best_model2.feature_importances_.argsort()\n",
    "plt.figure(figsize=(5,7))\n",
    "plt.barh(X.columns[sorted_idx][-10:], best_model2.feature_importances_[sorted_idx][-10:])\n",
    "plt.xlabel(\"Random Forest Feature Importance\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4ca7472-0652-49bd-aef2-81ca61469336",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model2 = pickle.load(open('./models/outcome_combined_6months/0XGBoostModel.sav', 'rb'))\n",
    "\n",
    "# pd.DataFrame([best_model3.feature_importances_], columns=X.columns).T.sort_values(0, ascending=False)\n",
    "sorted_idx = best_model2.feature_importances_.argsort()\n",
    "plt.figure(figsize=(5,7))\n",
    "plt.barh(X.columns[sorted_idx][-10:], best_model2.feature_importances_[sorted_idx][-10:])\n",
    "plt.xlabel(\"XGBoost Feature Importance\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c9953e6-6fc4-481c-a5dc-5be9e2d97063",
   "metadata": {},
   "source": [
    "# 12 months"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfe3cacf-85d8-4889-b3f7-b0653c74d935",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_outcome = 'outcome_combined_12months'\n",
    "y = trainingData[[target_outcome]]\n",
    "\n",
    "#model parameters\n",
    "params = {'xgb_lr': 0.6,\n",
    "         'xgb_maxdepth': 10}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b801fbf-b23b-4c62-8e31-083cd3b5635f",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "#EXECUTE model training\n",
    "\n",
    "kf = StratifiedKFold(n_splits=n_splits, random_state=1234, shuffle=True)\n",
    "kf.get_n_splits(X)\n",
    "models3 = pd.DataFrame(columns=['modelname', 'class_ratio'])\n",
    "summary_result3 = []\n",
    "cols = ['model_name', 'class_ratio', 'acc','spec','sens','auc', 'auprc', 'balance_accuracy', 'f1_score', 'ppv', 'npv']\n",
    "split_counter = 0\n",
    "\n",
    "#train model\n",
    "for train_index, test_index in kf.split(X, y):\n",
    "    #split data\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "    #Build models -> it can be commented if the models have been trained\n",
    "    models_temp = pd.DataFrame(build_models(X_train, y_train[target_outcome], params, split_counter), columns=['modelname', 'class_ratio'])\n",
    "    models3 = pd.concat([models3,models_temp]).reset_index(drop=True)\n",
    "    split_counter+=1\n",
    "        \n",
    "#evaluate model\n",
    "for modelname, classratio in models3.values:\n",
    "    # print('======================================================================')\n",
    "    print(modelname)\n",
    "    model = pickle.load(open('./models/'+ target_outcome + '/'+ modelname + '.sav', 'rb'))\n",
    "    summary_result3.append((str(model), classratio, ) + summariseResult (X_test, y_test[target_outcome], model) )       \n",
    "\n",
    "\n",
    "summary_result3 = pd.DataFrame(summary_result3, columns=cols)\n",
    "summary_result3['model_num'] = summary_result3.index\n",
    "# summary_result1['method_name'] = summary_result1.apply(lambda x: 'LR' if x.model_num%2 == 0 else 'XGBoost', axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e27d5bb5-e42f-4ad0-9c59-af9b9f5645cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(target_outcome)\n",
    "summary_result3['model_name'] = summary_result3.apply(lambda x: modelNameFixer(x.model_name), axis=1)\n",
    "summary_result3.groupby('model_name').mean().sort_values(['auc'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6365bfd3-728e-4071-9abd-d8b87135d795",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_result3.to_csv(\"summaryResult_outcome3.csv\")\n",
    "summary_result3 = pd.read_csv(\"summaryResult_outcome3.csv\")\n",
    "\n",
    "bar = sns.catplot(x = \"model_name\",       # x variable name\n",
    "            y = \"auc\",       # y variable name            \n",
    "            data = summary_result3,     # dataframe to plot\n",
    "            kind = \"bar\",\n",
    "            height=5,\n",
    "            aspect=5/2.5,\n",
    "            ci = None)\n",
    "ax = bar.facet_axis(0,0)\n",
    "for p in ax.patches:\n",
    "    ax.text(p.get_x() + 0.01, \n",
    "            p.get_height() * 1.01, \n",
    "            '{0:.4f}'.format(p.get_height()), \n",
    "            color='black', rotation='horizontal', fontsize=11)\n",
    "    \n",
    "# listOf_Yticks = np.arange(0.5, 0.7, 0.05)\n",
    "ax.set_ylim(0.4, 1)\n",
    "ax.set_ylabel('AUC Score', fontsize=11)\n",
    "ax.set_xlabel('Method', fontsize=11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "722308db-b7ef-479b-b5fd-4f57a8ff1fa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model3 = pickle.load(open('./models/outcome_combined_12months/0DTModel.sav', 'rb'))\n",
    "\n",
    "# pd.DataFrame([best_model3.feature_importances_], columns=X.columns).T.sort_values(0, ascending=False)\n",
    "sorted_idx = best_model3.feature_importances_.argsort()\n",
    "plt.figure(figsize=(5,7))\n",
    "plt.barh(X.columns[sorted_idx][-10:], best_model3.feature_importances_[sorted_idx][-10:])\n",
    "plt.xlabel(\"Decision Tree Feature Importance\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d90e68e-3bb4-4768-9026-eaa1af12ef41",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "best_model3 = pickle.load(open('./models/outcome_combined_12months/0RFModel.sav', 'rb'))\n",
    "\n",
    "# pd.DataFrame([best_model3.feature_importances_], columns=X.columns).T.sort_values(0, ascending=False)\n",
    "sorted_idx = best_model3.feature_importances_.argsort()\n",
    "plt.figure(figsize=(5,7))\n",
    "plt.barh(X.columns[sorted_idx][-10:], best_model3.feature_importances_[sorted_idx][-10:])\n",
    "plt.xlabel(\"Random Forest Feature Importance\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63e290ea-fbf1-42bd-b7db-4712fdf65e11",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "best_model3 = pickle.load(open('./models/outcome_combined_12months/0XGBoostModel.sav', 'rb'))\n",
    "\n",
    "# pd.DataFrame([best_model3.feature_importances_], columns=X.columns).T.sort_values(0, ascending=False)\n",
    "sorted_idx = best_model3.feature_importances_.argsort()\n",
    "plt.figure(figsize=(5,7))\n",
    "plt.barh(X.columns[sorted_idx][-10:], best_model3.feature_importances_[sorted_idx][-10:])\n",
    "plt.xlabel(\"XGBoost Feature Importance\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
