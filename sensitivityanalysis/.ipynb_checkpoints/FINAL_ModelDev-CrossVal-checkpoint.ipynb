{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3cf617ae-7cd6-4168-9b2a-c61a35fcaf7c",
   "metadata": {
    "tags": []
   },
   "source": [
    "# ANALYSIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6f7287c-5c7e-4d25-9085-f3971b3d5784",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#uncomment this below code to install imblearn package\n",
    "# !pip install imbalanced-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c95c2128",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import pyreadr\n",
    "\n",
    "#statistics\n",
    "from scipy.stats import chi2_contingency, ttest_ind\n",
    "\n",
    "# import cudf #gpu-powered DataFrame (Pandas alternative)\n",
    "\n",
    "#imbalance handling\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler, RepeatedEditedNearestNeighbours\n",
    "from imblearn.pipeline import Pipeline\n",
    "\n",
    "#preprocessing\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import OrdinalEncoder, OneHotEncoder, LabelEncoder, MinMaxScaler, StandardScaler\n",
    "\n",
    "\n",
    "#internal validation\n",
    "from sklearn.model_selection import StratifiedKFold, KFold, RepeatedStratifiedKFold, cross_val_score, GridSearchCV, PredefinedSplit, train_test_split\n",
    "\n",
    "#performance metrices\n",
    "from sklearn.metrics import make_scorer, confusion_matrix, classification_report, f1_score, balanced_accuracy_score, matthews_corrcoef, auc, average_precision_score, roc_auc_score, balanced_accuracy_score, roc_curve, accuracy_score\n",
    "\n",
    "#Models selection\n",
    "from sklearn.naive_bayes import GaussianNB, ComplementNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import xgboost as xgb\n",
    "# from cuml.svm import SVC #gpu-powered SVM\n",
    "\n",
    "#Tree pruning\n",
    "from sklearn.tree._tree import TREE_LEAF\n",
    "\n",
    "\n",
    "#save and load trained model\n",
    "import pickle\n",
    "\n",
    "#visualisation\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn import tree\n",
    "\n",
    "from collections import Counter\n",
    "import os\n",
    "# import torch\n",
    "\n",
    "random_state = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fd2fa869-bb96-4ebc-9d51-2b542e9486e1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Data loader\n",
    "# features = pd.read_csv(\"../FinalData/cleaned_features_11072023.csv\")\n",
    "gridSearchData, crossValData, internalEvaluationData, externalEvaluationData = pickle.load(open('../Clean_data/dataset_scaled_2vs1_25102024.sav', 'rb'))\n",
    "outcomes = pd.read_csv(\"../Clean_data/cleaned_outcomes_24102024.csv\")\n",
    "# features = features[features.columns[1:]]\n",
    "# outcomes = outcomes[outcomes.columns[1:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "79ec3857-4665-4107-8364-c1f5d39f363f",
   "metadata": {},
   "outputs": [],
   "source": [
    "gridSearch_X, _, _, _, gridSearch_tab, _, _, _, gridSearch_y, _, _, _ = pickle.load(open('../Clean_data/seasonal_dataset_full_05112024.sav', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1cfe0d32-39ff-41ba-86f0-cfbbfcb1a48b",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique, counts = np.unique(gridSearch_y, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c3d744aa-40e1-45f3-b171-d07137a03c9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1317823495481638"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts[1]/counts[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "25f7e171-4ac8-4a82-9aac-5c9e2128484c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features size:  87\n",
      "['sex', 'rhinitis', 'cardiovascular', 'heartfailure', 'psoriasis', 'anaphylaxis', 'diabetes', 'ihd', 'anxiety', 'eczema', 'nasalpolyps', 'asthmaPlan', 'BMI_cat_normal', 'BMI_cat_not recorded', 'BMI_cat_obese', 'BMI_cat_overweight', 'BMI_cat_underweight', 'ethnic_group_Asian', 'ethnic_group_Black', 'ethnic_group_Mixed', 'ethnic_group_Other', 'ethnic_group_White', 'ethnic_group_not recorded', 'smokingStatus_current', 'smokingStatus_former', 'smokingStatus_never', 'imd_decile_0', 'imd_decile_1', 'imd_decile_2', 'imd_decile_3', 'imd_decile_4', 'imd_decile_5', 'imd_decile_6', 'imd_decile_7', 'imd_decile_8', 'imd_decile_9', 'imd_decile_10', 'CharlsonScore_0.0', 'CharlsonScore_1.0', 'CharlsonScore_2.0', 'CharlsonScore_3.0', 'CharlsonScore_4.0', 'CharlsonScore_5.0', 'CharlsonScore_6.0', 'CharlsonScore_7.0', 'CharlsonScore_8.0', 'CharlsonScore_9.0', 'CharlsonScore_10.0', 'CharlsonScore_11.0', 'CharlsonScore_12.0', 'PEFStatus_60-80', 'PEFStatus_less than 60', 'PEFStatus_more than 80', 'PEFStatus_not recorded', 'EosinophilLevel_high', 'EosinophilLevel_normal', 'EosinophilLevel_not recorded', 'BTS_step_0', 'BTS_step_1', 'BTS_step_2', 'BTS_step_3', 'BTS_step_4', 'BTS_step_5', 'DeviceType_BAI', 'DeviceType_DPI', 'DeviceType_NEB', 'DeviceType_not recorded', 'DeviceType_pMDI', 'PriorEducation_No', 'PriorEducation_Yes', 'age', 'average_daily_dose_ICS', 'prescribed_daily_dose_ICS', 'ICS_medication_possesion_ratio', 'numPCS', 'numPCSAsthma', 'numAntibioticsEvents', 'numAntibioticswithLRTI', 'numOCSEvents', 'numOCSwithLRTI', 'numAsthmaAttacks', 'numAcuteRespEvents', 'numHospEvents', 'numAsthmaManagement', 'numAsthmaReview', 'numAsthmaMedReview', 'numAsthmaReviewRCP']\n"
     ]
    }
   ],
   "source": [
    "#Define feature candidates\n",
    "\n",
    "features_columns = gridSearchData.columns.to_list()\n",
    "exclude_columns = ['patid', 'practice_id', 'set', #identifier\n",
    "                   'BMI', #use the categorical instead\n",
    "                   'ethnicity', #use ethnic_group instead\n",
    "                   'Spacer',  #all zero\n",
    "                   \n",
    "                   'outcome_3months', 'outcome_6months', 'outcome_9months', 'outcome_12months', 'outcome_15months', 'outcome_18months', \n",
    "                   'outcome_21months', 'outcome_24months', 'outcome_combined_6months', 'outcome_combined_9months', 'outcome_combined_12months', \n",
    "                   'outcome_combined_15months', 'outcome_combined_18months', 'outcome_combined_24months', '3months', '6months', '12months', '24months', #outcomes variable\n",
    "                   \n",
    "                   'postcode_district', 'County', 'LocalAuthority', 'OutputAreaClassification', #location related variables, use IMD decile only\n",
    "                   \n",
    "                   'age_cat', 'ICS_medication_possesion_ratio_cat', 'numOCS_cat', 'numOCSEvents_cat', 'numOCSwithLRTI_cat', 'numAcuteRespEvents_cat', \n",
    "                   'numAntibioticsEvents_cat', 'numAntibioticswithLRTI_cat', 'numAsthmaAttacks_cat', 'numHospEvents_cat', 'numPCS_cat', 'numPCSAsthma_cat', \n",
    "                   'numAsthmaManagement_cat', 'numAsthmaReview_cat', 'numAsthmaMedReview_cat', 'numAsthmaReviewRCP_cat', 'average_daily_dose_ICS_cat', \n",
    "                   'prescribed_daily_dose_ICS_cat', #use continous vars instead\n",
    "                   \n",
    "                   'count_rhinitis', 'count_cardiovascular', 'count_heartfailure',\n",
    "                   'count_psoriasis', 'count_anaphylaxis', 'count_diabetes', 'count_ihd',\n",
    "                   'count_anxiety', 'count_eczema', 'count_nasalpolyps',\n",
    "                   'count_paracetamol', 'count_nsaids', 'count_betablocker', #use binary ones\n",
    "                   \n",
    "                   'paracetamol', 'nsaids', 'betablocker', #no data in evaluation\n",
    "                                      \n",
    "                  ]\n",
    "# exclude_columns = exclude_columns + [x for x in features_columns if '_count' in x] #filter out commorbid count variables\n",
    "features_columns = [x for x in features_columns if x not in exclude_columns]\n",
    "print('Features size: ', len(features_columns))\n",
    "print(features_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b9471fc0-4184-4109-a778-27f6b625695f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features size:  87\n",
      "['sex', 'rhinitis', 'cardiovascular', 'heartfailure', 'psoriasis', 'anaphylaxis', 'diabetes', 'ihd', 'anxiety', 'eczema', 'nasalpolyps', 'asthmaPlan', 'BMI_cat_normal', 'BMI_cat_not recorded', 'BMI_cat_obese', 'BMI_cat_overweight', 'BMI_cat_underweight', 'ethnic_group_Asian', 'ethnic_group_Black', 'ethnic_group_Mixed', 'ethnic_group_Other', 'ethnic_group_White', 'ethnic_group_not recorded', 'smokingStatus_current', 'smokingStatus_former', 'smokingStatus_never', 'imd_decile_0', 'imd_decile_1', 'imd_decile_2', 'imd_decile_3', 'imd_decile_4', 'imd_decile_5', 'imd_decile_6', 'imd_decile_7', 'imd_decile_8', 'imd_decile_9', 'imd_decile_10', 'CharlsonScore_0.0', 'CharlsonScore_1.0', 'CharlsonScore_2.0', 'CharlsonScore_3.0', 'CharlsonScore_4.0', 'CharlsonScore_5.0', 'CharlsonScore_6.0', 'CharlsonScore_7.0', 'CharlsonScore_8.0', 'CharlsonScore_9.0', 'CharlsonScore_10.0', 'CharlsonScore_11.0', 'CharlsonScore_12.0', 'PEFStatus_60-80', 'PEFStatus_less than 60', 'PEFStatus_more than 80', 'PEFStatus_not recorded', 'EosinophilLevel_high', 'EosinophilLevel_normal', 'EosinophilLevel_not recorded', 'BTS_step_0', 'BTS_step_1', 'BTS_step_2', 'BTS_step_3', 'BTS_step_4', 'BTS_step_5', 'DeviceType_BAI', 'DeviceType_DPI', 'DeviceType_NEB', 'DeviceType_not recorded', 'DeviceType_pMDI', 'PriorEducation_No', 'PriorEducation_Yes', 'age', 'average_daily_dose_ICS', 'prescribed_daily_dose_ICS', 'ICS_medication_possesion_ratio', 'numPCS', 'numPCSAsthma', 'numAntibioticsEvents', 'numAntibioticswithLRTI', 'numOCSEvents', 'numOCSwithLRTI', 'numAsthmaAttacks', 'numAcuteRespEvents', 'numHospEvents', 'numAsthmaManagement', 'numAsthmaReview', 'numAsthmaMedReview', 'numAsthmaReviewRCP']\n"
     ]
    }
   ],
   "source": [
    "#Define feature candidates for cat models\n",
    "\n",
    "features_columns = gridSearchData.columns.to_list()\n",
    "exclude_columns = ['patid', 'practice_id', 'set', #identifier\n",
    "                   'BMI', #use the categorical instead\n",
    "                   'ethnicity', #use ethnic_group instead\n",
    "                   'Spacer',  #all zero\n",
    "                   \n",
    "                   'outcome_3months', 'outcome_6months', 'outcome_9months', 'outcome_12months', 'outcome_15months', 'outcome_18months', \n",
    "                   'outcome_21months', 'outcome_24months', 'outcome_combined_6months', 'outcome_combined_9months', 'outcome_combined_12months', \n",
    "                   'outcome_combined_15months', 'outcome_combined_18months', 'outcome_combined_24months', '3months', '6months', '12months', '24months', #outcomes variable\n",
    "                   \n",
    "                   'postcode_district', 'County', 'LocalAuthority', 'OutputAreaClassification', #location related variables, use IMD decile only\n",
    "                   \n",
    "                   'age_cat', 'ICS_medication_possesion_ratio_cat', 'numOCS_cat', 'numOCSEvents_cat', 'numOCSwithLRTI_cat', 'numAcuteRespEvents_cat', \n",
    "                   'numAntibioticsEvents_cat', 'numAntibioticswithLRTI_cat', 'numAsthmaAttacks_cat', 'numHospEvents_cat', 'numPCS_cat', 'numPCSAsthma_cat', \n",
    "                   'numAsthmaManagement_cat', 'numAsthmaReview_cat', 'numAsthmaMedReview_cat', 'numAsthmaReviewRCP_cat', 'average_daily_dose_ICS_cat', \n",
    "                   'prescribed_daily_dose_ICS_cat', #use continous vars instead\n",
    "                   \n",
    "                   'count_rhinitis', 'count_cardiovascular', 'count_heartfailure',\n",
    "                   'count_psoriasis', 'count_anaphylaxis', 'count_diabetes', 'count_ihd',\n",
    "                   'count_anxiety', 'count_eczema', 'count_nasalpolyps',\n",
    "                   'count_paracetamol', 'count_nsaids', 'count_betablocker', #use binary ones\n",
    "                   \n",
    "                   'paracetamol', 'nsaids', 'betablocker', #no data in evaluation\n",
    "                                      \n",
    "                  ]\n",
    "# exclude_columns = exclude_columns + [x for x in features_columns if '_count' in x] #filter out commorbid count variables\n",
    "features_columns = [x for x in features_columns if x not in exclude_columns]\n",
    "print('Features size: ', len(features_columns))\n",
    "print(features_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7037f720-0ed4-4e4a-84c8-f511fadac736",
   "metadata": {
    "tags": []
   },
   "source": [
    "# UTILS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a4db59da-1f72-428e-9203-08d62c6d9090",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Model evaluation function\n",
    "\n",
    "def summariseResult (testX, testY, model):\n",
    "    preds = model.predict_proba(testX)\n",
    "    preds = [x[1] for x in preds]\n",
    "    # tn, fp, fn, tp = confusion_matrix(testY, preds).ravel()\n",
    "    # specificity = tn / (tn+fp)\n",
    "    # sensitivity = tp / (tp+fn)\n",
    "    # ppv = 100*tp/(tp+fp)\n",
    "    # npv = 100*tn/(fn+tn)\n",
    "    # acc = accuracy_score(testY, preds)\n",
    "    # f1score = f1_score(testY, preds, average = 'binary')\n",
    "    # balanceacc = balanced_accuracy_score(testY, preds)\n",
    "    fpr, tpr, thresholds = roc_curve(testY, preds, pos_label=1)\n",
    "    # aucscore = auc(fpr, tpr)\n",
    "    aucscore = roc_auc_score(testY, preds)\n",
    "    auprc = average_precision_score(testY, preds)\n",
    "    # plot_confusion_matrix(model, testX, testY, cmap='viridis')  \n",
    "    return np.round(aucscore,4), np.round(auprc,4)\n",
    "    # return np.round(acc,4), np.round(specificity,4), np.round(sensitivity,4), np.round(aucscore,4), np.round(auprc,4), np.round(balanceacc,4), np.round(f1score,4), np.round(ppv,4), np.round(npv,4)\n",
    "\n",
    "#Fix model name for visualisation\n",
    "\n",
    "def modelNameFixer(x):\n",
    "    if 'liblinear' in x:\n",
    "        return 'Lasso'\n",
    "    elif 'GaussianNB' in x:\n",
    "        return 'GNB'\n",
    "    elif 'SVC' in x:\n",
    "        return 'SVC'\n",
    "    elif 'RandomForest' in x:\n",
    "        return 'RF'\n",
    "    elif 'XGB' in x:\n",
    "        return 'XGBoost'\n",
    "    elif 'DecisionTree' in x:\n",
    "        return 'DT'\n",
    "    else:\n",
    "        return 'LR'\n",
    "    \n",
    "    \n",
    "# instantiate the model (using the default parameters)\n",
    "def build_models (X_train, y_train, target_outcome, params_dict, model_folder, fold):\n",
    "    models = [] #list to store all the models\n",
    "    print(\"Building models . . . .\")\n",
    "\n",
    "    #LR\n",
    "    model = 'LR'\n",
    "    params = params_dict[(params_dict['outcome']==target_outcome)&(params_dict['model']==model)]['params'].tolist()[0]\n",
    "    # params = eval(params)\n",
    "    print(params)\n",
    "    lr_model = LogisticRegression(class_weight='balanced', C = params['C'], max_iter=params['max_iter'], solver=params['solver'], random_state=random_state)\n",
    "    lr_model.fit(X_train,y_train)\n",
    "    pickle.dump(lr_model, open(model_folder+ target_outcome + '_'+ model + str(fold) + '.sav', 'wb'))\n",
    "    models.append([model + str(fold), target_outcome, y_train.value_counts()[1]/y_train.value_counts()[0]]) \n",
    "    print(\"LR done\")\n",
    "\n",
    "    #Lasso\n",
    "    model = 'Lasso'\n",
    "    params = params_dict[(params_dict['outcome']==target_outcome)&(params_dict['model']==model)]['params'].tolist()[0]\n",
    "    # params = eval(params)\n",
    "    print(params)\n",
    "    lasso_model = LogisticRegression(class_weight='balanced',  C = params['C'], max_iter=params['max_iter'], penalty='l1', solver=params['solver'], random_state=random_state) #only the LIBLINEAR and SAGA (added in v0.19) solvers handle the L1 penalty\n",
    "    lasso_model.fit(X_train, y_train)\n",
    "    pickle.dump(lasso_model, open(model_folder+ target_outcome + '_'+ model + str(fold) + '.sav', 'wb'))\n",
    "    models.append([model + str(fold), target_outcome, y_train.value_counts()[1]/y_train.value_counts()[0]])\n",
    "    print(\"Lasso done\")\n",
    "    \n",
    "    #Elastics\n",
    "    model = 'ElasticNet'\n",
    "    params = params_dict[(params_dict['outcome']==target_outcome)&(params_dict['model']==model)]['params'].tolist()[0]\n",
    "    # params = eval(params)\n",
    "    print(params)\n",
    "    elastics_model = LogisticRegression(class_weight='balanced', solver='saga', l1_ratio=params['l1_ratio'], max_iter=params['max_iter'],  penalty = 'elasticnet', random_state=random_state)\n",
    "    elastics_model.fit(X_train, y_train)\n",
    "    pickle.dump(elastics_model, open(model_folder+ target_outcome + '_'+ model + str(fold) + '.sav', 'wb'))\n",
    "    models.append([model + str(fold), target_outcome, y_train.value_counts()[1]/y_train.value_counts()[0]])\n",
    "    print(\"Elastics done\")\n",
    "\n",
    "\n",
    "    #DT\n",
    "    model = 'DT'\n",
    "    params = params_dict[(params_dict['outcome']==target_outcome)&(params_dict['model']==model)]['params'].tolist()[0]\n",
    "    # params = eval(params)\n",
    "    print(params)\n",
    "    dt_model = DecisionTreeClassifier(class_weight='balanced', max_depth=params['max_depth'], criterion=params['criterion'], splitter=params['splitter'], random_state=random_state)\n",
    "    dt_model.fit(X_train, y_train)\n",
    "    pickle.dump(dt_model, open(model_folder+ target_outcome + '_'+ model + str(fold) + '.sav', 'wb'))    \n",
    "    models.append([model + str(fold), target_outcome, y_train.value_counts()[1]/y_train.value_counts()[0]])\n",
    "    print(\"DT done\")\n",
    "\n",
    "    #RF\n",
    "    model = 'RF'\n",
    "    params = params_dict[(params_dict['outcome']==target_outcome)&(params_dict['model']==model)]['params'].tolist()[0]\n",
    "    # params = eval(params)\n",
    "    print(params)\n",
    "    rf_model = RandomForestClassifier(class_weight='balanced', max_depth=params['max_depth'], \n",
    "                                      criterion=params['criterion'], n_estimators=params['n_estimators'], \n",
    "                                      min_samples_split=params['min_samples_split'],\n",
    "                                      min_samples_leaf=params['min_samples_leaf'],\n",
    "                                      max_features=params['max_features'],\n",
    "                                      bootstrap=params['bootstrap'], \n",
    "                                      random_state=random_state)\n",
    "    rf_model.fit(X_train, y_train)\n",
    "    pickle.dump(rf_model, open(model_folder+ target_outcome + '_'+ model + str(fold) + '.sav', 'wb'))     \n",
    "    models.append([model + str(fold), target_outcome, y_train.value_counts()[1]/y_train.value_counts()[0]])\n",
    "    print(\"RF done\")\n",
    "\n",
    "    #XGB\n",
    "    model = 'XGB'\n",
    "    params = params_dict[(params_dict['outcome']==target_outcome)&(params_dict['model']==model)]['params'].tolist()[0]\n",
    "    # params = eval(params)\n",
    "    print(params)\n",
    "    scale_pos_ratio = y_train.value_counts()[0]/y_train.value_counts()[1]\n",
    "    xgb_model = xgb.XGBClassifier(objective ='binary:logistic', tree_method = \"hist\", \n",
    "                                  n_estimators=params['n_estimators'],\n",
    "                                  max_depth=params['max_depth'],\n",
    "                                  learning_rate=params['learning_rate'],\n",
    "                                  reg_alpha=params['reg_alpha'],\n",
    "                                  reg_lambda=params['reg_lambda'],\n",
    "                                  subsample=params['subsample'],\n",
    "                                  colsample_bytree=params['colsample_bytree'],\n",
    "                                  scale_pos_weight=params['scale_pos_weight'],\n",
    "                                  device = \"cuda\", \n",
    "                                  verbosity = 3,\n",
    "                                  importance_type = 'gain', random_state=random_state)\n",
    "    # xgb_model = xgb.XGBClassifier(objective ='binary:logistic', learning_rate = 0.001, tree_method='gpu_hist', gpu_id=0,  verbosity = 0, random_state = 1234)\n",
    "    xgb_model.fit(X_train,y_train)\n",
    "    pickle.dump(xgb_model, open(model_folder+ target_outcome + '_'+ model + str(fold) + '.sav', 'wb')) \n",
    "    models.append([model + str(fold),  target_outcome, y_train.value_counts()[1]/y_train.value_counts()[0]])\n",
    "    print(\"XGB done\")\n",
    "    \n",
    "    return models\n",
    "    # return [xgb_model]\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "def is_leaf(inner_tree, index):\n",
    "    # Check whether node is leaf node\n",
    "    return (inner_tree.children_left[index] == TREE_LEAF and \n",
    "            inner_tree.children_right[index] == TREE_LEAF)\n",
    "\n",
    "def prune_index(inner_tree, decisions, index=0):\n",
    "    # Start pruning from the bottom - if we start from the top, we might miss\n",
    "    # nodes that become leaves during pruning.\n",
    "    # Do not use this directly - use prune_duplicate_leaves instead.\n",
    "    if not is_leaf(inner_tree, inner_tree.children_left[index]):\n",
    "        prune_index(inner_tree, decisions, inner_tree.children_left[index])\n",
    "    if not is_leaf(inner_tree, inner_tree.children_right[index]):\n",
    "        prune_index(inner_tree, decisions, inner_tree.children_right[index])\n",
    "\n",
    "    # Prune children if both children are leaves now and make the same decision:     \n",
    "    if (is_leaf(inner_tree, inner_tree.children_left[index]) and\n",
    "        is_leaf(inner_tree, inner_tree.children_right[index]) and\n",
    "        (decisions[index] == decisions[inner_tree.children_left[index]]) and \n",
    "        (decisions[index] == decisions[inner_tree.children_right[index]])):\n",
    "        # turn node into a leaf by \"unlinking\" its children\n",
    "        inner_tree.children_left[index] = TREE_LEAF\n",
    "        inner_tree.children_right[index] = TREE_LEAF\n",
    "        ##print(\"Pruned {}\".format(index))\n",
    "\n",
    "def prune_duplicate_leaves(mdl):\n",
    "    # Remove leaves if both \n",
    "    decisions = mdl.tree_.value.argmax(axis=2).flatten().tolist() # Decision for each node\n",
    "    prune_index(mdl.tree_, decisions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dffb0b7d-703f-43b2-af52-e555a9ef1cb4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(444393, 87)\n",
      "(121714, 87)\n",
      "(19860, 87)\n"
     ]
    }
   ],
   "source": [
    "X = crossValData[features_columns]\n",
    "X_internalVal = internalEvaluationData[features_columns]\n",
    "X_externalVal = externalEvaluationData[features_columns]\n",
    "\n",
    "\n",
    "print(X.shape)\n",
    "print(X_internalVal.shape)\n",
    "print(X_externalVal.shape)\n",
    "\n",
    "\n",
    "target_outcomes = [\n",
    "    'outcome_3months', 'outcome_6months', 'outcome_9months', \n",
    "    'outcome_12months',\n",
    "] \n",
    "# target_outcomes = ['12months'] \n",
    "model_names = [\n",
    "    'LR', 'Lasso', 'ElasticNet', \n",
    "    'DT', 'RF', \n",
    "    'XGB'\n",
    "              ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba329484-ef88-4bba-a169-70f029879bf0",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f225c66-5f1f-4331-a3c1-45e22ab444c8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80821b01-8f91-4da1-ab92-c7fa3891eb3c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#params\n",
    "params_dict = pd.read_csv('../MODELS/BS_result_new.csv')\n",
    "def process_params(param_items, best_param):\n",
    "    a = eval(param_items)\n",
    "    b = eval(best_param)\n",
    "    c = {}\n",
    "    for key, value in zip(a,b):\n",
    "        c[key] = value\n",
    "    return c\n",
    "\n",
    "params_dict['params'] = params_dict.apply(lambda x: dict(eval(x.best_param[11:])), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd97da62-733f-46ac-aeec-b9ced5aafe30",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "params_dict.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7a7b15f-2d6d-4905-93a5-7f0aaaba0844",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "## k-fold\n",
    "\n",
    "#EXECUTE model training\n",
    "summary_result_train = []\n",
    "# summary_result_internalVal = []\n",
    "# summary_result_externalVal = []\n",
    "\n",
    "cols = ['model_name', 'fold', 'outcome', 'class_ratio', 'auc', 'auprc']\n",
    "n_splits = 5\n",
    "model_folder = '../MODELS/CrosVal/'\n",
    "\n",
    "for target_outcome in target_outcomes:\n",
    "    models = pd.DataFrame(columns=['modelname', 'target_outcome', 'class_ratio'])\n",
    "    print(target_outcome)\n",
    "    y = crossValData[target_outcome]\n",
    "    # y_internalVal = internalEvaluationData[target_outcome]\n",
    "    # y_externalVal = externalEvaluationData[target_outcome]\n",
    "    kf = StratifiedKFold(n_splits=n_splits, random_state=random_state, shuffle=True)\n",
    "    kf.get_n_splits(X)\n",
    "    fold = 0\n",
    "    \n",
    "    for train_index, test_index in kf.split(X, y):\n",
    "        #split data\n",
    "        fold+=1\n",
    "        print(f'fold: {fold}')\n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "        #Build models -> it can be commented if the models have been trained\n",
    "        models_temp = pd.DataFrame(build_models(X_train, y_train, target_outcome, params_dict, model_folder, fold), columns=['modelname', 'target_outcome', 'class_ratio'])\n",
    "        models = pd.concat([models,models_temp]).reset_index(drop=True)\n",
    "    \n",
    "    \n",
    "        #evaluate model\n",
    "        for modelname, target_outcome, classratio in models_temp.values:\n",
    "            # print('======================================================================')\n",
    "            print(modelname)\n",
    "            model = pickle.load(open('../Models/CrosVal/'+ target_outcome + '_'+ modelname + '.sav', 'rb'))       \n",
    "            summary_result_train.append((modelname, fold, target_outcome, classratio, ) + summariseResult (X_test, y_test, model) )       \n",
    "            # summary_result_internalVal.append((modelname, fold, target_outcome, classratio, ) + summariseResult (X_internalVal, y_internalVal, model) )       \n",
    "            # summary_result_externalVal.append((modelname, fold, target_outcome, classratio, ) + summariseResult (X_externalVal, y_externalVal, model) )       \n",
    "\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "\n",
    "summary_result_train = pd.DataFrame(summary_result_train, columns=cols)\n",
    "summary_result_train['model_num'] = summary_result_train.index\n",
    "summary_result_train.to_csv('../MODELS/CrossVal.csv', index_label=False, index=False)\n",
    "# summary_result_internalVal = pd.DataFrame(summary_result_internalVal, columns=cols)\n",
    "# summary_result_internalVal['model_num'] = summary_result_internalVal.index\n",
    "\n",
    "# summary_result_externalVal = pd.DataFrame(summary_result_externalVal, columns=cols)\n",
    "# summary_result_externalVal['model_num'] = summary_result_externalVal.index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eddf0d95-01b2-4327-a3bf-db3885fa7439",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6db6d979-0731-4852-8b2c-496f4903aafb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98d96814-cd1a-4ec7-a2df-848726cc4dbd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b06fcb2f-15c8-4599-aede-2ad8cd314579",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b85a01bb-a091-45af-9e89-d22de6d262a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c4f6d5d-551c-471d-a5bb-07d69864d6da",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_result_train['set'] = 'Cross validation (England)'\n",
    "summary_result_internalVal['set'] = 'Internal validation (England)'\n",
    "summary_result_externalVal['set'] = 'External validation (Wales & Scotland)'\n",
    "\n",
    "\n",
    "combine = pd.concat([summary_result_train, summary_result_internalVal, \n",
    "                     summary_result_externalVal,\n",
    "                    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e92f764-2f76-4e85-949e-0d5b160198cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#PLOT\n",
    "data = combine\n",
    "data = combine[(combine.outcome=='outcome_12months')]\n",
    "bar = sns.catplot(x = 'model_name',       # x variable name\n",
    "            y = 'auc',       # y variable name            \n",
    "            data=data,\n",
    "            kind = \"bar\",\n",
    "            hue = 'set',\n",
    "            # hue_order=['10-fold CV', 'Evaluation Set', 'Wales', 'Scotland'],\n",
    "            height=4,\n",
    "            row='outcome',\n",
    "            aspect=3.5,\n",
    "            errorbar = None,)\n",
    "\n",
    "for items in bar.axes:\n",
    "    for ax in items:\n",
    "        for p in ax.patches:\n",
    "            ax.text(p.get_x() + 0.01, \n",
    "                p.get_height() * 1.002, \n",
    "                '{0:.3f}'.format(p.get_height()), \n",
    "                color='black', rotation=20, fontsize=7)\n",
    "\n",
    "ax.set_ylim(0.3, .85)\n",
    "# ax.set_ylabel('AUC Score', fontsize=13)\n",
    "ax.set_xlabel('Method', fontsize=10)\n",
    "# ax.set_xticklabels(fontsize=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5def431-7d36-4f0c-bec9-288e1d8d1d52",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bec1020-664b-4216-8dd3-512e5fe45c12",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf59e91d-85fa-402e-8eb4-99ea9a710f67",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3bf0efd3-b777-4317-9675-6fc47aa44b30",
   "metadata": {},
   "source": [
    "# END of TRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b89dd25-ff3f-4cca-b25d-5befe7853ec5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bf35146-ffe8-41e8-a831-a840906e440c",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "\n",
    "#EXECUTE model training\n",
    "summary_result_internalVal = []\n",
    "summary_result_externalVal = []\n",
    "\n",
    "# cols = ['model_name', 'outcome', 'class_ratio', 'acc','spec','sens','auc', 'auprc', 'balance_accuracy', 'f1_score', 'ppv', 'npv']\n",
    "cols = ['model_name', 'outcome', 'class_ratio', 'auc', 'auprc']\n",
    "model_folder = '../CrosVal/'\n",
    "fold = 0\n",
    "\n",
    "for target_outcome in target_outcomes:\n",
    "    models = pd.DataFrame(columns=['modelname', 'target_outcome', 'class_ratio'])\n",
    "    print(target_outcome)\n",
    "    y = trainingData[target_outcome]\n",
    "    y_val = validationData[target_outcome]\n",
    "    y = pd.concat([y, y_val])\n",
    "    y_internaleval = internalEvaluationData[target_outcome]\n",
    "    y_eval = evaluationData[target_outcome]\n",
    "    y_eval_Wales = evaluationDataWales[target_outcome]\n",
    "    y_eval_Scotland = evaluationDataScotland[target_outcome]\n",
    "    #Build models -> it can be commented if the models have been trained\n",
    "    models_temp = pd.DataFrame(build_models(X, y, target_outcome, params_dict, model_folder, fold), columns=['modelname', 'target_outcome', 'class_ratio'])\n",
    "    models = pd.concat([models,models_temp]).reset_index(drop=True)\n",
    "\n",
    "    #evaluate model\n",
    "    for modelname, target_outcome, classratio in models.values:\n",
    "        # print('======================================================================')\n",
    "        print(modelname)\n",
    "        model = pickle.load(open(model_folder+ target_outcome + '/'+ modelname + '.sav', 'rb'))\n",
    "        summary_result_eval.append((str(modelname), target_outcome, classratio, ) + summariseResult (X_eval, y_eval, model) )\n",
    "        summary_result_Wales.append((str(modelname), target_outcome, classratio, ) + summariseResult (X_eval_Wales, y_eval_Wales, model) )       \n",
    "        summary_result_Scotland.append((str(modelname), target_outcome, classratio, ) + summariseResult (X_eval_Scotland, y_eval_Scotland, model) )       \n",
    "        summary_result_val.append((str(modelname), target_outcome, classratio, ) + summariseResult (X_internaleval, y_internaleval, model) )       \n",
    "\n",
    "\n",
    "summary_result_eval = pd.DataFrame(summary_result_eval, columns=cols)\n",
    "summary_result_eval['model_num'] = summary_result_eval.index\n",
    "\n",
    "summary_result_Wales = pd.DataFrame(summary_result_Wales, columns=cols)\n",
    "summary_result_Wales['model_num'] = summary_result_Wales.index\n",
    "\n",
    "summary_result_Scotland = pd.DataFrame(summary_result_Scotland, columns=cols)\n",
    "summary_result_Scotland['model_num'] = summary_result_Scotland.index\n",
    "\n",
    "summary_result_internaleval = pd.DataFrame(summary_result_val, columns=cols)\n",
    "summary_result_internaleval['model_num'] = summary_result_val.index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1df0bb2-a000-4236-a576-7d625e72205c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# summary_result_eval['model_name'] = summary_result_eval.apply(lambda x: modelNameFixer(x['model_name']), axis=1)\n",
    "# summary_result_val['model_name'] = summary_result_val.apply(lambda x: modelNameFixer(x['model_name']), axis=1)\n",
    "# summary_result_Wales['model_name'] = summary_result_Wales.apply(lambda x: modelNameFixer(x['model_name']), axis=1)\n",
    "# summary_result_Scotland['model_name'] = summary_result_Scotland.apply(lambda x: modelNameFixer(x['model_name']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "993827f6-2c42-4670-8d36-c1e016c7b46c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# summary_result.to_csv('../Models/summary_result_test_1year.csv', index_label=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78d90777-2b7e-47bf-b71a-4830b584e880",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# summary_result = pd.read_csv('../Models/summary_result.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc3017ee-42a8-4f9f-83f2-af18bbc05fde",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# summary_result_internaleval['set'] = 'England'\n",
    "# summary_result_eval['set'] = 'Wales & Scotland'\n",
    "# summary_result_Wales['set'] = 'Wales'\n",
    "# summary_result_Scotland['set'] = 'Scotland'\n",
    "\n",
    "# combine = pd.concat([summary_result_internaleval, summary_result_eval, \n",
    "#                      summary_result_Wales, summary_result_Scotland,\n",
    "#                     ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0b9a3e4-006f-4f11-a7a7-6c3520d3a508",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "combine = pickle.load(open('../Models/benchmarking_result_2vs1.sav', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "127a665c-d323-45e7-bdbb-dde6725e472f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "combine[combine.model_name == 'LR']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d319f724-6f6a-4190-b2a4-f73356369df0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_names = ['LR', 'Lasso', 'Elastics', 'DT', 'RF', 'XGB']\n",
    "for model_name in model_names:\n",
    "    model = pickle.load(open('../Models_trainValEval/12months/'+model_name+'0.sav', 'rb'))\n",
    "    preds = model.predict_proba(X_eval)\n",
    "    preds = [x[1] for x in preds]\n",
    "    fpr, tpr, thresholds = roc_curve(y_eval, preds, pos_label=1)\n",
    "    auc = np.round(roc_auc_score(y_eval, preds), 4)\n",
    "    plt.plot(fpr,tpr,label=model_name+\", auc=\"+str(auc))\n",
    "plt.legend(loc=4)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4326ce41-3969-402d-982b-518b3a147c3f",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_names = ['LR', 'Lasso', 'Elastics', 'DT', 'RF', 'XGB']\n",
    "for model_name in model_names:\n",
    "    for target_outcome in target_outcomes:\n",
    "        y_eval = evaluationData[target_outcome]\n",
    "        model = pickle.load(open('../Models_trainValEval/'+target_outcome+'/'+model_name+'0.sav', 'rb'))\n",
    "        preds = model.predict_proba(X_eval)\n",
    "        preds = [x[1] for x in preds]\n",
    "        fpr, tpr, thresholds = roc_curve(y_eval, preds, pos_label=1)\n",
    "        auc = np.round(roc_auc_score(y_eval, preds), 4)\n",
    "        plt.plot(fpr,tpr,label=target_outcome+\", auc=\"+str(auc))\n",
    "    plt.legend(loc=4)\n",
    "    plt.title(model_name)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00ef9572-a727-4e63-a836-3dd67ab32bf9",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_folder = '../Models_trainValEval/'\n",
    "summary_result_val = []\n",
    "summary_result_eval = []\n",
    "summary_result_Wales = []\n",
    "summary_result_Scotland = []\n",
    "cols = ['model_name', 'outcome', 'auc', 'auprc']\n",
    "for target_outcome in target_outcomes:\n",
    "    y = trainingData[target_outcome]\n",
    "    y_val = validationData[target_outcome]\n",
    "    y = pd.concat([y, y_val])\n",
    "    y_internaleval = internalEvaluationData[target_outcome]\n",
    "    y_eval = evaluationData[target_outcome]\n",
    "    y_eval_Wales = evaluationDataWales[target_outcome]\n",
    "    y_eval_Scotland = evaluationDataScotland[target_outcome]\n",
    "    for model_name in model_names:\n",
    "        # print('======================================================================')\n",
    "        # print(model_name)\n",
    "        model = pickle.load(open(model_folder+ target_outcome + '/'+ model_name + '0.sav', 'rb'))\n",
    "        summary_result_eval.append((str(model_name),target_outcome,) + summariseResult (X_eval, y_eval, model) )\n",
    "        summary_result_Wales.append((str(model_name),target_outcome,) + summariseResult (X_eval_Wales, y_eval_Wales, model) )       \n",
    "        summary_result_Scotland.append((str(model_name),target_outcome,) + summariseResult (X_eval_Scotland, y_eval_Scotland, model) )       \n",
    "        summary_result_val.append((str(model_name),target_outcome,) + summariseResult (X_internaleval, y_internaleval, model) )   \n",
    "\n",
    "    \n",
    "summary_result_eval = pd.DataFrame(summary_result_eval, columns=cols)\n",
    "summary_result_eval['model_num'] = summary_result_eval.index\n",
    "\n",
    "summary_result_Wales = pd.DataFrame(summary_result_Wales, columns=cols)\n",
    "summary_result_Wales['model_num'] = summary_result_Wales.index\n",
    "\n",
    "summary_result_Scotland = pd.DataFrame(summary_result_Scotland, columns=cols)\n",
    "summary_result_Scotland['model_num'] = summary_result_Scotland.index\n",
    "\n",
    "summary_result_internaleval = pd.DataFrame(summary_result_val, columns=cols)\n",
    "summary_result_internaleval['model_num'] = summary_result_val.index\n",
    "summary_result_internaleval['set'] = 'England'\n",
    "summary_result_eval['set'] = 'Wales & Scotland'\n",
    "summary_result_Wales['set'] = 'Wales'\n",
    "summary_result_Scotland['set'] = 'Scotland'\n",
    "\n",
    "combine = pd.concat([summary_result_internaleval, summary_result_eval, \n",
    "                     summary_result_Wales, summary_result_Scotland,\n",
    "                    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0609be8d-4265-475f-9d39-a7fad3bcc37c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = combine\n",
    "data = combine[(combine.outcome=='12months')]\n",
    "bar = sns.catplot(x = 'model_name',       # x variable name\n",
    "            y = 'auc',       # y variable name            \n",
    "            data=data,\n",
    "            kind = \"bar\",\n",
    "            hue = 'set',\n",
    "            # hue_order=['10-fold CV', 'Evaluation Set', 'Wales', 'Scotland'],\n",
    "            height=4,\n",
    "            row='outcome',\n",
    "            aspect=3.5,\n",
    "            errorbar = None,)\n",
    "\n",
    "for items in bar.axes:\n",
    "    for ax in items:\n",
    "        for p in ax.patches:\n",
    "            ax.text(p.get_x() + 0.01, \n",
    "                p.get_height() * 1.002, \n",
    "                '{0:.4f}'.format(p.get_height()), \n",
    "                color='black', rotation=20, fontsize=7)\n",
    "\n",
    "ax.set_ylim(0.6, .81)\n",
    "# ax.set_ylabel('AUC Score', fontsize=13)\n",
    "ax.set_xlabel('Method', fontsize=10)\n",
    "# ax.set_xticklabels(fontsize=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7234d3a-d26b-4b2a-8ad5-d3b5edb38978",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = combine\n",
    "# data = combine[(combine.outcome=='12months')]\n",
    "data = combine[(combine.set=='Wales & Scotland')]\n",
    "bar = sns.catplot(x = 'model_name',       # x variable name\n",
    "            y = 'auc',       # y variable name            \n",
    "            data=data,\n",
    "            kind = \"bar\",\n",
    "            hue = 'set',\n",
    "            # hue_order=['10-fold CV', 'Evaluation Set', 'Wales', 'Scotland'],\n",
    "            height=3,\n",
    "            row='outcome',\n",
    "            aspect=1.5,\n",
    "            errorbar = None,legend=False, sharex=False)\n",
    "\n",
    "for items in bar.axes:\n",
    "    for ax in items:\n",
    "        for p in ax.patches:\n",
    "            ax.text(p.get_x() + 0.01, \n",
    "                p.get_height() * 1.002, \n",
    "                '{0:.4f}'.format(p.get_height()), \n",
    "                color='black', rotation=20, fontsize=7)\n",
    "\n",
    "ax.set_ylim(0.6, .81)\n",
    "# ax.set_ylabel('AUC Score', fontsize=13)\n",
    "ax.set_xlabel('Method', fontsize=10)\n",
    "# ax.set_xticklabels(fontsize=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3cdbe5e-ff07-40da-aa26-bba6d4f0e1e1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pickle.dump(combine, open('../Models/benchmarking_result.sav', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9b74a71-100b-4c52-8b4a-8ebbc91cc962",
   "metadata": {},
   "source": [
    "## Calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "10439406-a07b-4c3b-9ebc-9c2b6669bb9f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def summariseResultCalibration (testX, testY, model, threshold):\n",
    "    preds = model.predict_proba(testX)\n",
    "    preds = [0 if x[1] < threshold else 1 for x in preds]\n",
    "    tn, fp, fn, tp = confusion_matrix(testY, preds).ravel()\n",
    "    specificity = tn / (tn+fp)\n",
    "    sensitivity = tp / (tp+fn)\n",
    "    ppv = 100*tp/(tp+fp)\n",
    "    npv = 100*tn/(fn+tn)\n",
    "    acc = accuracy_score(testY, preds)\n",
    "    f1score = f1_score(testY, preds, average = 'binary')\n",
    "    balanceacc = balanced_accuracy_score(testY, preds)\n",
    "    aucscore = roc_auc_score(testY, preds)\n",
    "    return np.round(acc,4), np.round(specificity,4), np.round(sensitivity,4), np.round(balanceacc,4), np.round(f1score,4), np.round(ppv,4), np.round(npv,4), np.round(aucscore,4)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "22d8ca32-25e5-4d3d-b7be-a29a451366ea",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:34:58] DEBUG: /workspace/src/gbm/gbtree.cc:130: Using tree method: 3\n",
      "[14:34:58] DEBUG: /workspace/src/tree/updater_gpu_hist.cu:822: [GPU Hist]: Configure\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/abudiarto/miniconda3/envs/tf2.13/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [14:34:59] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
      "Potential solutions:\n",
      "- Use a data structure that matches the device ordinal in the booster.\n",
      "- Set the device for booster before call to inplace_predict.\n",
      "\n",
      "This warning will only be shown once.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:34:59] DEBUG: /workspace/src/gbm/gbtree.cc:130: Using tree method: 3\n",
      "[14:34:59] DEBUG: /workspace/src/tree/updater_gpu_hist.cu:822: [GPU Hist]: Configure\n",
      "[14:34:59] DEBUG: /workspace/src/gbm/gbtree.cc:130: Using tree method: 3\n",
      "[14:34:59] DEBUG: /workspace/src/tree/updater_gpu_hist.cu:822: [GPU Hist]: Configure\n",
      "[14:34:59] DEBUG: /workspace/src/gbm/gbtree.cc:130: Using tree method: 3\n",
      "[14:34:59] DEBUG: /workspace/src/tree/updater_gpu_hist.cu:822: [GPU Hist]: Configure\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>outcome</th>\n",
       "      <th>model</th>\n",
       "      <th>threshold</th>\n",
       "      <th>acc</th>\n",
       "      <th>sens</th>\n",
       "      <th>spec</th>\n",
       "      <th>balanced_acc</th>\n",
       "      <th>f1</th>\n",
       "      <th>ppv</th>\n",
       "      <th>npv</th>\n",
       "      <th>auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>outcome_3months</td>\n",
       "      <td>LR</td>\n",
       "      <td>0.512986</td>\n",
       "      <td>0.7317</td>\n",
       "      <td>0.7378</td>\n",
       "      <td>0.6380</td>\n",
       "      <td>0.6879</td>\n",
       "      <td>0.2262</td>\n",
       "      <td>13.7487</td>\n",
       "      <td>96.8860</td>\n",
       "      <td>0.6879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>outcome_6months</td>\n",
       "      <td>LR</td>\n",
       "      <td>0.521344</td>\n",
       "      <td>0.7416</td>\n",
       "      <td>0.7514</td>\n",
       "      <td>0.6499</td>\n",
       "      <td>0.7006</td>\n",
       "      <td>0.3258</td>\n",
       "      <td>21.7429</td>\n",
       "      <td>95.2815</td>\n",
       "      <td>0.7006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>outcome_9months</td>\n",
       "      <td>LR</td>\n",
       "      <td>0.532532</td>\n",
       "      <td>0.7495</td>\n",
       "      <td>0.7670</td>\n",
       "      <td>0.6230</td>\n",
       "      <td>0.6950</td>\n",
       "      <td>0.3761</td>\n",
       "      <td>26.9314</td>\n",
       "      <td>93.6547</td>\n",
       "      <td>0.6950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>outcome_12months</td>\n",
       "      <td>LR</td>\n",
       "      <td>0.501458</td>\n",
       "      <td>0.7388</td>\n",
       "      <td>0.7550</td>\n",
       "      <td>0.6507</td>\n",
       "      <td>0.7029</td>\n",
       "      <td>0.4371</td>\n",
       "      <td>32.9031</td>\n",
       "      <td>92.1319</td>\n",
       "      <td>0.7029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>outcome_3months</td>\n",
       "      <td>DT</td>\n",
       "      <td>0.669588</td>\n",
       "      <td>0.7537</td>\n",
       "      <td>0.7634</td>\n",
       "      <td>0.6061</td>\n",
       "      <td>0.6847</td>\n",
       "      <td>0.2323</td>\n",
       "      <td>14.3689</td>\n",
       "      <td>96.7301</td>\n",
       "      <td>0.6847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>outcome_6months</td>\n",
       "      <td>DT</td>\n",
       "      <td>0.644877</td>\n",
       "      <td>0.7701</td>\n",
       "      <td>0.7875</td>\n",
       "      <td>0.6059</td>\n",
       "      <td>0.6967</td>\n",
       "      <td>0.3361</td>\n",
       "      <td>23.2596</td>\n",
       "      <td>94.9496</td>\n",
       "      <td>0.6967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>outcome_9months</td>\n",
       "      <td>DT</td>\n",
       "      <td>0.648115</td>\n",
       "      <td>0.7681</td>\n",
       "      <td>0.7929</td>\n",
       "      <td>0.5881</td>\n",
       "      <td>0.6905</td>\n",
       "      <td>0.3806</td>\n",
       "      <td>28.1368</td>\n",
       "      <td>93.3181</td>\n",
       "      <td>0.6905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>outcome_12months</td>\n",
       "      <td>DT</td>\n",
       "      <td>0.526802</td>\n",
       "      <td>0.7314</td>\n",
       "      <td>0.7441</td>\n",
       "      <td>0.6624</td>\n",
       "      <td>0.7032</td>\n",
       "      <td>0.4346</td>\n",
       "      <td>32.3344</td>\n",
       "      <td>92.2707</td>\n",
       "      <td>0.7032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>outcome_3months</td>\n",
       "      <td>RF</td>\n",
       "      <td>0.541349</td>\n",
       "      <td>0.7443</td>\n",
       "      <td>0.7513</td>\n",
       "      <td>0.6372</td>\n",
       "      <td>0.6943</td>\n",
       "      <td>0.2345</td>\n",
       "      <td>14.3728</td>\n",
       "      <td>96.9336</td>\n",
       "      <td>0.6943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>outcome_6months</td>\n",
       "      <td>RF</td>\n",
       "      <td>0.492194</td>\n",
       "      <td>0.7096</td>\n",
       "      <td>0.7099</td>\n",
       "      <td>0.7060</td>\n",
       "      <td>0.7080</td>\n",
       "      <td>0.3184</td>\n",
       "      <td>20.5523</td>\n",
       "      <td>95.7839</td>\n",
       "      <td>0.7080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>outcome_9months</td>\n",
       "      <td>RF</td>\n",
       "      <td>0.517838</td>\n",
       "      <td>0.7292</td>\n",
       "      <td>0.7374</td>\n",
       "      <td>0.6696</td>\n",
       "      <td>0.7035</td>\n",
       "      <td>0.3747</td>\n",
       "      <td>26.0090</td>\n",
       "      <td>94.1826</td>\n",
       "      <td>0.7035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>outcome_12months</td>\n",
       "      <td>RF</td>\n",
       "      <td>0.524642</td>\n",
       "      <td>0.7454</td>\n",
       "      <td>0.7619</td>\n",
       "      <td>0.6556</td>\n",
       "      <td>0.7088</td>\n",
       "      <td>0.4452</td>\n",
       "      <td>33.7043</td>\n",
       "      <td>92.2977</td>\n",
       "      <td>0.7088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>outcome_3months</td>\n",
       "      <td>XGB</td>\n",
       "      <td>0.430055</td>\n",
       "      <td>0.6933</td>\n",
       "      <td>0.6922</td>\n",
       "      <td>0.7109</td>\n",
       "      <td>0.7015</td>\n",
       "      <td>0.2218</td>\n",
       "      <td>13.1396</td>\n",
       "      <td>97.3367</td>\n",
       "      <td>0.7015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>outcome_6months</td>\n",
       "      <td>XGB</td>\n",
       "      <td>0.581629</td>\n",
       "      <td>0.7362</td>\n",
       "      <td>0.7426</td>\n",
       "      <td>0.6761</td>\n",
       "      <td>0.7093</td>\n",
       "      <td>0.3300</td>\n",
       "      <td>21.8237</td>\n",
       "      <td>95.5696</td>\n",
       "      <td>0.7093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>outcome_9months</td>\n",
       "      <td>XGB</td>\n",
       "      <td>0.656510</td>\n",
       "      <td>0.7487</td>\n",
       "      <td>0.7618</td>\n",
       "      <td>0.6538</td>\n",
       "      <td>0.7078</td>\n",
       "      <td>0.3867</td>\n",
       "      <td>27.4520</td>\n",
       "      <td>94.1047</td>\n",
       "      <td>0.7078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>outcome_12months</td>\n",
       "      <td>XGB</td>\n",
       "      <td>0.578658</td>\n",
       "      <td>0.7366</td>\n",
       "      <td>0.7486</td>\n",
       "      <td>0.6717</td>\n",
       "      <td>0.7102</td>\n",
       "      <td>0.4429</td>\n",
       "      <td>33.0315</td>\n",
       "      <td>92.5107</td>\n",
       "      <td>0.7102</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             outcome model  threshold     acc    sens    spec  balanced_acc  \\\n",
       "0    outcome_3months    LR   0.512986  0.7317  0.7378  0.6380        0.6879   \n",
       "1    outcome_6months    LR   0.521344  0.7416  0.7514  0.6499        0.7006   \n",
       "2    outcome_9months    LR   0.532532  0.7495  0.7670  0.6230        0.6950   \n",
       "3   outcome_12months    LR   0.501458  0.7388  0.7550  0.6507        0.7029   \n",
       "4    outcome_3months    DT   0.669588  0.7537  0.7634  0.6061        0.6847   \n",
       "5    outcome_6months    DT   0.644877  0.7701  0.7875  0.6059        0.6967   \n",
       "6    outcome_9months    DT   0.648115  0.7681  0.7929  0.5881        0.6905   \n",
       "7   outcome_12months    DT   0.526802  0.7314  0.7441  0.6624        0.7032   \n",
       "8    outcome_3months    RF   0.541349  0.7443  0.7513  0.6372        0.6943   \n",
       "9    outcome_6months    RF   0.492194  0.7096  0.7099  0.7060        0.7080   \n",
       "10   outcome_9months    RF   0.517838  0.7292  0.7374  0.6696        0.7035   \n",
       "11  outcome_12months    RF   0.524642  0.7454  0.7619  0.6556        0.7088   \n",
       "12   outcome_3months   XGB   0.430055  0.6933  0.6922  0.7109        0.7015   \n",
       "13   outcome_6months   XGB   0.581629  0.7362  0.7426  0.6761        0.7093   \n",
       "14   outcome_9months   XGB   0.656510  0.7487  0.7618  0.6538        0.7078   \n",
       "15  outcome_12months   XGB   0.578658  0.7366  0.7486  0.6717        0.7102   \n",
       "\n",
       "        f1      ppv      npv     auc  \n",
       "0   0.2262  13.7487  96.8860  0.6879  \n",
       "1   0.3258  21.7429  95.2815  0.7006  \n",
       "2   0.3761  26.9314  93.6547  0.6950  \n",
       "3   0.4371  32.9031  92.1319  0.7029  \n",
       "4   0.2323  14.3689  96.7301  0.6847  \n",
       "5   0.3361  23.2596  94.9496  0.6967  \n",
       "6   0.3806  28.1368  93.3181  0.6905  \n",
       "7   0.4346  32.3344  92.2707  0.7032  \n",
       "8   0.2345  14.3728  96.9336  0.6943  \n",
       "9   0.3184  20.5523  95.7839  0.7080  \n",
       "10  0.3747  26.0090  94.1826  0.7035  \n",
       "11  0.4452  33.7043  92.2977  0.7088  \n",
       "12  0.2218  13.1396  97.3367  0.7015  \n",
       "13  0.3300  21.8237  95.5696  0.7093  \n",
       "14  0.3867  27.4520  94.1047  0.7078  \n",
       "15  0.4429  33.0315  92.5107  0.7102  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calibrationResult = []\n",
    "model_names = ['LR', 'DT', 'RF', 'XGB']\n",
    "for model_name in model_names:\n",
    "    for target_outcome in target_outcomes:\n",
    "        model = pickle.load(open('../MODELS/TestResult/'+target_outcome+'_'+model_name+'.sav', 'rb'))\n",
    "        y_externalVal = externalEvaluationData[target_outcome]\n",
    "        preds = model.predict_proba(X_externalVal)\n",
    "        preds = [x[1] for x in preds]\n",
    "        fpr, tpr, thresholds = roc_curve(y_externalVal, preds)\n",
    "        optimal_idx = np.argmax(tpr - fpr)# Find optimal probability threshold\n",
    "        threshold = thresholds[optimal_idx]\n",
    "        calibrationResult.append(((target_outcome, model_name, threshold)+summariseResultCalibration(X_externalVal, y_externalVal, model, threshold)))\n",
    "\n",
    "cols = ['outcome', 'model', 'threshold', 'acc', 'sens', 'spec', 'balanced_acc', 'f1', 'ppv' , 'npv', 'auc']\n",
    "pd.DataFrame(calibrationResult, columns = cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52435bc5-9f38-4629-bd53-ed58d660e4ad",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baaabe03-0654-40e4-846c-26c3b1ebb50d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "best_model_dt = pickle.load(open('../Models_trainValEval/12months/DT0.sav', 'rb'))\n",
    "\n",
    "# pd.DataFrame([best_model3.feature_importances_], columns=X.columns).T.sort_values(0, ascending=False)\n",
    "sorted_idx = best_model_dt.feature_importances_.argsort()\n",
    "plt.figure(figsize=(3,4))\n",
    "plt.barh(X.columns[sorted_idx][-10:], best_model_dt.feature_importances_[sorted_idx][-10:])\n",
    "plt.xlabel(\"Decision Tree Feature Importance\")\n",
    "plt.show()\n",
    "dttop10 = X.columns[sorted_idx][-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "621c9b9a-76cf-45c8-a42d-ec9a120842cd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "best_model_dt = pickle.load(open('../Models_trainValEval/12months/RF0.sav', 'rb'))\n",
    "\n",
    "# pd.DataFrame([best_model3.feature_importances_], columns=X.columns).T.sort_values(0, ascending=False)\n",
    "sorted_idx = best_model_dt.feature_importances_.argsort()\n",
    "plt.figure(figsize=(3,4))\n",
    "plt.barh(X.columns[sorted_idx][-10:], best_model_dt.feature_importances_[sorted_idx][-10:])\n",
    "plt.xlabel(\"Random Forest Feature Importance\")\n",
    "plt.show()\n",
    "rftop10 = X.columns[sorted_idx][-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f23258bb-f406-47ac-b970-2c68c6c9f392",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "best_model_dt = pickle.load(open('../Models_trainValEval/12months/XGB0.sav', 'rb'))\n",
    "\n",
    "# pd.DataFrame([best_model3.feature_importances_], columns=X.columns).T.sort_values(0, ascending=False)\n",
    "sorted_idx = best_model_dt.feature_importances_.argsort()\n",
    "plt.figure(figsize=(3,4))\n",
    "plt.barh(X.columns[sorted_idx][-10:], best_model_dt.feature_importances_[sorted_idx][-10:])\n",
    "plt.xlabel(\"XGBoost Feature Importance\")\n",
    "plt.show()\n",
    "xgbtop10 = X.columns[sorted_idx][-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "585071b8-244d-4f64-bd03-6cfcb038b749",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "best_model_lr = pickle.load(open('../Models_trainValEval/12months/LR0.sav', 'rb'))\n",
    "\n",
    "# pd.DataFrame([best_model3.feature_importances_], columns=X.columns).T.sort_values(0, ascending=False)\n",
    "sorted_idx = best_model_lr.coef_[0].argsort()\n",
    "plt.figure(figsize=(3,4))\n",
    "plt.barh(X.columns[sorted_idx][-10:], best_model_lr.coef_[0][sorted_idx][-10:])\n",
    "plt.xlabel(\"LR Feature Importance\")\n",
    "plt.show()\n",
    "lrtop10 = X.columns[sorted_idx][-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55301152-1e06-40ba-91c6-a15ef4be1c00",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "best_model_lasso = pickle.load(open('../Models_trainValEval/12months/Lasso0.sav', 'rb'))\n",
    "\n",
    "# pd.DataFrame([best_model3.feature_importances_], columns=X.columns).T.sort_values(0, ascending=False)\n",
    "sorted_idx = best_model_lasso.coef_[0].argsort()\n",
    "plt.figure(figsize=(3,4))\n",
    "plt.barh(X.columns[sorted_idx][-10:], best_model_lasso.coef_[0][sorted_idx][-10:])\n",
    "plt.xlabel(\"Lasso Feature Importance\")\n",
    "plt.show()\n",
    "lassotop10 = X.columns[sorted_idx][-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3edf1cea-c3ce-4cc3-a50f-eed9f0348437",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "best_model_lasso = pickle.load(open('../Models_trainValEval/12months/Elastics0.sav', 'rb'))\n",
    "\n",
    "# pd.DataFrame([best_model3.feature_importances_], columns=X.columns).T.sort_values(0, ascending=False)\n",
    "sorted_idx = best_model_lasso.coef_[0].argsort()\n",
    "plt.figure(figsize=(3,4))\n",
    "plt.barh(X.columns[sorted_idx][-10:], best_model_lasso.coef_[0][sorted_idx][-10:])\n",
    "plt.xlabel(\"Elastics Feature Importance\")\n",
    "plt.show()\n",
    "elasticstop10 = X.columns[sorted_idx][-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a91b58c1-a6cd-4616-b37e-8a838c4e694e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "list(set(xgbtop10).intersection(set(lassotop10)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3210cf71-819b-4110-a6da-a8476d3164f3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model2visualise = pickle.load(open('../Models_trainValEval/12months/DT0.sav', 'rb'))\n",
    "prune_duplicate_leaves(model2visualise)\n",
    "fig = plt.figure(figsize=(30,10))\n",
    "_ = tree.plot_tree(model2visualise, \n",
    "                   feature_names=X.columns,  \n",
    "                   class_names=['no asthma attack','asthma attack'],\n",
    "                   filled=True,)\n",
    "# plt.savefig('../FinalData/dt.png',format='png',bbox_inches = \"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18cc8cb2-0b7c-4068-8602-3f20ce245e3b",
   "metadata": {},
   "source": [
    "## Minimum depth DT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd9f3421-1c24-4b2a-a9d4-883463ff6890",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "#DT with minimum max of depth\n",
    "\n",
    "#EXECUTE model training\n",
    "X = trainingData[features_columns]\n",
    "# X_test = evaluationData[features_columns]\n",
    "target_outcome = '12months'\n",
    "\n",
    "print(target_outcome)\n",
    "y = trainingData[target_outcome]\n",
    "y_test = evaluationData[target_outcome]\n",
    "#Build models -> it can be commented if the models have been trained\n",
    "\n",
    "# if os.path.isfile('../Models_trainValEval/dt_minimum_depth.sav'):\n",
    "#     dt_model = pickle.load(open('../Models_trainValEval/dt_minimum_depth.sav', 'rb'))\n",
    "# else:\n",
    "dt_model = DecisionTreeClassifier(class_weight='balanced', max_depth=4, splitter='random', random_state=1234)\n",
    "dt_model.fit(X, y)\n",
    "pickle.dump(dt_model, open('../Models_trainValEval/dt_minimum_depth.sav', 'wb'))    \n",
    "    \n",
    "\n",
    "print(summariseResult (X_val, y_val, dt_model))\n",
    "print(summariseResult (X_eval, y_eval, dt_model))\n",
    "print(summariseResult (X_eval_Wales, y_eval_Wales, dt_model))\n",
    "print(\"DT done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69bca650-b488-4717-9563-093c43b119f2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prune_duplicate_leaves(dt_model)\n",
    "fig = plt.figure(figsize=(15,10))\n",
    "_ = tree.plot_tree(dt_model, \n",
    "                   feature_names=X.columns,  \n",
    "                   class_names=['no asthma attack','asthma attack'],\n",
    "                   filled=True)\n",
    "plt.savefig('../FinalData/dt_minimumdepth.png',format='png',bbox_inches = \"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c20cc936-fc3a-480e-ad1b-cccbbc8cd41b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "scaler = pickle.load(open('../Models_trainValEval/cont_scaler.pkl', 'rb'))\n",
    "continuous_vars = ['age', 'CharlsonScore', 'average_daily_dose_ICS', 'prescribed_daily_dose_ICS', 'ICS_medication_possesion_ratio', \n",
    "                   'numOCS', 'numPCS', 'numPCSAsthma', 'numAntibioticsEvents', 'numAntibioticswithLRTI', 'numOCSEvents', 'numOCSwithLRTI', \n",
    "                   'numAsthmaAttacks', 'numAcuteRespEvents', 'numHospEvents']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "263f296b-25f4-4399-b254-48e940663b6f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "DataOfInterest_cont = pd.DataFrame(scaler.inverse_transform(trainingData[continuous_vars]), columns=scaler.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4b0eefc-26d5-4b8e-bf2f-6d7683f35940",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "VarOfInterest = ['numOCS', 'numPCS']\n",
    "additionalVars = ['prescribed_daily_dose_ICS', 'numAntibioticsEvents', 'ICS_medication_possesion_ratio', 'numAsthmaAttacks', 'numAntibioticswithLRTI', 'age']\n",
    "DataOfInterest = pd.concat((DataOfInterest_cont, trainingData[['BTS_step', 'imd_decile_0']+target_outcomes]), axis=1)\n",
    "#solve little problem with inverse scaling:\n",
    "DataOfInterest['numAsthmaAttacks'] = DataOfInterest.numAsthmaAttacks.apply(lambda x: 0 if x<1 else x)\n",
    "DataOfInterest['numOCSwithLRTI'] = DataOfInterest.numOCSwithLRTI.apply(lambda x: 0 if x<1 else x)\n",
    "DataOfInterest['numHospEvents'] = DataOfInterest.numHospEvents.apply(lambda x: 0 if x<1 else x)\n",
    "DataOfInterest.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "960c4212-78a5-40ef-ac3c-faf16ee0c50d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "scaler.feature_names_in_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e162ed5f-0822-4876-b7f8-905cefd4b556",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "depth3_1 = [[0, 0, 0,\n",
    "       0, 0,\n",
    "       0.041, -1.086, 0, 0,\n",
    "       0, 0, 0,\n",
    "       0, 0, 0]]\n",
    "\n",
    "depth3_2 = [[0, 0, 0,\n",
    "       0, 0,\n",
    "       0.583, -1.086, 0, 0,\n",
    "       0, 0, 0,\n",
    "       0, 0, 0]]\n",
    "\n",
    "depth4_1 = [[0, -0.822, 0,\n",
    "       0, 0,\n",
    "       0.041, -0.23, 0, 0,\n",
    "       0, 0, 0,\n",
    "       2.493, 0, 0]]\n",
    "\n",
    "depth4_2 = [[0, -0.822, 0,\n",
    "       0, 0,\n",
    "       0.583, -1.02, 0, 0,\n",
    "       0, 0, 0,\n",
    "       2.493, 0, 0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a934c8e3-7234-485d-a7d3-454a0bf7c656",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "scaler.inverse_transform(depth3_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cc2358f-70d9-44ba-823d-c1869cb2dffd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "scaler.inverse_transform(depth3_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a22496a5-8506-444c-86d2-1e3fa62ebdc9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "scaler.inverse_transform(depth4_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "782383b5-decf-4938-a214-12035965c976",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "scaler.inverse_transform(depth4_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "502a97c3-0381-4d81-85e2-006001b5fe9d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "DataOfInterest.CharlsonScore.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dfac1c0-e120-4c31-ad12-de84bb2a6510",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d63f20cd-8ccf-41f5-a528-770dcaa93c41",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "preds_dt = best_model_dt.predict(trainingData[features_columns])\n",
    "preds_lasso = best_model_lasso.predict(trainingData[features_columns])\n",
    "prediction_table = pd.DataFrame([trainingData['12months'], preds_dt, preds_lasso]).T\n",
    "prediction_table.columns = ['y_true', 'y_pred_dt', 'y_pred_lasso']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8a0a349-ca09-4955-bfa3-cf594957ac01",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "false_positive = prediction_table[(prediction_table.y_pred_dt==1) & (prediction_table.y_true!=prediction_table.y_pred_dt)]\n",
    "false_negative = prediction_table[(prediction_table.y_pred_dt==0) & (prediction_table.y_true!=prediction_table.y_pred_dt)]\n",
    "true_positive = prediction_table[(prediction_table.y_pred_dt==1) & (prediction_table.y_true==prediction_table.y_pred_dt)]\n",
    "true_negative = prediction_table[(prediction_table.y_pred_dt==0) & (prediction_table.y_true==prediction_table.y_pred_dt)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec3982da-bf1d-48ff-a3fb-0395c0a6f519",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print('True Pos')\n",
    "print(DataOfInterest.iloc[true_positive.index][VarOfInterest+['BTS_step']].describe())\n",
    "print('-----------------------------------------------------------------------------------')\n",
    "print('False Neg')\n",
    "print(DataOfInterest.iloc[false_negative.index][VarOfInterest+['BTS_step']].describe())\n",
    "print('-----------------------------------------------------------------------------------')\n",
    "# print('False Pos')\n",
    "# print(DataOfInterest.iloc[false_positive.index][VarOfInterest+['BTS_step']].describe())\n",
    "# print('-----------------------------------------------------------------------------------')\n",
    "# print('True Neg')\n",
    "# print(DataOfInterest.iloc[true_negative.index][VarOfInterest+['BTS_step']].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "976c8654-fead-4a22-9602-946a25406eae",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "DataOfInterest.iloc[true_positive.index][VarOfInterest+['BTS_step']].boxplot(ax=ax)\n",
    "ax.set_ylim(-50,400)\n",
    "plt.show()\n",
    "print('-----------------------------------------------------------------------------------')\n",
    "fig, ax = plt.subplots()\n",
    "DataOfInterest.iloc[false_negative.index][VarOfInterest+['BTS_step']].boxplot()\n",
    "ax.set_ylim(-50,400)\n",
    "plt.show()\n",
    "print('-----------------------------------------------------------------------------------')\n",
    "fig, ax = plt.subplots()\n",
    "DataOfInterest.iloc[true_negative.index][VarOfInterest+['BTS_step']].boxplot()\n",
    "ax.set_ylim(-50,400)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe6e4b6e-bb69-4c98-ae74-7711e9bf6bdd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(DataOfInterest.iloc[true_positive.index][VarOfInterest+['BTS_step']+additionalVars+['imd_decile_0']].describe())\n",
    "print('-----------------------------------------------------------------------------------')\n",
    "print(DataOfInterest.iloc[false_negative.index][VarOfInterest+['BTS_step']+additionalVars+['imd_decile_0']].describe())\n",
    "print('-----------------------------------------------------------------------------------')\n",
    "print(DataOfInterest.iloc[true_negative.index][VarOfInterest+['BTS_step']+additionalVars+['imd_decile_0']].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94da4310-610e-4eb8-b2d3-55302c07bf5d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "DataOfInterest.iloc[true_positive.index][VarOfInterest+['BTS_step']].sample(n=20, random_state=1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e060086-dc67-4232-b8fc-5c406bf7a7de",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "DataOfInterest.iloc[false_negative.index][VarOfInterest+['BTS_step']].sample(n=20, random_state=1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0abade78-e191-4c5e-a928-35bd1732936d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a68a60f6-89a5-4070-a5e5-c9a737ddad71",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bcbfbc12-c37e-444b-8859-be5785cb7de0",
   "metadata": {},
   "source": [
    "## Run models only on the subset of BTS == 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23b5c8db-a5ea-4d61-9c0f-e20c98a3bd4a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "trainingDataSubset = trainingData[(trainingData.BTS_step < 7)]\n",
    "validationDataSubset = validationData[(validationData.BTS_step < 7) ]\n",
    "evaluationDataSubset = evaluationData[(evaluationData.BTS_step < 7)]\n",
    "evaluationDataWalesSubset = evaluationDataWales[(evaluationDataWales.BTS_step < 7) ]\n",
    "evaluationDataScotlandSubset = evaluationDataScotland[(evaluationDataScotland.BTS_step < 7)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "011b3108-663b-4ddd-b893-6ce8e5a9372a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#encode categorical data\n",
    "\n",
    "# cat_vars = ['PEFStatus','EosinophilLevel']\n",
    "onehot_vars = ['BTS_step']\n",
    "# data_categorical = trainingData[cat_vars]\n",
    "data_onehot = trainingDataSubset[onehot_vars]\n",
    "\n",
    "# #ordinal encoder\n",
    "# encoder = OrdinalEncoder(categories=[['not_recorded','less than 60', '60-80', 'more than 80'], ['unknown', 'normal', 'high']]).set_output(transform=\"pandas\")\n",
    "# data_encoded = encoder.fit_transform(data_categorical)\n",
    "# pickle.dump(encoder, open('../Models/cat_encoder.pkl', 'wb'))\n",
    "    \n",
    "#one hot encoder\n",
    "onehot_encoder = OneHotEncoder(sparse_output=False).set_output(transform=\"pandas\")\n",
    "onehot_encoded = onehot_encoder.fit_transform(data_onehot)\n",
    "# pickle.dump(onehot_encoder, open('../Models/onehot_encoder.pkl', 'wb'))\n",
    "\n",
    "# trainingDataSubset = pd.concat([trainingDataSubset.drop(cat_vars, axis=1), data_encoded], axis=1)\n",
    "trainingDataSubset = pd.concat([trainingDataSubset.drop(onehot_vars, axis=1), onehot_encoded], axis=1)\n",
    "\n",
    "print('Data shape after encoding: ', trainingDataSubset.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "699b2d79-2de5-4c41-af3c-a89b61340795",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#encode cat vars for validation and evaluation set\n",
    "# data_val_categorical = validationData[cat_vars]\n",
    "data_val_onehot = validationDataSubset[onehot_vars]\n",
    "# data_eval_categorical = evaluationData[cat_vars]\n",
    "data_eval_onehot = evaluationDataSubset[onehot_vars]\n",
    "# data_eval_Wales_categorical = evaluationDataWales[cat_vars]\n",
    "data_eval_Wales_onehot = evaluationDataWalesSubset[onehot_vars]\n",
    "# data_eval_Scotland_categorical = evaluationDataScotland[cat_vars]\n",
    "data_eval_Scotland_onehot = evaluationDataScotlandSubset[onehot_vars]\n",
    "\n",
    "# encoder = pickle.load(open('../Models/cat_encoder.pkl', 'rb'))\n",
    "# data_val_encoded = encoder.transform(data_val_categorical)\n",
    "# data_eval_encoded = encoder.transform(data_eval_categorical)\n",
    "# data_eval_Wales_encoded = encoder.transform(data_eval_Wales_categorical)\n",
    "# data_eval_Scotland_encoded = encoder.transform(data_eval_Scotland_categorical)\n",
    "\n",
    "# onehot_encoder = pickle.load(open('../Models/onehot_encoder.pkl', 'rb'))\n",
    "onehot_val_encoded = onehot_encoder.transform(data_val_onehot)\n",
    "onehot_eval_encoded = onehot_encoder.transform(data_eval_onehot)\n",
    "onehot_eval_Wales_encoded = onehot_encoder.transform(data_eval_Wales_onehot)\n",
    "onehot_eval_Scotland_encoded = onehot_encoder.transform(data_eval_Scotland_onehot)\n",
    "\n",
    "# validationDataSubset = pd.concat([validationDataSubset.drop(cat_vars, axis=1), data_val_encoded], axis=1)\n",
    "validationDataSubset = pd.concat([validationDataSubset.drop(onehot_vars, axis=1), onehot_val_encoded], axis=1)\n",
    "\n",
    "# evaluationDataSubset = pd.concat([evaluationDataSubset.drop(cat_vars, axis=1), data_eval_encoded], axis=1)\n",
    "evaluationDataSubset = pd.concat([evaluationDataSubset.drop(onehot_vars, axis=1), onehot_eval_encoded], axis=1)\n",
    "\n",
    "# evaluationDataWalesSubset = pd.concat([evaluationDataWalesSubset.drop(cat_vars, axis=1), data_eval_Wales_encoded], axis=1)\n",
    "evaluationDataWalesSubset = pd.concat([evaluationDataWalesSubset.drop(onehot_vars, axis=1), onehot_eval_Wales_encoded], axis=1)\n",
    "\n",
    "# evaluationDataScotlandSubset = pd.concat([evaluationDataScotlandSubset.drop(cat_vars, axis=1), data_eval_Scotland_encoded], axis=1)\n",
    "evaluationDataScotlandSubset = pd.concat([evaluationDataScotlandSubset.drop(onehot_vars, axis=1), onehot_eval_Scotland_encoded], axis=1)\n",
    "\n",
    "print('Val data shape after encoding: ', validationDataSubset.shape)\n",
    "print('Eval data shape after encoding: ', evaluationDataSubset.shape)\n",
    "print('Evaluation data Wales shape: ', evaluationDataWalesSubset.shape)\n",
    "print('Evaluation data Scotland shape: ', evaluationDataScotlandSubset.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ee0514a-5b9c-4199-b9bb-31b7bd6b4acd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "trainingDataSubset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94e982b7-1a51-4c73-b86a-d482d42d42cc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "trainingDataSubset.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48836f2d-4aa4-45cc-8c26-3e2f023d790c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "features_columns.remove('BTS_step')\n",
    "features_columns = features_columns + ['BTS_step_0.0', 'BTS_step_1.0', 'BTS_step_2.0',\n",
    "                                       'BTS_step_3.0', 'BTS_step_4.0', 'BTS_step_5.0']\n",
    "features_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d658e66-316c-430d-8eaf-3e6ddb0b1b73",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_subset = trainingDataSubset[features_columns]\n",
    "X_val_subset = validationDataSubset[features_columns]\n",
    "X_eval_subset = evaluationDataSubset[features_columns]\n",
    "X_eval_Wales_subset = evaluationDataWalesSubset[features_columns]\n",
    "X_eval_Scotland_subset = evaluationDataScotlandSubset[features_columns]\n",
    "target_outcomes = ['3months', '6months', '12months', '24months'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc032b87-4a5a-4477-bb41-ed250aff00ac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_subset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea695565-9cf8-4368-addc-05602adb1821",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_subset.shape[0]/trainingData.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7fff2f6-b190-47db-ad2c-eb621aeec105",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "\n",
    "#EXECUTE model training\n",
    "summary_result_val_subset = []\n",
    "summary_result_eval_subset = []\n",
    "summary_result_Wales_subset = []\n",
    "summary_result_Scotland_subset = []\n",
    "cols = ['model_name', 'outcome', 'class_ratio', 'acc','spec','sens','auc', 'auprc', 'balance_accuracy', 'f1_score', 'ppv', 'npv']\n",
    "model_folder = '../Models_subsetBTS/'\n",
    "fold = 0\n",
    "\n",
    "for target_outcome in target_outcomes:\n",
    "    models = pd.DataFrame(columns=['modelname', 'target_outcome', 'class_ratio'])\n",
    "    print(target_outcome)\n",
    "    y_subset = trainingDataSubset[target_outcome]\n",
    "    y_val_subset = validationDataSubset[target_outcome]\n",
    "    y_eval_subset = evaluationDataSubset[target_outcome]\n",
    "    y_eval_Wales_subset = evaluationDataWalesSubset[target_outcome]\n",
    "    y_eval_Scotland_subset = evaluationDataScotlandSubset[target_outcome]\n",
    "    #Build models -> it can be commented if the models have been trained\n",
    "    models_temp = pd.DataFrame(build_models(X_subset, y_subset, target_outcome, params_dict, model_folder, fold), columns=['modelname', 'target_outcome', 'class_ratio'])\n",
    "    models = pd.concat([models,models_temp]).reset_index(drop=True)\n",
    "\n",
    "    #evaluate model\n",
    "    for modelname, target_outcome, classratio in models.values:\n",
    "        # print('======================================================================')\n",
    "        print(modelname)\n",
    "        model = pickle.load(open(model_folder+ target_outcome + '/'+ modelname + '.sav', 'rb'))\n",
    "        summary_result_eval_subset.append((str(modelname), target_outcome, classratio, ) + summariseResult (X_eval_subset, y_eval_subset, model) )\n",
    "        summary_result_Wales_subset.append((str(modelname), target_outcome, classratio, ) + summariseResult (X_eval_Wales_subset, y_eval_Wales_subset, model) )       \n",
    "        summary_result_Scotland_subset.append((str(modelname), target_outcome, classratio, ) + summariseResult (X_eval_Scotland_subset, y_eval_Scotland_subset, model) )       \n",
    "        summary_result_val_subset.append((str(modelname), target_outcome, classratio, ) + summariseResult (X_val_subset, y_val_subset, model) )       \n",
    "\n",
    "\n",
    "summary_result_eval_subset = pd.DataFrame(summary_result_eval_subset, columns=cols)\n",
    "summary_result_eval_subset['model_num'] = summary_result_eval_subset.index\n",
    "\n",
    "summary_result_Wales_subset = pd.DataFrame(summary_result_Wales_subset, columns=cols)\n",
    "summary_result_Wales_subset['model_num'] = summary_result_Wales_subset.index\n",
    "\n",
    "summary_result_Scotland_subset = pd.DataFrame(summary_result_Scotland_subset, columns=cols)\n",
    "summary_result_Scotland_subset['model_num'] = summary_result_Scotland_subset.index\n",
    "\n",
    "summary_result_val_subset = pd.DataFrame(summary_result_val_subset, columns=cols)\n",
    "summary_result_val_subset['model_num'] = summary_result_val_subset.index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e665a28-683f-468b-b87a-c16ed39aab3f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "summary_result_val_subset['set'] = 'val'\n",
    "summary_result_eval_subset['set'] = 'eval'\n",
    "summary_result_Wales_subset['set'] = 'Wales'\n",
    "summary_result_Scotland_subset['set'] = 'Scotland'\n",
    "\n",
    "combine_subset = pd.concat([summary_result_val_subset, summary_result_eval_subset, \n",
    "                     summary_result_Wales_subset, summary_result_Scotland_subset,\n",
    "                    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0db5a6de-3ce1-44d0-8d35-abf3ea6b3c10",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = combine_subset\n",
    "# data = combine[combine.set!='Training Set']\n",
    "bar = sns.catplot(x = 'model_name',       # x variable name\n",
    "            y = 'auc',       # y variable name            \n",
    "            data=data,\n",
    "            kind = \"bar\",\n",
    "            hue = 'set',\n",
    "            # hue_order=['10-fold CV', 'Evaluation Set', 'Wales', 'Scotland'],\n",
    "            height=5,\n",
    "            row='outcome',\n",
    "            aspect=3,\n",
    "            errorbar = None,)\n",
    "\n",
    "for items in bar.axes:\n",
    "    for ax in items:\n",
    "        for p in ax.patches:\n",
    "            ax.text(p.get_x() + 0.01, \n",
    "                p.get_height() * 1.005, \n",
    "                '{0:.4f}'.format(p.get_height()), \n",
    "                color='black', rotation=20, fontsize=8)\n",
    "\n",
    "ax.set_ylim(0.55, 0.76)\n",
    "# ax.set_ylabel('AUC Score', fontsize=13)\n",
    "ax.set_xlabel('Method', fontsize=13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2cda8ec-c791-45ef-9b99-8314b15d1947",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "best_model_dt = pickle.load(open('../Models_subsetBTS/12months/DT0.sav', 'rb'))\n",
    "\n",
    "# pd.DataFrame([best_model3.feature_importances_], columns=X.columns).T.sort_values(0, ascending=False)\n",
    "sorted_idx = best_model_dt.feature_importances_.argsort()\n",
    "plt.figure(figsize=(3,4))\n",
    "plt.barh(X_subset.columns[sorted_idx][-10:], best_model_dt.feature_importances_[sorted_idx][-10:])\n",
    "plt.xlabel(\"Decision Tree Feature Importance\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f35ab2e-d534-4eeb-8a58-48e17043e650",
   "metadata": {},
   "source": [
    "# Novelty detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e56f9167-0acf-40f7-9871-2d889eebb2b4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.covariance import EllipticEnvelope\n",
    "from sklearn.ensemble import IsolationForest\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a85a581c-26c9-4cc2-bfc6-77cc2372de09",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def summariseResultNovelty (testX, testY, model, modelname):\n",
    "    if modelname == 'Gaussian Mixture':\n",
    "        preds = model.predict_proba(testX)[:,1]\n",
    "        aucscore = roc_auc_score(testY, preds)\n",
    "    else:\n",
    "        # scaller = MinMaxScaler()\n",
    "        # preds = scaller.fit_transform(model.decision_function(testX).reshape(-1, 1))[:,0]\n",
    "        preds = model.predict(testX)\n",
    "        preds = [0 if x == 1 else 1 for x in preds]\n",
    "        fpr, tpr, thresholds = roc_curve(testY, preds, pos_label=1)\n",
    "        aucscore = auc(fpr, tpr)\n",
    "    \n",
    "    auprc = average_precision_score(testY, preds)\n",
    "    # plot_confusion_matrix(model, testX, testY, cmap='viridis')  \n",
    "    return np.round(aucscore,4), np.round(auprc,4)\n",
    "    # return np.round(acc,4), np.round(specificity,4), np.round(sensitivity,4), np.round(aucscore,4), np.round(auprc,4), np.round(balanceacc,4), np.round(f1score,4), np.round(ppv,4), np.round(npv,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ce0b054-653d-41cf-b9d0-254a6a4780b2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "contamination = y.value_counts()[1]/y.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9760cb5c-d40e-4b3f-a1a9-001e3dec3bb2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ignore, use = train_test_split(trainingData, stratify=trainingData['12months'], test_size=.2)\n",
    "print(use.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "455262d0-b5fc-4403-bc3a-d23b6e37d01a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f6a636b-772c-4e99-a360-468906747438",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "#hyperparameter search\n",
    "from skopt import BayesSearchCV\n",
    "from skopt.space import Real, Integer, Categorical\n",
    "from skopt.utils import use_named_args\n",
    "from skopt import gp_minimize\n",
    "\n",
    "#Bayesiain continuous search\n",
    "\n",
    "\n",
    "X = use[features_columns]\n",
    "cv = StratifiedKFold(n_splits=3)\n",
    "n_calls = 10\n",
    "n_jobs = 10\n",
    "\n",
    "output = []\n",
    "\n",
    "for target_outcome in target_outcomes:\n",
    "    print('######################################################################################################')\n",
    "    print(target_outcome)\n",
    "    y = use[target_outcome]\n",
    "    scale_pos_ratio = y.value_counts()[0]/y.value_counts()[1]\n",
    "    \n",
    "#     if target_outcome == 'outcome_combined_24months':   \n",
    "#   ##############################################################################\n",
    "    print('#IF')\n",
    "    IF = IsolationForest(contamination=contamination, random_state=1234)\n",
    "    IF_params = [Integer(100, 500, \"uniform\", name='n_estimators'),\n",
    "                 Categorical([True, False], name = 'bootstrap')]\n",
    "    \n",
    "    @use_named_args(IF_params)\n",
    "    def IF_objective(**params):\n",
    "        IF.set_params(**params)\n",
    "\n",
    "        return 1-np.mean(cross_val_score(IF, X.values, y.values, cv=cv,\n",
    "                                        scoring=make_scorer(roc_auc_score)))\n",
    "\n",
    "    res_gp_IF = gp_minimize(IF_objective, IF_params, n_calls=n_calls, random_state=1234, verbose=3, n_jobs=n_jobs)\n",
    "    output.append([target_outcome, 'IF', 1-res_gp_IF.fun, res_gp_IF.x])\n",
    "    \n",
    "    GM = GaussianMixture(n_components=2, random_state=1234)\n",
    "    GM_params = [Categorical(['liblinear', 'newton-cholesky'], name = 'solver'),\n",
    "                 Real(0.1, 10, 'log-uniform', name='C'), \n",
    "                 Integer(50, 200, 'uniform', name='max_iter')]\n",
    "\n",
    "    \n",
    "    ########################################################################################\n",
    "    print('#EE')\n",
    "    EE = EllipticEnvelope(contamination=contamination, random_state=1234)\n",
    "    \n",
    "    EE_params = [Categorical([True, False], name = 'assume_centered')]\n",
    "    \n",
    "    @use_named_args(EE_params)\n",
    "    def EE_objective(**params):\n",
    "        EE.set_params(**params)\n",
    "\n",
    "        return 1-np.mean(cross_val_score(EE, X.values, y.values, cv=cv,\n",
    "                                        scoring=make_scorer(roc_auc_score)))\n",
    "\n",
    "    res_gp_EE = gp_minimize(EE_objective, EE_params, n_calls=n_calls, random_state=1234, verbose=3, n_jobs=n_jobs)\n",
    "    output.append([target_outcome, 'EE', 1-res_gp_EE.fun, res_gp_EE.x])\n",
    "\n",
    "########################################################################################\n",
    "\n",
    "    print('#GM')\n",
    "    GM = GaussianMixture(random_state=1234)\n",
    "    GM_params = [Categorical(['full', 'tied', 'diag', 'spherical'], name = 'covariance_type'),\n",
    "                 Categorical(['kmeans', 'random'], name = 'init_params'),\n",
    "                 Integer(50, 200, 'uniform', name='max_iter'),\n",
    "                 Integer(1, 3, 'uniform', name='n_components')]\n",
    "\n",
    "    @use_named_args(GM_params)\n",
    "    def GM_objective(**params):\n",
    "        GM.set_params(**params)\n",
    "\n",
    "        return 1-np.mean(cross_val_score(GM, X.values, y.values, cv=cv,\n",
    "                                        scoring=make_scorer(roc_auc_score)))\n",
    "\n",
    "    res_gp_GM = gp_minimize(GM_objective, GM_params, n_calls=n_calls, random_state=1234, verbose=3, n_jobs=n_jobs)\n",
    "    output.append([target_outcome, 'GM', 1-res_gp_GM.fun, res_gp_GM.x])\n",
    "    \n",
    "    \n",
    "\n",
    "########################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9331db5b-7879-4db6-a9b7-523748ccbb33",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(output, columns=['outcome', 'model', 'best_score', 'best_param']).to_csv('../Models/BS_novelty.csv', index = False, index_label=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28ba0d6a-8e5d-4627-8441-6f18a58a216f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(output, columns=['outcome', 'model', 'best_score', 'best_param'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0842fb14-2323-48bb-809f-cc3e469ae257",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "params_dict = pd.read_csv('../Models/BS_novelty.csv')\n",
    "def process_params(param_items, best_param):\n",
    "    a = eval(param_items)\n",
    "    b = eval(best_param)\n",
    "    c = {}\n",
    "    for key, value in zip(a,b):\n",
    "        c[key] = value\n",
    "    return c\n",
    "\n",
    "params_dict['params'] = params_dict.apply(lambda x: process_params(x.param_items, x.best_param), axis=1)\n",
    "params_dict.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c466775e-813e-42b4-8790-715fda75ff54",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def novelty_models(modelname, target_outcome, params, contamination):\n",
    "    if modelname == 'Isolation Forest':\n",
    "        params = params[(params.model == 'IF')&(params.outcome == target_outcome)]['params'].tolist()[0]\n",
    "        model = IsolationForest(n_estimators=params['n_estimators'], bootstrap = params['bootstrap'], contamination=contamination, random_state=1234)\n",
    "    elif modelname=='Elliptic Envelope':\n",
    "        params = params[(params.model == 'EE')&(params.outcome == target_outcome)]['params'].tolist()[0]\n",
    "        model = EllipticEnvelope(assume_centered=params['assume_centered'], contamination=contamination, random_state=1234)\n",
    "    elif modelname=='Gaussian Mixture':\n",
    "        params = params[(params.model == 'GM')&(params.outcome == target_outcome)]['params'].tolist()[0]\n",
    "        model = GaussianMixture(covariance_type=params['covariance_type'], init_params=params['init_params'], max_iter=params['max_iter'], n_components=2, random_state=1234)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0236fe9-88da-42d3-9048-cd01571bf012",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "modelnames = ['Isolation Forest', 'Elliptic Envelope', 'Gaussian Mixture']\n",
    "summary_result_internal_eval = []\n",
    "summary_result_eval = []\n",
    "summary_result_eval_Wales = []\n",
    "summary_result_eval_Scotland = []\n",
    "for target_outcome in target_outcomes:\n",
    "    y = trainingData[target_outcome]\n",
    "    y_val = validationData[target_outcome]\n",
    "    y = pd.concat([y, y_val])\n",
    "    y_internaleval = internalEvaluationData[target_outcome]\n",
    "    y_eval = evaluationData[target_outcome]\n",
    "    y_eval_Wales = evaluationDataWales[target_outcome]\n",
    "    y_eval_Scotland = evaluationDataScotland[target_outcome]\n",
    "    contamination = y.value_counts()[1]/y.shape[0]\n",
    "    for modelname in modelnames:\n",
    "        model = novelty_models(modelname, target_outcome, params_dict, contamination)\n",
    "        model.fit(X)\n",
    "        summary_result_internal_eval.append((str(modelname), target_outcome, ) + summariseResultNovelty (X_internaleval, y_internaleval.values, model, modelname))\n",
    "        summary_result_eval.append((str(modelname), target_outcome, ) + summariseResultNovelty (X_eval, y_eval.values, model, modelname))\n",
    "        summary_result_eval_Wales.append((str(modelname), target_outcome, ) + summariseResultNovelty (X_eval_Wales, y_eval_Wales.values, model, modelname))\n",
    "        summary_result_eval_Scotland.append((str(modelname), target_outcome, ) + summariseResultNovelty (X_eval_Scotland, y_eval_Scotland.values, model, modelname))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dca7a1c-9cdb-4ff7-a231-47af70d8b949",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "summary_result_eval = pd.DataFrame(summary_result_eval, columns=['model', 'outcome', 'AUC', 'AUPRC'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4f9c510-b538-42b0-9838-0944574b25d9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "g = sns.FacetGrid(summary_result_eval, col='outcome', col_wrap=2, height=3, aspect=1.6, ylim=(0.4, 0.7))\n",
    "g.map(sns.barplot, 'model', 'AUC', order=summary_result_eval.model.unique()).add_legend()\n",
    "\n",
    "for ax in g.axes:\n",
    "    for p in ax.patches:\n",
    "             ax.annotate(\"%.4f\" % p.get_height(), (p.get_x() + p.get_width() / 2., p.get_height()),\n",
    "                 ha='center', va='center', fontsize=8, color='black', xytext=(0, 5),\n",
    "                 textcoords='offset points')\n",
    "    ax.set_ylabel('AUC Score', fontsize=8)\n",
    "    ax.set_xlabel('Method', fontsize=11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ab0ffa1-6f32-4628-b226-e3214affb11f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = GaussianMixture(n_components=2, random_state=1234)\n",
    "model.fit(X)\n",
    "preds = model.predict(X_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4a2358b-c2c9-418f-943a-f3e345875a28",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "np.count_nonzero(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3827a28b-bccf-4521-9cef-c690882367cd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "confusion_matrix(y_eval, preds)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
