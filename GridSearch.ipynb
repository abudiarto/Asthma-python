{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3cf617ae-7cd6-4168-9b2a-c61a35fcaf7c",
   "metadata": {},
   "source": [
    "# ANALYSIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a6f7287c-5c7e-4d25-9085-f3971b3d5784",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#uncomment this below code to install imblearn package\n",
    "# !pip install imbalanced-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5bdbffb2-b2a4-45fb-b395-13d2cd7513a3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !pip install scikit-optimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c95c2128",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "\n",
    "#statistics\n",
    "from scipy.stats import chi2_contingency, ttest_ind\n",
    "\n",
    "import cudf #gpu-powered DataFrame (Pandas alternative)\n",
    "\n",
    "#imbalance handling\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler, RepeatedEditedNearestNeighbours\n",
    "from imblearn.pipeline import Pipeline\n",
    "\n",
    "#preprocessing\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import OrdinalEncoder, OneHotEncoder, LabelEncoder, MinMaxScaler, StandardScaler\n",
    "\n",
    "#hyperparameter search\n",
    "from skopt import BayesSearchCV\n",
    "from skopt.space import Real, Integer, Categorical\n",
    "from skopt.utils import use_named_args\n",
    "from skopt import gp_minimize\n",
    "\n",
    "#internal validation\n",
    "from sklearn.model_selection import StratifiedKFold, KFold, RepeatedStratifiedKFold, cross_val_score, GridSearchCV, PredefinedSplit, RandomizedSearchCV\n",
    "\n",
    "\n",
    "#performance metrices\n",
    "from sklearn.metrics import make_scorer, confusion_matrix, classification_report, f1_score, balanced_accuracy_score, r2_score, auc, average_precision_score, roc_auc_score, recall_score, roc_curve, accuracy_score\n",
    "\n",
    "#Models selection\n",
    "from sklearn.naive_bayes import GaussianNB, ComplementNB\n",
    "from sklearn.linear_model import LogisticRegression, ElasticNet\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import xgboost as xgb\n",
    "from cuml.svm import SVC #gpu-powered SVM\n",
    "\n",
    "\n",
    "#save and load trained model\n",
    "import pickle\n",
    "\n",
    "#visualisation\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "11624789",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_12328/3164845275.py:2: DtypeWarning: Columns (26,27,29,30,33,34,68,72) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  features = pd.read_csv(\"../FinalData/cleaned_features_11072023.csv\")\n"
     ]
    }
   ],
   "source": [
    "# Data loader\n",
    "features = pd.read_csv(\"../FinalData/cleaned_features_11072023.csv\")\n",
    "outcomes = pd.read_csv(\"../FinalData/cleaned_outcomes_11072023.csv\")\n",
    "features = features[features.columns[1:]]\n",
    "# outcomes = outcomes[outcomes.columns[1:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c3d4d97c-6eff-4df9-b769-8fcde18f5fcf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(577962, 87)\n",
      "(577962, 15)\n"
     ]
    }
   ],
   "source": [
    "print(features.shape)\n",
    "print(outcomes.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eb99babd-f83f-4f3f-b9e3-1934a6f6ba12",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['patid', 'practice_id', 'sex', 'age', 'BMI', 'weight', 'height',\n",
       "       'ethnicity', 'ethnic_group', 'smokingStatus', 'CharlsonScore',\n",
       "       'count_rhinitis', 'count_cardiovascular', 'count_heartfailure',\n",
       "       'count_psoriasis', 'count_anaphylaxis', 'count_diabetes', 'count_ihd',\n",
       "       'count_anxiety', 'count_eczema', 'count_nasalpolyps',\n",
       "       'count_paracetamol', 'count_nsaids', 'count_betablocker', 'id',\n",
       "       'event_date', 'recorded_date', 'visit_id', 'code_id', 'snomed_id',\n",
       "       'numeric_1', 'numeric_2', 'created_datetime', 'updated_datetime',\n",
       "       'PEFStatus', 'EosinophilLevel', 'BTS_step', 'average_daily_dose_ICS',\n",
       "       'prescribed_daily_dose_ICS', 'ICS_medication_possesion_ratio',\n",
       "       'DeviceType', 'Spacer', 'numOCS', 'PriorEducation', 'numPCS',\n",
       "       'numPCSAsthma', 'numAntibioticsEvents', 'numAntibioticswithLRTI',\n",
       "       'numOCSEvents', 'numOCSwithLRTI', 'numAsthmaAttacks',\n",
       "       'numAcuteRespEvents', 'numHospEvents', 'postcode_district',\n",
       "       'imd_decile', 'Country', 'County', 'LocalAuthority',\n",
       "       'OutputAreaClassification', 'cat_BMI', 'cat_age',\n",
       "       'cat_average_daily_dose_ICS', 'cat_prescribed_daily_dose_ICS',\n",
       "       'cat_ICS_medication_possesion_ratio', 'cat_numOCS', 'cat_numOCSEvents',\n",
       "       'cat_numOCSwithLRTI', 'cat_numAcuteRespEvents',\n",
       "       'cat_numAntibioticsEvents', 'cat_numAntibioticswithLRTI',\n",
       "       'cat_numAsthmaAttacks', 'cat_numHospEvents', 'cat_numPCS',\n",
       "       'cat_numPCSAsthma', 'rhinitis', 'cardiovascular', 'heartfailure',\n",
       "       'psoriasis', 'anaphylaxis', 'diabetes', 'ihd', 'anxiety', 'eczema',\n",
       "       'nasalpolyps', 'paracetamol', 'nsaids', 'betablocker'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5754f4e6-c1eb-48b6-8cd3-3864ee8f639e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patid</th>\n",
       "      <th>practice_id</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>BMI</th>\n",
       "      <th>weight</th>\n",
       "      <th>height</th>\n",
       "      <th>ethnicity</th>\n",
       "      <th>ethnic_group</th>\n",
       "      <th>smokingStatus</th>\n",
       "      <th>...</th>\n",
       "      <th>psoriasis</th>\n",
       "      <th>anaphylaxis</th>\n",
       "      <th>diabetes</th>\n",
       "      <th>ihd</th>\n",
       "      <th>anxiety</th>\n",
       "      <th>eczema</th>\n",
       "      <th>nasalpolyps</th>\n",
       "      <th>paracetamol</th>\n",
       "      <th>nsaids</th>\n",
       "      <th>betablocker</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>43231452</td>\n",
       "      <td>39</td>\n",
       "      <td>0.0</td>\n",
       "      <td>48</td>\n",
       "      <td>26.609713</td>\n",
       "      <td>76.0</td>\n",
       "      <td>1.6900</td>\n",
       "      <td>not_recorded</td>\n",
       "      <td>not_recorded</td>\n",
       "      <td>Active Smoker</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>43206365</td>\n",
       "      <td>39</td>\n",
       "      <td>1.0</td>\n",
       "      <td>58</td>\n",
       "      <td>23.946360</td>\n",
       "      <td>72.5</td>\n",
       "      <td>1.7400</td>\n",
       "      <td>not_recorded</td>\n",
       "      <td>not_recorded</td>\n",
       "      <td>Former Smoker</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>43203606</td>\n",
       "      <td>559</td>\n",
       "      <td>0.0</td>\n",
       "      <td>51</td>\n",
       "      <td>17.104513</td>\n",
       "      <td>39.0</td>\n",
       "      <td>1.5100</td>\n",
       "      <td>not_recorded</td>\n",
       "      <td>not_recorded</td>\n",
       "      <td>Active Smoker</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>43117348</td>\n",
       "      <td>502</td>\n",
       "      <td>0.0</td>\n",
       "      <td>69</td>\n",
       "      <td>35.303241</td>\n",
       "      <td>74.0</td>\n",
       "      <td>1.4478</td>\n",
       "      <td>not_recorded</td>\n",
       "      <td>not_recorded</td>\n",
       "      <td>Former Smoker</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>43289035</td>\n",
       "      <td>593</td>\n",
       "      <td>0.0</td>\n",
       "      <td>49</td>\n",
       "      <td>31.217482</td>\n",
       "      <td>75.0</td>\n",
       "      <td>1.5500</td>\n",
       "      <td>White British</td>\n",
       "      <td>White - ethnic group</td>\n",
       "      <td>Active Smoker</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 87 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      patid  practice_id  sex  age        BMI  weight  height      ethnicity  \\\n",
       "0  43231452           39  0.0   48  26.609713    76.0  1.6900   not_recorded   \n",
       "1  43206365           39  1.0   58  23.946360    72.5  1.7400   not_recorded   \n",
       "2  43203606          559  0.0   51  17.104513    39.0  1.5100   not_recorded   \n",
       "3  43117348          502  0.0   69  35.303241    74.0  1.4478   not_recorded   \n",
       "4  43289035          593  0.0   49  31.217482    75.0  1.5500  White British   \n",
       "\n",
       "           ethnic_group  smokingStatus  ...  psoriasis  anaphylaxis  diabetes  \\\n",
       "0          not_recorded  Active Smoker  ...          0            0         0   \n",
       "1          not_recorded  Former Smoker  ...          0            0         0   \n",
       "2          not_recorded  Active Smoker  ...          0            0         0   \n",
       "3          not_recorded  Former Smoker  ...          1            0         0   \n",
       "4  White - ethnic group  Active Smoker  ...          0            0         0   \n",
       "\n",
       "   ihd  anxiety  eczema  nasalpolyps  paracetamol  nsaids  betablocker  \n",
       "0    0        0       0            0            0       0            0  \n",
       "1    0        1       0            0            0       0            0  \n",
       "2    0        0       1            0            0       0            0  \n",
       "3    0        0       1            0            0       0            0  \n",
       "4    0        0       1            0            0       0            0  \n",
       "\n",
       "[5 rows x 87 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "03d70236-7158-4812-8a5b-d5d9890a94e4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patid</th>\n",
       "      <th>outcome_3months</th>\n",
       "      <th>outcome_6months</th>\n",
       "      <th>outcome_9months</th>\n",
       "      <th>outcome_12months</th>\n",
       "      <th>outcome_15months</th>\n",
       "      <th>outcome_18months</th>\n",
       "      <th>outcome_21months</th>\n",
       "      <th>outcome_24months</th>\n",
       "      <th>outcome_combined_6months</th>\n",
       "      <th>outcome_combined_9months</th>\n",
       "      <th>outcome_combined_12months</th>\n",
       "      <th>outcome_combined_15months</th>\n",
       "      <th>outcome_combined_18months</th>\n",
       "      <th>outcome_combined_24months</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>43231452</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>43206365</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>43203606</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>43117348</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>43289035</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      patid  outcome_3months  outcome_6months  outcome_9months  \\\n",
       "0  43231452                0                0                0   \n",
       "1  43206365                0                0                0   \n",
       "2  43203606                0                0                0   \n",
       "3  43117348                0                0                0   \n",
       "4  43289035                0                0                0   \n",
       "\n",
       "   outcome_12months  outcome_15months  outcome_18months  outcome_21months  \\\n",
       "0                 0                 0                 0                 0   \n",
       "1                 0                 0                 0                 0   \n",
       "2                 0                 0                 0                 0   \n",
       "3                 0                 0                 0                 0   \n",
       "4                 0                 0                 0                 0   \n",
       "\n",
       "   outcome_24months  outcome_combined_6months  outcome_combined_9months  \\\n",
       "0                 0                         0                         0   \n",
       "1                 0                         0                         0   \n",
       "2                 0                         0                         0   \n",
       "3                 0                         0                         0   \n",
       "4                 0                         0                         0   \n",
       "\n",
       "   outcome_combined_12months  outcome_combined_15months  \\\n",
       "0                          0                          0   \n",
       "1                          0                          0   \n",
       "2                          0                          0   \n",
       "3                          0                          0   \n",
       "4                          0                          0   \n",
       "\n",
       "   outcome_combined_18months  outcome_combined_24months  \n",
       "0                          0                          0  \n",
       "1                          0                          0  \n",
       "2                          0                          0  \n",
       "3                          0                          0  \n",
       "4                          0                          0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outcomes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "862ee9fb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original data shape:  (577962, 89)\n"
     ]
    }
   ],
   "source": [
    "masterData = features.merge(outcomes, how = 'left', left_on='patid', right_on='patid') #join table\n",
    "# masterData = masterData.dropna() #NAs from Country\n",
    "masterData = masterData.reset_index(drop=True)\n",
    "exclude_columns = ['weight', 'height', 'id', 'event_date', 'recorded_date', 'visit_id', 'code_id', 'snomed_id',\n",
    "       'numeric_1', 'numeric_2', 'created_datetime', 'updated_datetime',]\n",
    "masterData = masterData.loc[:,~masterData.columns.isin(exclude_columns)]\n",
    "print('original data shape: ', masterData.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8e7a7bee-e74a-4c9f-87ff-0b557c67c82c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "patid                                 0\n",
       "practice_id                           0\n",
       "sex                                   0\n",
       "age                                   0\n",
       "BMI                                   0\n",
       "ethnicity                             0\n",
       "ethnic_group                          0\n",
       "smokingStatus                         0\n",
       "CharlsonScore                         0\n",
       "count_rhinitis                        0\n",
       "count_cardiovascular                  0\n",
       "count_heartfailure                    0\n",
       "count_psoriasis                       0\n",
       "count_anaphylaxis                     0\n",
       "count_diabetes                        0\n",
       "count_ihd                             0\n",
       "count_anxiety                         0\n",
       "count_eczema                          0\n",
       "count_nasalpolyps                     0\n",
       "count_paracetamol                     0\n",
       "count_nsaids                          0\n",
       "count_betablocker                     0\n",
       "PEFStatus                             0\n",
       "EosinophilLevel                       0\n",
       "BTS_step                              0\n",
       "average_daily_dose_ICS                0\n",
       "prescribed_daily_dose_ICS             0\n",
       "ICS_medication_possesion_ratio        0\n",
       "DeviceType                            0\n",
       "Spacer                                0\n",
       "numOCS                                0\n",
       "PriorEducation                        0\n",
       "numPCS                                0\n",
       "numPCSAsthma                          0\n",
       "numAntibioticsEvents                  0\n",
       "numAntibioticswithLRTI                0\n",
       "numOCSEvents                          0\n",
       "numOCSwithLRTI                        0\n",
       "numAsthmaAttacks                      0\n",
       "numAcuteRespEvents                    0\n",
       "numHospEvents                         0\n",
       "postcode_district                     0\n",
       "imd_decile                            0\n",
       "Country                               0\n",
       "County                                0\n",
       "LocalAuthority                        0\n",
       "OutputAreaClassification              0\n",
       "cat_BMI                               0\n",
       "cat_age                               0\n",
       "cat_average_daily_dose_ICS            0\n",
       "cat_prescribed_daily_dose_ICS         0\n",
       "cat_ICS_medication_possesion_ratio    0\n",
       "cat_numOCS                            0\n",
       "cat_numOCSEvents                      0\n",
       "cat_numOCSwithLRTI                    0\n",
       "cat_numAcuteRespEvents                0\n",
       "cat_numAntibioticsEvents              0\n",
       "cat_numAntibioticswithLRTI            0\n",
       "cat_numAsthmaAttacks                  0\n",
       "cat_numHospEvents                     0\n",
       "cat_numPCS                            0\n",
       "cat_numPCSAsthma                      0\n",
       "rhinitis                              0\n",
       "cardiovascular                        0\n",
       "heartfailure                          0\n",
       "psoriasis                             0\n",
       "anaphylaxis                           0\n",
       "diabetes                              0\n",
       "ihd                                   0\n",
       "anxiety                               0\n",
       "eczema                                0\n",
       "nasalpolyps                           0\n",
       "paracetamol                           0\n",
       "nsaids                                0\n",
       "betablocker                           0\n",
       "outcome_3months                       0\n",
       "outcome_6months                       0\n",
       "outcome_9months                       0\n",
       "outcome_12months                      0\n",
       "outcome_15months                      0\n",
       "outcome_18months                      0\n",
       "outcome_21months                      0\n",
       "outcome_24months                      0\n",
       "outcome_combined_6months              0\n",
       "outcome_combined_9months              0\n",
       "outcome_combined_12months             0\n",
       "outcome_combined_15months             0\n",
       "outcome_combined_18months             0\n",
       "outcome_combined_24months             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.options.display.max_rows = 287\n",
    "masterData.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ecdc7fd9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 months -> 1 :  35.63\n",
      "6 months -> 1 :  23.46\n",
      "9 months -> 1 :  18.06\n",
      "12 months -> 1 :  13.49\n",
      "15 months -> 1 :  10.92\n",
      "18 months -> 1 :  9.91\n",
      "24 months -> 1 :  8.85\n"
     ]
    }
   ],
   "source": [
    "#Positive vs negative class ratio\n",
    "\n",
    "print('3 months -> 1 : ', round(masterData.outcome_3months.value_counts()[0]/masterData.outcome_3months.value_counts()[1],2))\n",
    "print('6 months -> 1 : ', round(masterData.outcome_combined_6months.value_counts()[0]/masterData.outcome_combined_6months.value_counts()[1],2))\n",
    "print('9 months -> 1 : ', round(masterData.outcome_combined_9months.value_counts()[0]/masterData.outcome_combined_9months.value_counts()[1],2))\n",
    "print('12 months -> 1 : ', round(masterData.outcome_combined_12months.value_counts()[0]/masterData.outcome_combined_12months.value_counts()[1],2))\n",
    "print('15 months -> 1 : ', round(masterData.outcome_combined_15months.value_counts()[0]/masterData.outcome_combined_15months.value_counts()[1],2))\n",
    "print('18 months -> 1 : ', round(masterData.outcome_combined_18months.value_counts()[0]/masterData.outcome_combined_18months.value_counts()[1],2))\n",
    "print('24 months -> 1 : ', round(masterData.outcome_combined_24months.value_counts()[0]/masterData.outcome_combined_24months.value_counts()[1],2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "346971ef",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 months ->  2.73 %\n",
      "6 months ->  4.09 %\n",
      "9 months ->  5.25 %\n",
      "12 months ->  6.9 %\n",
      "15 months ->  8.39 %\n",
      "18 months ->  9.16 %\n",
      "24 months ->  10.15 %\n"
     ]
    }
   ],
   "source": [
    "#Proportion of asthma attack in each outcome\n",
    "\n",
    "print('3 months -> ', round(masterData.outcome_3months.value_counts()[1]/len(masterData)*100,2), '%')\n",
    "print('6 months -> ', round(masterData.outcome_combined_6months.value_counts()[1]/len(masterData)*100,2), '%')\n",
    "print('9 months -> ', round(masterData.outcome_combined_9months.value_counts()[1]/len(masterData)*100,2), '%')\n",
    "print('12 months -> ', round(masterData.outcome_combined_12months.value_counts()[1]/len(masterData)*100,2), '%')\n",
    "print('15 months -> ', round(masterData.outcome_combined_15months.value_counts()[1]/len(masterData)*100,2), '%')\n",
    "print('18 months -> ', round(masterData.outcome_combined_18months.value_counts()[1]/len(masterData)*100,2), '%')\n",
    "print('24 months -> ', round(masterData.outcome_combined_24months.value_counts()[1]/len(masterData)*100,2), '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "48e347d6-3a9f-4008-b9db-d73475693da6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape for scenario 1 (577962, 89)\n"
     ]
    }
   ],
   "source": [
    "#Data scenario\n",
    "# 1: all data without ethnicity variable\n",
    "# 2: all data with ethnicity variable (include all missing values in ethnicity as separate group)\n",
    "# 3: filter data based on ethnicity (exclude missing values)\n",
    "\n",
    "scenario = 1 #change it based on the scenario\n",
    "\n",
    "if scenario == 1:\n",
    "    #include all data\n",
    "    allData = masterData\n",
    "    \n",
    "elif scenario == 2:\n",
    "    #Exclude ethnic column\n",
    "    allData = masterData.drop('ethnic_group', axis=1)\n",
    "    \n",
    "elif scenario == 3:\n",
    "    #exclude missing values for ethnic variable\n",
    "    allData = masterData[masterData.ethnic_group!='not_recorded']\n",
    "    \n",
    "allData = allData.reset_index(drop=True)\n",
    "print('Data shape for scenario', str(scenario), allData.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2b2ddc20-4158-4c1b-93df-4043c7c16520",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape: (555836, 88)\n",
      "Evaluation data shape:  (22126, 88)\n"
     ]
    }
   ],
   "source": [
    "#Split data into training and evaluation set based on the country. Include only 18+ patients.\n",
    "\n",
    "trainingData = allData[(allData.Country == 'England') & (allData.age>=18)]\n",
    "evaluationData = allData[((allData.Country == 'Scotland') | (allData.Country == 'Wales')) & (allData.age>=18)] #used for internal validation\n",
    "\n",
    "#remove country variable\n",
    "trainingData = trainingData.drop('Country', axis=1)\n",
    "evaluationData = evaluationData.drop('Country', axis=1)\n",
    "\n",
    "trainingData = trainingData.reset_index(drop=True)\n",
    "evaluationData = evaluationData.reset_index(drop=True)\n",
    "\n",
    "print('Training data shape:', trainingData.shape)\n",
    "print('Evaluation data shape: ', evaluationData.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4dab986e-f533-41c7-810c-442127311122",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape after encoding:  (555836, 113)\n"
     ]
    }
   ],
   "source": [
    "#encode categorical data\n",
    "\n",
    "cat_vars = ['PEFStatus','EosinophilLevel']\n",
    "onehot_vars = ['ethnic_group','smokingStatus', 'DeviceType', 'cat_BMI', 'imd_decile']\n",
    "data_categorical = trainingData[cat_vars]\n",
    "data_onehot = trainingData[onehot_vars]\n",
    "\n",
    "#ordinal encoder\n",
    "encoder = OrdinalEncoder(categories=[['not_recorded','less than 60', '60-80', 'more than 80'], ['unknown', 'normal', 'high']]).set_output(transform=\"pandas\")\n",
    "data_encoded = encoder.fit_transform(data_categorical)\n",
    "pickle.dump(encoder, open('../Models/cat_encoder.pkl', 'wb'))\n",
    "    \n",
    "#one hot encoder\n",
    "onehot_encoder = OneHotEncoder(sparse_output=False).set_output(transform=\"pandas\")\n",
    "onehot_encoded = onehot_encoder.fit_transform(data_onehot)\n",
    "pickle.dump(onehot_encoder, open('../Models/onehot_encoder.pkl', 'wb'))\n",
    "\n",
    "trainingData = pd.concat([trainingData.drop(cat_vars, axis=1), data_encoded], axis=1)\n",
    "trainingData = pd.concat([trainingData.drop(onehot_vars, axis=1), onehot_encoded], axis=1)\n",
    "\n",
    "print('Data shape after encoding: ', trainingData.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fd1a28e0-3029-4ced-a4a2-16195934702a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape after scaling:  (555836, 113)\n"
     ]
    }
   ],
   "source": [
    "#Data normalisation for continous variable into 0-1 range\n",
    "\n",
    "\n",
    "continuous_vars = ['age', 'CharlsonScore', 'average_daily_dose_ICS', 'prescribed_daily_dose_ICS', 'ICS_medication_possesion_ratio', \n",
    "                   'numOCS', 'numPCS', 'numPCSAsthma', 'numAntibioticsEvents', 'numAntibioticswithLRTI', 'numOCSEvents', 'numOCSwithLRTI', \n",
    "                   'numAsthmaAttacks', 'numAcuteRespEvents', 'numHospEvents']\n",
    "\n",
    "# define scaler\n",
    "scaler = StandardScaler()\n",
    "data_scaled = scaler.fit_transform(trainingData[continuous_vars])\n",
    "pickle.dump(scaler, open('../Models/cont_scaler.pkl', 'wb'))\n",
    "\n",
    "\n",
    "data_scaled = pd.DataFrame(data_scaled, columns=scaler.get_feature_names_out())\n",
    "trainingData = pd.concat([trainingData.drop(continuous_vars, axis=1), data_scaled], axis=1)\n",
    "\n",
    "print('Data shape after scaling: ', trainingData.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f81e0adc-7a4b-4e28-852c-811c20125656",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features size:  63\n",
      "['sex', 'BTS_step', 'PriorEducation', 'rhinitis', 'cardiovascular', 'heartfailure', 'psoriasis', 'anaphylaxis', 'diabetes', 'ihd', 'anxiety', 'eczema', 'nasalpolyps', 'paracetamol', 'nsaids', 'betablocker', 'PEFStatus', 'EosinophilLevel', 'ethnic_group_Asian - ethnic group', 'ethnic_group_Black - ethnic group', 'ethnic_group_Mixed ethnic census group', 'ethnic_group_Other ethnic group', 'ethnic_group_White - ethnic group', 'ethnic_group_not_recorded', 'smokingStatus_Active Smoker', 'smokingStatus_Former Smoker', 'smokingStatus_Non Smoker', 'DeviceType_BAI', 'DeviceType_DPI', 'DeviceType_NEB', 'DeviceType_pMDI', 'DeviceType_unknown', 'cat_BMI_normal', 'cat_BMI_not recorded', 'cat_BMI_obese', 'cat_BMI_overweight', 'cat_BMI_underweight', 'imd_decile_0', 'imd_decile_1', 'imd_decile_2', 'imd_decile_3', 'imd_decile_4', 'imd_decile_5', 'imd_decile_6', 'imd_decile_7', 'imd_decile_8', 'imd_decile_9', 'imd_decile_10', 'age', 'CharlsonScore', 'average_daily_dose_ICS', 'prescribed_daily_dose_ICS', 'ICS_medication_possesion_ratio', 'numOCS', 'numPCS', 'numPCSAsthma', 'numAntibioticsEvents', 'numAntibioticswithLRTI', 'numOCSEvents', 'numOCSwithLRTI', 'numAsthmaAttacks', 'numAcuteRespEvents', 'numHospEvents']\n"
     ]
    }
   ],
   "source": [
    "#Define feature candidates\n",
    "\n",
    "features_columns = trainingData.columns.to_list()\n",
    "exclude_columns = ['patid', 'practice_id', #identifier\n",
    "                   'BMI', #use the categorical instead\n",
    "                   'ethnicity', #use ethnic_group instead\n",
    "                   'Spacer',  #all zero\n",
    "                   \n",
    "                   'outcome_3months', 'outcome_6months', 'outcome_9months', 'outcome_12months', 'outcome_15months', 'outcome_18months', \n",
    "                   'outcome_21months', 'outcome_24months', 'outcome_combined_6months', 'outcome_combined_9months', 'outcome_combined_12months', \n",
    "                   'outcome_combined_15months', 'outcome_combined_18months', 'outcome_combined_24months', #outcomes variable\n",
    "                   \n",
    "                   'postcode_district', 'County', 'LocalAuthority', 'OutputAreaClassification', #location related variables, use IMD decile only\n",
    "                   \n",
    "                   'cat_age', 'cat_average_daily_dose_ICS', 'cat_prescribed_daily_dose_ICS', 'cat_ICS_medication_possesion_ratio', 'cat_numOCS', 'cat_numOCSEvents', \n",
    "                   'cat_numOCSwithLRTI', 'cat_numAcuteRespEvents', 'cat_numAntibioticsEvents', 'cat_numAntibioticswithLRTI', 'cat_numAsthmaAttacks', 'cat_numHospEvents', \n",
    "                   'cat_numPCS', 'cat_numPCSAsthma', #use continous vars instead\n",
    "                   \n",
    "                   'count_rhinitis', 'count_cardiovascular', 'count_heartfailure',\n",
    "                   'count_psoriasis', 'count_anaphylaxis', 'count_diabetes', 'count_ihd',\n",
    "                   'count_anxiety', 'count_eczema', 'count_nasalpolyps',\n",
    "                   'count_paracetamol', 'count_nsaids', 'count_betablocker', #use binary ones\n",
    "                  ]\n",
    "exclude_columns = exclude_columns + [x for x in features_columns if '_count' in x] #filter out commorbid count variables\n",
    "features_columns = [x for x in features_columns if x not in exclude_columns]\n",
    "print('Features size: ', len(features_columns))\n",
    "print(features_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43d04aff-9853-406e-aae4-c4b7890bfe19",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1483ee06-230b-40f9-8558-09545cbdae54",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#ONE HOT encoding for categorical data\n",
    "\n",
    "# categoricalNonnumericVars = pd.Series(list(set(categoricalNonnumericVars).intersection(set(features_columns)))).tolist() #select only variables within the feature candidate list\n",
    "\n",
    "# # define one hot encoder\n",
    "# categoricalEncoder = OneHotEncoder(sparse=False)\n",
    "\n",
    "# # transform data\n",
    "# result = categoricalEncoder.fit_transform(trainingData[categoricalNonnumericVars]) \n",
    "# result = pd.DataFrame(result, columns=categoricalEncoder.get_feature_names_out())\n",
    "\n",
    "# #save encoder\n",
    "# pickle.dump(categoricalEncoder, open('./models/categoricalEncoder.pkl', 'wb'))\n",
    "\n",
    "# # replace categorical variables in the original data with the one hot version\n",
    "# trainingData = pd.concat([trainingData.loc[:, ~trainingData.columns.isin(categoricalNonnumericVars)],result], axis=1)\n",
    "# print('Data shape after one-hot encoding: ', trainingData.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b24a133-cba6-4246-a8e5-91911d8f4d8e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# #ONE HOT encoding for evaluation dataset\n",
    "\n",
    "# # transform data\n",
    "# result = categoricalEncoder.transform(evaluationData[categoricalNonnumericVars]) \n",
    "# result = pd.DataFrame(result, columns=categoricalEncoder.get_feature_names_out())\n",
    "\n",
    "# # replace categorical variables in the original data with the one hot version\n",
    "# evaluationData = pd.concat([evaluationData.loc[:, ~evaluationData.columns.isin(categoricalNonnumericVars)],result], axis=1)\n",
    "# print('Data shape after one-hot encoding: ', evaluationData.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cad1832-4118-44c9-acdf-da61cefb7a76",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# #Scaling continous variable into 0-1 range for evaluation dataset\n",
    "\n",
    "\n",
    "# # transform data\n",
    "# result = scaler.transform(evaluationData[continuous_vars])\n",
    "# result = pd.DataFrame(result, columns=scaler.get_feature_names_out())\n",
    "\n",
    "# evaluationData = pd.concat([evaluationData.loc[:,~evaluationData.columns.isin(continuous_vars)],result], axis=1)\n",
    "\n",
    "# print('Data shape after scaling: ', evaluationData.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4db59da-1f72-428e-9203-08d62c6d9090",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# #Model evaluation function\n",
    "\n",
    "# def summariseResult (testX, testY, model):\n",
    "#     preds = model.predict(testX)\n",
    "#     tn, fp, fn, tp = confusion_matrix(testY, preds).ravel()\n",
    "#     specificity = tn / (tn+fp)\n",
    "#     sensitivity = tp / (tp+fn)\n",
    "#     ppv = 100*tp/(tp+fp)\n",
    "#     npv = 100*tn/(fn+tn)\n",
    "#     acc = accuracy_score(testY, preds)\n",
    "#     f1score = f1_score(testY, preds, average = 'binary')\n",
    "#     balanceacc = balanced_accuracy_score(testY, preds)\n",
    "#     fpr, tpr, thresholds = roc_curve(testY, preds, pos_label=1)\n",
    "#     aucscore = auc(fpr, tpr)\n",
    "#     # auc = roc_auc_score(testY, preds)\n",
    "#     auprc = average_precision_score(testY, preds)\n",
    "#     # plot_confusion_matrix(model, testX, testY, cmap='viridis')  \n",
    "#     return np.round(acc,4), np.round(specificity,4), np.round(sensitivity,4), np.round(aucscore,4), np.round(auprc,4), np.round(balanceacc,4), np.round(f1score,4), np.round(ppv,4), np.round(npv,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bfef79e-1dce-4010-b0cc-8694c6c79202",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# #Fix model name for visualisation\n",
    "\n",
    "# def modelNameFixer(x):\n",
    "#     if 'liblinear' in x:\n",
    "#         return 'Lasso'\n",
    "#     elif 'GaussianNB' in x:\n",
    "#         return 'GNB'\n",
    "#     elif 'SVC' in x:\n",
    "#         return 'SVC'\n",
    "#     elif 'RandomForest' in x:\n",
    "#         return 'RF'\n",
    "#     elif 'XGB' in x:\n",
    "#         return 'XGBoost'\n",
    "#     elif 'DecisionTree' in x:\n",
    "#         return 'DT'\n",
    "#     else:\n",
    "#         return 'LR'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b28f624-2c79-4f33-bc78-84ba16c78938",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # instantiate the model (using the default parameters)\n",
    "# def build_models (X_train, y_train, params, split_counter):\n",
    "#     models = [] #list to store all the models\n",
    "#     model_counter = 0\n",
    "#     print(\"Building models . . . .\")\n",
    "\n",
    "#     #LR\n",
    "#     lr_model = LogisticRegression(class_weight='balanced', penalty='l2', random_state=1234)\n",
    "#     lr_model.fit(X_train,y_train)\n",
    "#     modelname =str(split_counter) + 'LRModel' \n",
    "#     models.append([modelname, y_train.value_counts()[1]/y_train.value_counts()[0]])\n",
    "#     model_counter+=1\n",
    "#     pickle.dump(lr_model, open('./models/'+ target_outcome + '/'+ modelname + '.sav', 'wb')) \n",
    "#     print(\"LR done\")\n",
    "\n",
    "#     #Lasso\n",
    "#     lasso_model = LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear', random_state=1234) #only the LIBLINEAR and SAGA (added in v0.19) solvers handle the L1 penalty\n",
    "#     lasso_model.fit(X_train, y_train)\n",
    "#     modelname =str(split_counter) + 'LassoModel' \n",
    "#     models.append([modelname, y_train.value_counts()[1]/y_train.value_counts()[0]])\n",
    "#     model_counter+=1\n",
    "#     pickle.dump(lasso_model, open('./models/'+ target_outcome + '/'+ modelname + '.sav', 'wb'))\n",
    "#     print(\"LR done\")\n",
    "\n",
    "#     #GNB\n",
    "#     gnb_model = GaussianNB()\n",
    "#     gnb_model.fit(X_train, y_train)\n",
    "#     modelname =str(split_counter) + 'GNBModel' \n",
    "#     models.append([modelname, y_train.value_counts()[1]/y_train.value_counts()[0]])\n",
    "#     model_counter+=1\n",
    "#     pickle.dump(gnb_model, open('./models/'+ target_outcome + '/'+ modelname + '.sav', 'wb'))     \n",
    "#     print(\"GNB done\")\n",
    "\n",
    "#     #SVM\n",
    "#     svc_model = SVC(class_weight='balanced', C = 0.7, degree=2, kernel='poly', random_state=1234, cache_size=2048)\n",
    "#     svc_model.fit(X_train,y_train)\n",
    "#     modelname =str(split_counter) + 'SVCModel' \n",
    "#     models.append([modelname, y_train.value_counts()[1]/y_train.value_counts()[0]])\n",
    "#     model_counter+=1\n",
    "#     pickle.dump(svc_model, open('./models/'+ target_outcome + '/'+ modelname + '.sav', 'wb'))     \n",
    "#     print(\"SVM done\")\n",
    "\n",
    "#     #DT\n",
    "#     dt_model = DecisionTreeClassifier(class_weight='balanced', random_state=1234)\n",
    "#     dt_model.fit(X_train, y_train)\n",
    "#     modelname =str(split_counter) + 'DTModel' \n",
    "#     models.append([modelname, y_train.value_counts()[1]/y_train.value_counts()[0]])\n",
    "#     model_counter+=1\n",
    "#     pickle.dump(dt_model, open('./models/'+ target_outcome + '/'+ modelname + '.sav', 'wb'))     \n",
    "#     print(\"DT done\")\n",
    "\n",
    "#     #RF\n",
    "#     rf_model = RandomForestClassifier(class_weight='balanced', n_estimators=500, random_state=1234)\n",
    "#     rf_model.fit(X_train, y_train)\n",
    "#     modelname =str(split_counter) + 'RFModel' \n",
    "#     models.append([modelname, y_train.value_counts()[1]/y_train.value_counts()[0]])\n",
    "#     model_counter+=1\n",
    "#     pickle.dump(rf_model, open('./models/'+ target_outcome + '/'+ modelname + '.sav', 'wb'))     \n",
    "#     print(\"RF done\")\n",
    "\n",
    "\n",
    "\n",
    "#     #XGB\n",
    "#     scale_pos_ratio = y_train.value_counts()[0]/y_train.value_counts()[1]\n",
    "#     xgb_model = xgb.XGBClassifier(objective ='binary:logistic', max_depth = params['xgb_maxdepth'], n_estimators = 2000,  tree_method='gpu_hist', gpu_id=0,  verbosity = 0, random_state = 1234,\n",
    "#                                  importance_type = 'gain', scale_pos_weight = scale_pos_ratio, use_label_encoder=False, learning_rate=params['xgb_lr'])\n",
    "#     # xgb_model = xgb.XGBClassifier(objective ='binary:logistic', learning_rate = 0.001, tree_method='gpu_hist', gpu_id=0,  verbosity = 0, random_state = 1234)\n",
    "#     xgb_model.fit(X_train,y_train)\n",
    "#     #save model\n",
    "#     modelname = str(split_counter) + 'XGBoostModel'\n",
    "#     models.append([modelname,  y_train.value_counts()[1]/y_train.value_counts()[0]])\n",
    "#     pickle.dump(xgb_model, open('./models/'+ target_outcome + '/'+ modelname + '.sav', 'wb')) \n",
    "#     model_counter+=1\n",
    "#     print(\"XGB done\")\n",
    "    \n",
    "#     return models\n",
    "#     # return [xgb_model]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "885da3da-214f-47c0-9a78-0c6cd54a9515",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "outcomes.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aeea54f-2a65-4a99-9ac4-d1325d0ae597",
   "metadata": {},
   "source": [
    "# GRID SEARCH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e874cb2c-243a-4afc-b022-6344986679d5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def print_dataframe(filtered_cv_results):\n",
    "    \"\"\"Pretty print for filtered dataframe\"\"\"\n",
    "    for mean_sensitivity, std_sensitivity, mean_specificity, std_specificity, mean_auc, std_auc, params in zip(\n",
    "        filtered_cv_results[\"mean_test_sensitivity\"],\n",
    "        filtered_cv_results[\"std_test_sensitivity\"],\n",
    "        filtered_cv_results[\"mean_test_specificity\"],\n",
    "        filtered_cv_results[\"std_test_specificity\"],\n",
    "        filtered_cv_results[\"mean_test_auc\"],\n",
    "        filtered_cv_results[\"std_test_auc\"],\n",
    "        filtered_cv_results[\"params\"],\n",
    "    ):\n",
    "        print(\n",
    "            f\"sensitivity: {mean_sensitivity:0.4f} (±{std_sensitivity:0.03f}),\"\n",
    "            f\" specificity: {mean_specificity:0.4f} (±{std_specificity:0.03f}),\"\n",
    "            f\"auc: {mean_auc:0.4f} (±{std_auc:0.03f}),\"\n",
    "            f\" for {params}\"\n",
    "        )\n",
    "    print()\n",
    "\n",
    "\n",
    "def refit_strategy(cv_results):\n",
    "    \"\"\"Define the strategy to select the best estimator.\n",
    "\n",
    "    The strategy defined here is to filter-out all results below a precision threshold\n",
    "    of 0.98, rank the remaining by recall and keep all models with one standard\n",
    "    deviation of the best by recall. Once these models are selected, we can select the\n",
    "    fastest model to predict.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    cv_results : dict of numpy (masked) ndarrays\n",
    "        CV results as returned by the `GridSearchCV`.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    best_index : int\n",
    "        The index of the best estimator as it appears in `cv_results`.\n",
    "    \"\"\"\n",
    "    # print the info about the grid-search for the different scores\n",
    "    sensitivity_threshold = 0.5\n",
    "\n",
    "    cv_results_ = pd.DataFrame(cv_results)\n",
    "    print(\"All grid-search results:\")\n",
    "    print_dataframe(cv_results_)\n",
    "\n",
    "    # Filter-out all results below the threshold\n",
    "    high_sensitivity_cv_results = cv_results_[\n",
    "        cv_results_[\"mean_test_sensitivity\"] > sensitivity_threshold\n",
    "    ]\n",
    "\n",
    "    print(f\"Models with a sensitivity higher than {sensitivity_threshold}:\")\n",
    "    print_dataframe(high_sensitivity_cv_results)\n",
    "\n",
    "    high_sensitivity_cv_results = high_sensitivity_cv_results[\n",
    "        [\n",
    "            \"mean_score_time\",\n",
    "            \"mean_test_sensitivity\",\n",
    "            \"std_test_sensitivity\",\n",
    "            \"mean_test_specificity\",\n",
    "            \"std_test_specificity\",\n",
    "            \"mean_test_auc\",\n",
    "            \"std_test_auc\",\n",
    "            \"rank_test_sensitivity\",\n",
    "            \"rank_test_specificity\",\n",
    "            \"rank_test_auc\",\n",
    "            \"params\",\n",
    "        ]\n",
    "    ]\n",
    "\n",
    "    # Select the most performant models in terms of sesntivity\n",
    "    # (within 1 sigma from the best)\n",
    "    best_auc_std = high_sensitivity_cv_results[\"mean_test_auc\"].std()\n",
    "    best_auc = high_sensitivity_cv_results[\"mean_test_auc\"].max()\n",
    "    best_auc_threshold = best_auc - best_auc_std\n",
    "\n",
    "    high_auc_cv_results = high_sensitivity_cv_results[\n",
    "        high_sensitivity_cv_results[\"mean_test_auc\"] > best_auc_threshold\n",
    "    ]\n",
    "    if high_auc_cv_results.shape[0] > 1:\n",
    "        print(\n",
    "            \"Out of the previously selected high sensitivity models, we keep all the\\n\"\n",
    "            \"the models within one standard deviation of the highest auc model:\"\n",
    "        )\n",
    "\n",
    "        print(best_auc_threshold)\n",
    "        print_dataframe(high_auc_cv_results)\n",
    "\n",
    "        # From the best candidates, select the fastest model to predict\n",
    "        fastest_top_auc_high_sensitivity_index = high_auc_cv_results[\n",
    "            \"mean_score_time\"\n",
    "        ].idxmin()\n",
    "\n",
    "        print(\n",
    "            \"\\nThe selected final model is the fastest to predict out of the previously\\n\"\n",
    "            \"selected subset of best models based on precision and recall.\\n\"\n",
    "            \"Its scoring time is:\\n\\n\"\n",
    "            f\"{high_auc_cv_results.loc[fastest_top_auc_high_sensitivity_index]}\"\n",
    "        )\n",
    "\n",
    "        return fastest_top_auc_high_sensitivity_index\n",
    "    elif high_auc_cv_results.shape[0] == 1:\n",
    "        print('no parameter achieve the threshold, so return the default best score')\n",
    "        return cv_results_[\"mean_test_auc\"].idxmax()\n",
    "    else:\n",
    "        print('no parameter achieve the threshold, so return the default best score')\n",
    "        return cv_results_[\"mean_test_auc\"].idxmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "97ae5126-3025-46c5-a103-86dcc435625b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# LR = ['solver', 'C', 'max_iter']\n",
    "# Lasso = ['solver', 'C', 'max_iter']\n",
    "# Elastic= ['l1_ratio', 'max_iter']\n",
    "# GNB = ['var_smoothing']\n",
    "# SVM = ['C', 'gamma']\n",
    "# DT = ['criterion', 'splitter', 'max_depth']\n",
    "# RF = ['criterion', 'n_estimators', 'max_depth']\n",
    "# XGB = ['n_estimators', 'learning_rate', 'reg_alpha', 'reg_lambda']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d50f3c58-d643-43dc-ab18-bb3661b03556",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "######################################################################################################\n",
      "outcome_combined_6months\n",
      "#SVM\n",
      "Iteration No: 1 started. Evaluating function at random point.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ................................ score: (test=0.624) total time=11.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed: 11.0min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ................................ score: (test=0.704) total time=12.4min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed: 23.4min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ................................ score: (test=0.761) total time=13.5min\n",
      "Iteration No: 1 ended. Evaluation done at random point.\n",
      "Time taken: 2216.5544\n",
      "Function value obtained: 0.3038\n",
      "Current minimum: 0.3038\n",
      "Iteration No: 2 started. Evaluating function at random point.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed: 36.9min finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ................................ score: (test=0.624) total time=11.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed: 11.0min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ................................ score: (test=0.704) total time=11.8min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed: 22.8min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ................................ score: (test=0.761) total time=12.9min\n",
      "Iteration No: 2 ended. Evaluation done at random point.\n",
      "Time taken: 2140.9843\n",
      "Function value obtained: 0.3036\n",
      "Current minimum: 0.3036\n",
      "Iteration No: 3 started. Evaluating function at random point.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed: 35.7min finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ................................ score: (test=0.514) total time= 6.5min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  6.5min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ................................ score: (test=0.517) total time= 7.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed: 13.5min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ................................ score: (test=0.519) total time= 7.1min\n",
      "Iteration No: 3 ended. Evaluation done at random point.\n",
      "Time taken: 1232.1670\n",
      "Function value obtained: 0.4833\n",
      "Current minimum: 0.3036\n",
      "Iteration No: 4 started. Evaluating function at random point.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed: 20.5min finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ................................ score: (test=0.624) total time=12.9min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed: 12.9min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ................................ score: (test=0.704) total time=13.3min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed: 26.2min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ................................ score: (test=0.761) total time=11.2min\n",
      "Iteration No: 4 ended. Evaluation done at random point.\n",
      "Time taken: 2243.3840\n",
      "Function value obtained: 0.3037\n",
      "Current minimum: 0.3036\n",
      "Iteration No: 5 started. Evaluating function at random point.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed: 37.4min finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ................................ score: (test=0.675) total time= 3.6min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  3.6min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ................................ score: (test=0.667) total time= 3.9min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:  7.6min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ................................ score: (test=0.625) total time= 4.1min\n",
      "Iteration No: 5 ended. Evaluation done at random point.\n",
      "Time taken: 701.1212\n",
      "Function value obtained: 0.3442\n",
      "Current minimum: 0.3036\n",
      "Iteration No: 6 started. Evaluating function at random point.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed: 11.7min finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ................................ score: (test=0.622) total time= 5.7min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  5.7min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ................................ score: (test=0.703) total time= 5.8min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed: 11.5min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ................................ score: (test=0.760) total time= 5.7min\n",
      "Iteration No: 6 ended. Evaluation done at random point.\n",
      "Time taken: 1035.5579\n",
      "Function value obtained: 0.3047\n",
      "Current minimum: 0.3036\n",
      "Iteration No: 7 started. Evaluating function at random point.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed: 17.3min finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ................................ score: (test=0.624) total time=12.9min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed: 12.9min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ................................ score: (test=0.704) total time=12.9min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed: 25.8min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ................................ score: (test=0.761) total time=14.1min\n",
      "Iteration No: 7 ended. Evaluation done at random point.\n",
      "Time taken: 2392.5825\n",
      "Function value obtained: 0.3037\n",
      "Current minimum: 0.3036\n",
      "Iteration No: 8 started. Evaluating function at random point.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed: 39.9min finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ................................ score: (test=0.688) total time= 3.4min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  3.4min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ................................ score: (test=0.721) total time= 3.7min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:  7.0min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ................................ score: (test=0.723) total time= 3.8min\n",
      "Iteration No: 8 ended. Evaluation done at random point.\n",
      "Time taken: 650.8080\n",
      "Function value obtained: 0.2894\n",
      "Current minimum: 0.2894\n",
      "Iteration No: 9 started. Evaluating function at random point.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed: 10.8min finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ................................ score: (test=0.538) total time= 6.9min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  6.9min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ................................ score: (test=0.550) total time= 7.5min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed: 14.3min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ................................ score: (test=0.550) total time= 7.7min\n",
      "Iteration No: 9 ended. Evaluation done at random point.\n",
      "Time taken: 1321.8670\n",
      "Function value obtained: 0.4538\n",
      "Current minimum: 0.2894\n",
      "Iteration No: 10 started. Evaluating function at random point.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed: 22.0min finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ................................ score: (test=0.509) total time= 5.1min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  5.1min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ................................ score: (test=0.510) total time= 5.5min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed: 10.5min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .................................. score: (test=nan) total time= 5.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/rapids/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/envs/rapids/lib/python3.10/site-packages/sklearn/metrics/_scorer.py\", line 115, in __call__\n",
      "    score = scorer._score(cached_call, estimator, *args, **kwargs)\n",
      "  File \"/opt/conda/envs/rapids/lib/python3.10/site-packages/sklearn/metrics/_scorer.py\", line 276, in _score\n",
      "    y_pred = method_caller(estimator, \"predict\", X)\n",
      "  File \"/opt/conda/envs/rapids/lib/python3.10/site-packages/sklearn/metrics/_scorer.py\", line 73, in _cached_call\n",
      "    return getattr(estimator, method)(*args, **kwargs)\n",
      "  File \"/opt/conda/envs/rapids/lib/python3.10/site-packages/cuml/internals/api_decorators.py\", line 188, in wrapper\n",
      "    ret = func(*args, **kwargs)\n",
      "  File \"svc.pyx\", line 617, in cuml.svm.svc.SVC.predict\n",
      "  File \"/opt/conda/envs/rapids/lib/python3.10/site-packages/cuml/internals/api_decorators.py\", line 188, in wrapper\n",
      "    ret = func(*args, **kwargs)\n",
      "  File \"svm_base.pyx\", line 658, in cuml.svm.svm_base.SVMBase.predict\n",
      "RuntimeError: CUDA error encountered at: file=/opt/conda/envs/rapids/include/raft/core/interruptible.hpp line=301: \n",
      "\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed: 15.5min finished\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input y contains NaN.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/rapids/lib/python3.10/site-packages/skopt/optimizer/gp.py\u001b[0m in \u001b[0;36mgp_minimize\u001b[0;34m(func, dimensions, base_estimator, n_calls, n_random_starts, n_initial_points, initial_point_generator, acq_func, acq_optimizer, x0, y0, random_state, verbose, callback, n_points, n_restarts_optimizer, xi, kappa, noise, n_jobs, model_queue_size)\u001b[0m\n\u001b[1;32m    257\u001b[0m             noise=noise)\n\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 259\u001b[0;31m     return base_minimize(\n\u001b[0m\u001b[1;32m    260\u001b[0m         \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mspace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbase_estimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbase_estimator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0macq_func\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0macq_func\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/rapids/lib/python3.10/site-packages/skopt/optimizer/base.py\u001b[0m in \u001b[0;36mbase_minimize\u001b[0;34m(func, dimensions, base_estimator, n_calls, n_random_starts, n_initial_points, initial_point_generator, acq_func, acq_optimizer, x0, y0, random_state, verbose, callback, n_points, n_restarts_optimizer, xi, kappa, n_jobs, model_queue_size)\u001b[0m\n\u001b[1;32m    298\u001b[0m         \u001b[0mnext_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m         \u001b[0mnext_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 300\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    301\u001b[0m         \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspecs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspecs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    302\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0meval_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/rapids/lib/python3.10/site-packages/skopt/optimizer/optimizer.py\u001b[0m in \u001b[0;36mtell\u001b[0;34m(self, x, y, fit)\u001b[0m\n\u001b[1;32m    491\u001b[0m                 \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_tell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/rapids/lib/python3.10/site-packages/skopt/optimizer/optimizer.py\u001b[0m in \u001b[0;36m_tell\u001b[0;34m(self, x, y, fit)\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcatch_warnings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    535\u001b[0m                 \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msimplefilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ignore\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 536\u001b[0;31m                 \u001b[0mest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mXi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0myi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    537\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    538\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"next_xs_\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macq_func\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"gp_hedge\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/rapids/lib/python3.10/site-packages/skopt/learning/gaussian_process/gpr.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    193\u001b[0m                 \u001b[0mnoise_level\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnoise\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnoise_level_bounds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"fixed\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m             )\n\u001b[0;32m--> 195\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mGaussianProcessRegressor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnoise_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/rapids/lib/python3.10/site-packages/sklearn/gaussian_process/_gpr.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    235\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m             \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_2d\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 237\u001b[0;31m         X, y = self._validate_data(\n\u001b[0m\u001b[1;32m    238\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m             \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/rapids/lib/python3.10/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    582\u001b[0m                 \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"y\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_y_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    583\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 584\u001b[0;31m                 \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    585\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    586\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/rapids/lib/python3.10/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[1;32m   1120\u001b[0m     )\n\u001b[1;32m   1121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1122\u001b[0;31m     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmulti_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_numeric\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_numeric\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1124\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/rapids/lib/python3.10/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_check_y\u001b[0;34m(y, multi_output, y_numeric, estimator)\u001b[0m\n\u001b[1;32m   1130\u001b[0m     \u001b[0;34m\"\"\"Isolated part of check_X_y dedicated to y validation\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1131\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1132\u001b[0;31m         y = check_array(\n\u001b[0m\u001b[1;32m   1133\u001b[0m             \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m             \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"csr\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/rapids/lib/python3.10/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m    919\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    920\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 921\u001b[0;31m             _assert_all_finite(\n\u001b[0m\u001b[1;32m    922\u001b[0m                 \u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    923\u001b[0m                 \u001b[0minput_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/rapids/lib/python3.10/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[1;32m    159\u001b[0m                 \u001b[0;34m\"#estimators-that-handle-nan-values\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m             )\n\u001b[0;32m--> 161\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg_err\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Input y contains NaN."
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "#Bayesiain continuous search\n",
    "\n",
    "X = trainingData[features_columns]\n",
    "outcomes = [\n",
    "            # 'outcome_3months', \n",
    "            'outcome_combined_6months', \n",
    "            # 'outcome_combined_12months', \n",
    "            # 'outcome_combined_24months',\n",
    "           ] \n",
    "cv = StratifiedKFold(n_splits=3)\n",
    "n_calls = 10\n",
    "n_jobs = 2\n",
    "\n",
    "output = []\n",
    "\n",
    "for target_outcome in outcomes:\n",
    "    print('######################################################################################################')\n",
    "    print(target_outcome)\n",
    "    y = trainingData[target_outcome]\n",
    "    scale_pos_ratio = y.value_counts()[0]/y.value_counts()[1]\n",
    "    \n",
    "#     if target_outcome == 'outcome_combined_24months':   \n",
    "#     ##############################################################################\n",
    "#         print('#LR')\n",
    "#         lr_model = LogisticRegression(class_weight='balanced', random_state=1234)\n",
    "#         lr_params = [Categorical(['liblinear', 'newton-cholesky'], name = 'solver'),\n",
    "#                      Real(0.1, 10, 'log-uniform', name='C'), \n",
    "#                      Integer(50, 200, 'uniform', name='max_iter')]\n",
    "\n",
    "#         @use_named_args(lr_params)\n",
    "#         def lr_objective(**params):\n",
    "#             lr_model.set_params(**params)\n",
    "\n",
    "#             return 1-np.mean(cross_val_score(lr_model, X, y, cv=cv,\n",
    "#                                             scoring=make_scorer(roc_auc_score)))\n",
    "\n",
    "#         res_gp_lr = gp_minimize(lr_objective, lr_params, n_calls=n_calls, random_state=1234, verbose=3, n_jobs=n_jobs)\n",
    "#         output.append([target_outcome, 'lr', 1-res_gp_lr.fun, res_gp_lr.x])\n",
    "\n",
    "#     ########################################################################################\n",
    "\n",
    "#         print('#Lasso')\n",
    "#         lasso_model = LogisticRegression(class_weight='balanced', penalty='l1', random_state=1234) #only the LIBLINEAR and SAGA (added in v0.19) solvers handle the L1 penalty\n",
    "#         lasso_params = [Categorical(['saga', 'liblinear'], name = 'solver'),\n",
    "#                           Real(0.1, 10, 'log-uniform', name='C'),\n",
    "#                           Integer(50, 200, 'uniform', name='max_iter')]\n",
    "\n",
    "#         @use_named_args(lasso_params)\n",
    "#         def lasso_objective(**params):\n",
    "#             lasso_model.set_params(**params)\n",
    "\n",
    "#             return 1-np.mean(cross_val_score(lasso_model, X, y, cv=cv,\n",
    "#                                             scoring=make_scorer(roc_auc_score)))\n",
    "\n",
    "#         res_gp_lasso = gp_minimize(lasso_objective, lasso_params, n_calls=n_calls, random_state=1234, verbose=3, n_jobs=n_jobs)\n",
    "#         output.append([target_outcome, 'lasso', 1-res_gp_lasso.fun, res_gp_lasso.x])\n",
    "\n",
    "#     ########################################################################################\n",
    "\n",
    "#         print('#Elastic')\n",
    "#         elastic_model = LogisticRegression(class_weight='balanced', penalty = 'elasticnet', solver = 'saga', random_state=1234)\n",
    "#         elastic_params = [Real(0.1, 1, 'log-uniform', name='l1_ratio'),\n",
    "#                           Integer(300, 800, 'uniform', name='max_iter')]\n",
    "\n",
    "#         @use_named_args(elastic_params)\n",
    "#         def elastic_objective(**params):\n",
    "#             elastic_model.set_params(**params)\n",
    "\n",
    "#             return 1-np.mean(cross_val_score(elastic_model, X, y, cv=cv,\n",
    "#                                             scoring=make_scorer(roc_auc_score)))\n",
    "\n",
    "#         res_gp_elastic = gp_minimize(elastic_objective, elastic_params, n_calls=n_calls, random_state=1234, verbose=3, n_jobs=n_jobs)\n",
    "#         output.append([target_outcome, 'elastic', 1-res_gp_elastic.fun, res_gp_elastic.x])\n",
    "\n",
    "#     ########################################################################################\n",
    "\n",
    "#         print('#NB')\n",
    "#         gnb_model = GaussianNB()\n",
    "#         gnb_params = [Real(1e-9, 1e-5, 'log-uniform', name='var_smoothing')]\n",
    "\n",
    "#         @use_named_args(gnb_params)\n",
    "#         def gnb_objective(**params):\n",
    "#             gnb_model.set_params(**params)\n",
    "\n",
    "#             return 1-np.mean(cross_val_score(gnb_model, X, y, cv=cv,\n",
    "#                                             scoring = make_scorer(roc_auc_score)))\n",
    "\n",
    "#         res_gp_gnb = gp_minimize(gnb_objective, gnb_params, n_calls=n_calls, random_state=1234, verbose=3, n_jobs=n_jobs)\n",
    "#         output.append([target_outcome, 'gnb', 1-res_gp_gnb.fun, res_gp_gnb.x])\n",
    "\n",
    "    ########################################################################################\n",
    "\n",
    "    print('#SVM')\n",
    "    svc_model = SVC(class_weight='balanced', kernel='rbf', cache_size=1000, random_state=1234)\n",
    "    svm_params = [Real(0.1, 100, \"log-uniform\", name='C'),\n",
    "                     Real(0.1, 100, \"log-uniform\", name='gamma')]\n",
    "\n",
    "    @use_named_args(svm_params)\n",
    "    def svm_objective(**params):\n",
    "        svc_model.set_params(**params)\n",
    "\n",
    "        return 1-np.mean(cross_val_score(svc_model, X, y, cv=cv,\n",
    "                                        scoring=make_scorer(roc_auc_score), verbose=3))\n",
    "\n",
    "    res_gp_svm = gp_minimize(svm_objective, svm_params, n_calls=n_calls, random_state=1234, verbose=3, n_jobs=n_jobs)\n",
    "    output.append([target_outcome, 'svm', 1-res_gp_svm.fun, res_gp_svm.x])\n",
    "\n",
    "    ########################################################################################\n",
    "#         print('#DT')\n",
    "#         dt_model = DecisionTreeClassifier(class_weight='balanced', random_state=1234)\n",
    "#         dt_params = [Categorical([\"gini\", \"entropy\", \"log_loss\"],name='criterion'),\n",
    "#                      Categorical(['best', 'random'],name='splitter'),\n",
    "#                      Integer(3, 10, \"uniform\", name='max_depth'),]\n",
    "\n",
    "#         @use_named_args(dt_params)\n",
    "#         def dt_objective(**params):\n",
    "#             scoring = {\n",
    "#                 'auc': make_scorer(roc_auc_score)\n",
    "#                 }\n",
    "#             dt_model.set_params(**params)\n",
    "\n",
    "#             return 1 - np.mean(cross_val_score(dt_model, X, y, cv=cv,\n",
    "#                                             scoring=make_scorer(roc_auc_score)))\n",
    "#         res_gp_dt = gp_minimize(dt_objective, dt_params, n_calls=n_calls, random_state=1234, verbose=3, n_jobs=n_jobs)\n",
    "#         output.append([target_outcome, 'dt', 1-res_gp_dt.fun, res_gp_dt.x])\n",
    "    \n",
    "# ##########################################################################################\n",
    "\n",
    "#     print('#RF')\n",
    "#     rf_model = RandomForestClassifier(class_weight='balanced', random_state=1234)\n",
    "#     rf_params = [Categorical([\"gini\", \"entropy\", \"log_loss\"],name='criterion'),\n",
    "#                  Integer(100, 500, \"uniform\", name='n_estimators'),\n",
    "#                  Integer(3, 10, \"uniform\", name='max_depth'),]\n",
    "\n",
    "#     @use_named_args(rf_params)\n",
    "#     def rf_objective(**params):\n",
    "#         scoring = {\n",
    "#             'auc': make_scorer(roc_auc_score)\n",
    "#             }\n",
    "#         rf_model.set_params(**params)\n",
    "\n",
    "#         return 1 - np.mean(cross_val_score(rf_model, X, y, cv=cv,\n",
    "#                                         scoring=make_scorer(roc_auc_score)))\n",
    "#     res_gp_rf = gp_minimize(rf_objective, rf_params, n_calls=n_calls, random_state=1234, verbose=3, n_jobs=n_jobs)\n",
    "#     output.append([target_outcome, 'rf', 1-res_gp_rf.fun, res_gp_rf.x])\n",
    "    \n",
    "# ##########################################################################################\n",
    "\n",
    "#     print('#XGB')\n",
    "#     xgb_model = xgb.XGBClassifier(objective ='binary:logistic', tree_method='gpu_hist', gpu_id=0,  verbosity = 0,\n",
    "#                                          importance_type = 'gain', scale_pos_weight = scale_pos_ratio, random_state=1234)\n",
    "#     xgb_params = [Integer(100,500,\"uniform\", name='n_estimators'),\n",
    "#                     Integer(3, 10, \"uniform\", name='max_depth'),\n",
    "#                      Real(1e-5, 1e-1, 'log-uniform', name='learning_rate'),\n",
    "#                      Real(1e-5, 1e-1, 'log-uniform', name='reg_alpha'),\n",
    "#                      Real(1e-5, 1e-1, 'log-uniform', name='reg_lambda'),]\n",
    "#     @use_named_args(xgb_params)\n",
    "#     def xgb_objective(**params):\n",
    "#         xgb_model.set_params(**params)\n",
    "\n",
    "#         return 1 - np.mean(cross_val_score(xgb_model, X, y, cv=cv,\n",
    "#                                         scoring=make_scorer(roc_auc_score)))\n",
    "#     res_gp_xgb = gp_minimize(xgb_objective, xgb_params, n_calls=n_calls, random_state=1234, verbose=3, n_jobs=n_jobs)\n",
    "#     output.append([target_outcome, 'xgb', 1-res_gp_xgb.fun, res_gp_xgb.x])\n",
    "\n",
    "########################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "563ea6bf-db20-454a-92aa-131143d56902",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(output, columns=['outcome', 'model', 'best_score', 'best_param']).to_csv('../Models/BS_result_svm6.csv', index = False, index_label=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e35fa30-84aa-450e-b351-da939e744d60",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(output, columns=['outcome', 'model', 'best_score', 'best_param'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca2a6abc-cb43-466f-8d94-51503a2a522a",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "#GRID SEARCH\n",
    "X = trainingData[features_columns]\n",
    "# X = cudf.DataFrame(X)\n",
    "outcomes = [\n",
    "            'outcome_3months', \n",
    "            'outcome_combined_6months', \n",
    "            'outcome_combined_12months', \n",
    "            'outcome_combined_24months',\n",
    "           ] \n",
    "model_names = ['LR', 'Lasso', 'ElasticNet', 'NB', 'SVM', 'DT', 'RF', 'XGB']\n",
    "\n",
    "\n",
    "output = []\n",
    "for outcome in outcomes:\n",
    "    print(outcome)\n",
    "    y = trainingData[outcome]\n",
    "    scale_pos_ratio = y.value_counts()[0]/y.value_counts()[1]\n",
    "    \n",
    "    #MODELS\n",
    "    lr_model = LogisticRegression(class_weight='balanced', random_state=1234)\n",
    "    lasso_model = LogisticRegression(class_weight='balanced', penalty='l1', random_state=1234) #only the LIBLINEAR and SAGA (added in v0.19) solvers handle the L1 penalty\n",
    "    elastic_model = LogisticRegression(class_weight='balanced', penalty = 'elasticnet', random_state=1234)\n",
    "    gnb_model = GaussianNB()\n",
    "    svc_model = SVC(class_weight='balanced', gamma = 10, kernel='rbf', cache_size=2000, random_state=1234)\n",
    "    dt_model = DecisionTreeClassifier(class_weight='balanced', random_state=1234)\n",
    "    rf_model = RandomForestClassifier(class_weight='balanced', random_state=1234)\n",
    "    xgb_model = xgb.XGBClassifier(objective ='binary:logistic', tree_method='gpu_hist', gpu_id=0,  verbosity = 0,\n",
    "                                     importance_type = 'gain', scale_pos_weight = scale_pos_ratio, random_state=1234)\n",
    "\n",
    "    #PARAMS\n",
    "    lr_params = {'solver': ['liblinear', 'newton-cholesky'],\n",
    "                 'C': [0.1, 1.0, 10.0],\n",
    "                 'max_iter': [80.0, 100.0, 120.0]}\n",
    "    lasso_params = {'solver': ['saga', 'liblinear'],\n",
    "                    'C': [0.1, 1, 10],\n",
    "                    'max_iter': [80, 100, 120]},\n",
    "    elastic_params = {'solver': ['saga', 'liblinear'],\n",
    "                      'l1_ratio': [0.3, 0.5, 0.7],\n",
    "                      'max_iter': [80, 100, 120]},\n",
    "    gnb_params = {'var_smoothing': [1e-8, 5e-8, 1e-9, 5e-9]}\n",
    "    svm_params={'C': [1.0, 10.0]}\n",
    "    dt_params = {'criterion':[\"gini\", \"entropy\", \"log_loss\"],\n",
    "                 'splitter': ['best', 'random'],\n",
    "                'max_depth': [3,5,7,9]}\n",
    "    rf_params = {'criterion':[\"gini\", \"entropy\", \"log_loss\"],\n",
    "                 'n_estimators': [100, 200, 300],\n",
    "                'max_depth': [3.0,5.0,7.0,9.0]}\n",
    "    xgb_params = {'n_estimators': [100, 200, 300],\n",
    "                'max_depth': [3.0,5.0,7.0,9.0],\n",
    "                 'learning_rate': [3e-1, 3e-2, 3e-3],\n",
    "                 'reg_alpha': [0.3, 0.5, 0.7],\n",
    "                 'reg_lambda': [0.3, 0.5, 0.7],}\n",
    "\n",
    "    #Models and params in DICT\n",
    "    models_to_be_trained = [\n",
    "        {'model_name': 'LR', 'model': lr_model, 'params': lr_params},\n",
    "        {'model_name': 'Lasso', 'model': lasso_model, 'params': lasso_params},\n",
    "        {'model_name': 'ElasticNet', 'model': elastic_model, 'params': elastic_params},\n",
    "        {'model_name': 'NB', 'model': gnb_model, 'params': gnb_params},\n",
    "        # {'model_name': 'SVM', 'model': svc_model, 'params': svm_params},\n",
    "        {'model_name': 'DT', 'model': dt_model, 'params': dt_params},\n",
    "        {'model_name': 'RF', 'model': rf_model, 'params': rf_params},\n",
    "        {'model_name': 'XGB', 'model': xgb_model, 'params': xgb_params}\n",
    "    ]\n",
    "    \n",
    "    #scoring\n",
    "    # scoring = {\n",
    "    #     'accuracy': make_scorer(balanced_accuracy_score),\n",
    "    #     'sensitivity': make_scorer(recall_score),\n",
    "    #     'specificity': make_scorer(recall_score,pos_label=0),\n",
    "    #     'auc': make_scorer(roc_auc_score)\n",
    "    #     }\n",
    "    scoring = {\n",
    "        'auc': make_scorer(roc_auc_score)\n",
    "        }\n",
    "    \n",
    "    for item in models_to_be_trained:\n",
    "        print(item['model_name'])\n",
    "        gs = BayesSearchCV(item['model'],\n",
    "                          search_spaces=item['params'],\n",
    "                          scoring=make_scorer(roc_auc_score),\n",
    "                           n_iter = 20,\n",
    "                          cv=2,\n",
    "                          verbose=3, \n",
    "                           n_jobs=5,\n",
    "                           n_points=10,\n",
    "                            random_state = 1234)\n",
    "        gs.fit(X, y)\n",
    "        output.append([outcome, item['model_name'], gs.best_params_])\n",
    "        pickle.dump(gs.cv_results_, open('../Models/gs/' + outcome.split('_')[-1] + '_' + item['model_name'] + '.sav', 'wb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb62bac4-e573-41d9-9187-2359cde616b0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "X = trainingData[features_columns]\n",
    "y = trainingData['outcome_combined_12months']\n",
    "X = cudf.DataFrame(X)\n",
    "# y = cudf.DataFrame(y)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ebbba04-4fa9-43bc-9809-c99ccfd09860",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# svc_model = SVC(class_weight='balanced', kernel='poly', random_state=1234)\n",
    "# svm_params={'C': [0.1, 1, 10], 'gamma': [1,10]}\n",
    "# gs = GridSearchCV(svc_model,\n",
    "#                   param_grid=svm_params,\n",
    "#                   scoring=['average_precision', 'balanced_accuracy', 'roc_auc'],\n",
    "#                   refit='roc_auc',\n",
    "#                   cv=3,\n",
    "#                   verbose=3,)\n",
    "# gs.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1f74bb4-1703-4248-a720-f53afa9abea3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "svc_model = SVC(class_weight='balanced', C = 10, gamma= 10, kernel='rbf', cache_size= 2000, random_state=1234, verbose=3)\n",
    "svc_model.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "043c6f4a-3608-49db-910a-cbc1e69dd42f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "preds = svc_model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "129c774a-6fae-4aee-ae77-8487bf003052",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72d88c57-deac-49e6-92f7-5c8a2f39d702",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "classification_report(y, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d25f6bd2-cd5f-4129-924b-ea1e2c36a122",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "output[5][1].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9281058f-00ae-44e3-91d9-bee8c6929490",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "gs.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6f39271-b950-4e9b-8bf2-7c20f796a4e4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "output[5][1]['params'][output[5][1]['rank_test_balanced_accuracy'][0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da95a0c9-99e9-4756-81c2-dd5d84194a21",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "output[5][1]['params'][output[5][1]['rank_test_average_precision'][0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a3cab69-885b-4331-a37d-846a7d9a61a9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(output, columns=['model', 'GS_result']).to_csv('../Models/GS_result.csv', index_label=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79bd1f8c-d809-44ae-aa9c-3777ceac52be",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "542271fb-66ee-42b4-b023-c6c03c898dc6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76a6fd43-a669-46d6-b962-b23ec9b8b2d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fbd1739-4fe0-49b8-b655-26c10bf0a5d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define number of split in k-fold\n",
    "\n",
    "n_splits = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b30f895e-5381-46ba-b938-e4635f2cea72",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create X set for model development\n",
    "\n",
    "target_outcome = 'outcome_3months'\n",
    "X = trainingData[features_columns]\n",
    "y = trainingData[[target_outcome]]\n",
    "print('X shape: ', X.shape)\n",
    "print('y shape: ', y.shape)\n",
    "\n",
    "#model parameters\n",
    "params = {'xgb_lr': 0.6,\n",
    "         'xgb_maxdepth': 7}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bc35cae-8c88-4260-a968-25e098bbeedc",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "#EXECUTE model training\n",
    "\n",
    "kf = StratifiedKFold(n_splits=n_splits, random_state=1234, shuffle=True)\n",
    "kf.get_n_splits(X)\n",
    "models1 = pd.DataFrame(columns=['modelname', 'class_ratio'])\n",
    "summary_result1 = []\n",
    "cols = ['model_name', 'class_ratio', 'acc','spec','sens','auc', 'auprc', 'balance_accuracy', 'f1_score', 'ppv', 'npv']\n",
    "split_counter = 0\n",
    "\n",
    "#train model\n",
    "for train_index, test_index in kf.split(X, y):\n",
    "    #split data\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "    #Build models -> it can be commented if the models have been trained\n",
    "    models_temp = pd.DataFrame(build_models(X_train, y_train[target_outcome], params, split_counter), columns=['modelname', 'class_ratio'])\n",
    "    models1 = pd.concat([models1,models_temp]).reset_index(drop=True)\n",
    "    split_counter+=1\n",
    "        \n",
    "#evaluate model\n",
    "for modelname, classratio in models1.values:\n",
    "    # print('======================================================================')\n",
    "    print(modelname)\n",
    "    model = pickle.load(open('./models/'+ target_outcome + '/'+ modelname + '.sav', 'rb'))\n",
    "    summary_result1.append((str(model), classratio, ) + summariseResult (X_test, y_test[target_outcome], model) )       \n",
    "\n",
    "\n",
    "summary_result1 = pd.DataFrame(summary_result1, columns=cols)\n",
    "summary_result1['model_num'] = summary_result1.index\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "552fe2d3-7c89-47cd-ae82-c10fb64cd3a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(target_outcome)\n",
    "summary_result1['model_name'] = summary_result1.apply(lambda x: modelNameFixer(x.model_name), axis=1)\n",
    "summary_result1.groupby('model_name').mean().sort_values(['auc'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b731a567-350a-409e-8bfd-dea303c9f7dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_result1.to_csv(\"summaryResult_outcome1.csv\")\n",
    "summary_result1 = pd.read_csv(\"summaryResult_outcome1.csv\")\n",
    "\n",
    "bar = sns.catplot(x = \"model_name\",       # x variable name\n",
    "            y = \"auc\",       # y variable name            \n",
    "            data = summary_result1,     # dataframe to plot\n",
    "            kind = \"bar\",\n",
    "            height=5,\n",
    "            aspect=5/2.5,\n",
    "            ci = None)\n",
    "ax = bar.facet_axis(0,0)\n",
    "for p in ax.patches:\n",
    "    ax.text(p.get_x() + 0.01, \n",
    "            p.get_height() * 1.01, \n",
    "            '{0:.4f}'.format(p.get_height()), \n",
    "            color='black', rotation='horizontal', fontsize=11)\n",
    "    \n",
    "# listOf_Yticks = np.arange(0.5, 0.7, 0.05)\n",
    "ax.set_ylim(0.4, 1)\n",
    "ax.set_ylabel('AUC Score', fontsize=11)\n",
    "ax.set_xlabel('Method', fontsize=11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3831d05a-49bd-41a9-8294-8ddeae8bc2ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# kf = StratifiedKFold(n_splits=2, random_state=1234, shuffle=True)\n",
    "# kf.get_n_splits(X)\n",
    "# for train_index, test_index in kf.split(X, y):\n",
    "#     #split data\n",
    "#     X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "#     y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "#     trymodel = SVC(class_weight='balanced', C = 0.7, degree=2, kernel='poly', random_state=1234, cache_size=2048)\n",
    "#     trymodel.fit(X_train,y_train)\n",
    "#     print(summariseResult(X_test, y_test, trymodel))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baaabe03-0654-40e4-846c-26c3b1ebb50d",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model1 = pickle.load(open('./models/outcome_3months/0DTModel.sav', 'rb'))\n",
    "\n",
    "# pd.DataFrame([best_model3.feature_importances_], columns=X.columns).T.sort_values(0, ascending=False)\n",
    "sorted_idx = best_model1.feature_importances_.argsort()\n",
    "plt.figure(figsize=(5,7))\n",
    "plt.barh(X.columns[sorted_idx][-10:], best_model1.feature_importances_[sorted_idx][-10:])\n",
    "plt.xlabel(\"Decision Tree Feature Importance\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "585071b8-244d-4f64-bd03-6cfcb038b749",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model1 = pickle.load(open('./models/outcome_3months/0RFModel.sav', 'rb'))\n",
    "\n",
    "# pd.DataFrame([best_model3.feature_importances_], columns=X.columns).T.sort_values(0, ascending=False)\n",
    "sorted_idx = best_model1.feature_importances_.argsort()\n",
    "plt.figure(figsize=(5,7))\n",
    "plt.barh(X.columns[sorted_idx][-10:], best_model1.feature_importances_[sorted_idx][-10:])\n",
    "plt.xlabel(\"Random Forest Feature Importance\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e292a9c-e922-4f1d-8655-ff243fb4f1e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model1 = pickle.load(open('./models/outcome_3months/0XGBoostModel.sav', 'rb'))\n",
    "\n",
    "# pd.DataFrame([best_model3.feature_importances_], columns=X.columns).T.sort_values(0, ascending=False)\n",
    "sorted_idx = best_model1.feature_importances_.argsort()\n",
    "plt.figure(figsize=(5,7))\n",
    "plt.barh(X.columns[sorted_idx][-10:], best_model1.feature_importances_[sorted_idx][-10:])\n",
    "plt.xlabel(\"XGBoost Feature Importance\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76596db2-c810-4c3a-b724-e59b6f9cd19a",
   "metadata": {},
   "source": [
    "# 6months"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ae588b5-980f-4712-bfef-e84dfcb1c902",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_outcome = 'outcome_combined_6months'\n",
    "y = trainingData[[target_outcome]]\n",
    "\n",
    "#model parameters\n",
    "params = {'xgb_lr': 0.6,\n",
    "         'xgb_maxdepth': 7}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70c88a10-ffac-4051-82e6-0866d4c3b28b",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "#EXECUTE model training\n",
    "\n",
    "kf = StratifiedKFold(n_splits=n_splits, random_state=1234, shuffle=True)\n",
    "kf.get_n_splits(X)\n",
    "models2 = pd.DataFrame(columns=['modelname', 'class_ratio'])\n",
    "summary_result2 = []\n",
    "cols = ['model_name', 'class_ratio', 'acc','spec','sens','auc', 'auprc', 'balance_accuracy', 'f1_score', 'ppv', 'npv']\n",
    "split_counter = 0\n",
    "\n",
    "#train model\n",
    "for train_index, test_index in kf.split(X, y):\n",
    "    #split data\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "    #Build models -> it can be commented if the models have been trained\n",
    "    models_temp = pd.DataFrame(build_models(X_train, y_train[target_outcome], params, split_counter), columns=['modelname', 'class_ratio'])\n",
    "    models2 = pd.concat([models2,models_temp]).reset_index(drop=True)\n",
    "    split_counter+=1\n",
    "        \n",
    "#evaluate model\n",
    "for modelname, classratio in models2.values:\n",
    "    # print('======================================================================')\n",
    "    print(modelname)\n",
    "    model = pickle.load(open('./models/'+ target_outcome + '/'+ modelname + '.sav', 'rb'))\n",
    "    summary_result2.append((str(model), classratio, ) + summariseResult (X_test, y_test[target_outcome], model) )       \n",
    "\n",
    "\n",
    "summary_result2 = pd.DataFrame(summary_result2, columns=cols)\n",
    "summary_result2['model_num'] = summary_result2.index\n",
    "# summary_result1['method_name'] = summary_result1.apply(lambda x: 'LR' if x.model_num%2 == 0 else 'XGBoost', axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d11f1f49-3ade-41c8-82d1-8d346211c299",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(target_outcome)\n",
    "summary_result2['model_name'] = summary_result2.apply(lambda x: modelNameFixer(x.model_name), axis=1)\n",
    "summary_result2.groupby('model_name').mean().sort_values(['auc'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8506386d-27a9-49fa-856b-a5683e7144e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_result2.to_csv(\"summaryResult_outcome2.csv\")\n",
    "summary_result2 = pd.read_csv(\"summaryResult_outcome2.csv\")\n",
    "\n",
    "bar = sns.catplot(x = \"model_name\",       # x variable name\n",
    "            y = \"auc\",       # y variable name            \n",
    "            data = summary_result2,     # dataframe to plot\n",
    "            kind = \"bar\",\n",
    "            height=5,\n",
    "            aspect=5/2.5,\n",
    "            ci = None)\n",
    "ax = bar.facet_axis(0,0)\n",
    "for p in ax.patches:\n",
    "    ax.text(p.get_x() + 0.01, \n",
    "            p.get_height() * 1.01, \n",
    "            '{0:.4f}'.format(p.get_height()), \n",
    "            color='black', rotation='horizontal', fontsize=11)\n",
    "    \n",
    "# listOf_Yticks = np.arange(0.5, 0.7, 0.05)\n",
    "ax.set_ylim(0.4, 1)\n",
    "ax.set_ylabel('AUC Score', fontsize=11)\n",
    "ax.set_xlabel('Method', fontsize=11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10426f78-d63b-4430-aa28-9781fe41a744",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model2 = pickle.load(open('./models/outcome_combined_6months/0DTModel.sav', 'rb'))\n",
    "\n",
    "# pd.DataFrame([best_model3.feature_importances_], columns=X.columns).T.sort_values(0, ascending=False)\n",
    "sorted_idx = best_model2.feature_importances_.argsort()\n",
    "plt.figure(figsize=(5,7))\n",
    "plt.barh(X.columns[sorted_idx][-10:], best_model2.feature_importances_[sorted_idx][-10:])\n",
    "plt.xlabel(\"Decision Tree Feature Importance\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3090a2a-1dcd-4723-8538-acc2ecafd220",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model2 = pickle.load(open('./models/outcome_combined_6months/0RFModel.sav', 'rb'))\n",
    "\n",
    "# pd.DataFrame([best_model3.feature_importances_], columns=X.columns).T.sort_values(0, ascending=False)\n",
    "sorted_idx = best_model2.feature_importances_.argsort()\n",
    "plt.figure(figsize=(5,7))\n",
    "plt.barh(X.columns[sorted_idx][-10:], best_model2.feature_importances_[sorted_idx][-10:])\n",
    "plt.xlabel(\"Random Forest Feature Importance\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4ca7472-0652-49bd-aef2-81ca61469336",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model2 = pickle.load(open('./models/outcome_combined_6months/0XGBoostModel.sav', 'rb'))\n",
    "\n",
    "# pd.DataFrame([best_model3.feature_importances_], columns=X.columns).T.sort_values(0, ascending=False)\n",
    "sorted_idx = best_model2.feature_importances_.argsort()\n",
    "plt.figure(figsize=(5,7))\n",
    "plt.barh(X.columns[sorted_idx][-10:], best_model2.feature_importances_[sorted_idx][-10:])\n",
    "plt.xlabel(\"XGBoost Feature Importance\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c9953e6-6fc4-481c-a5dc-5be9e2d97063",
   "metadata": {},
   "source": [
    "# 12 months"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfe3cacf-85d8-4889-b3f7-b0653c74d935",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_outcome = 'outcome_combined_12months'\n",
    "y = trainingData[[target_outcome]]\n",
    "\n",
    "#model parameters\n",
    "params = {'xgb_lr': 0.6,\n",
    "         'xgb_maxdepth': 10}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b801fbf-b23b-4c62-8e31-083cd3b5635f",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "#EXECUTE model training\n",
    "\n",
    "kf = StratifiedKFold(n_splits=n_splits, random_state=1234, shuffle=True)\n",
    "kf.get_n_splits(X)\n",
    "models3 = pd.DataFrame(columns=['modelname', 'class_ratio'])\n",
    "summary_result3 = []\n",
    "cols = ['model_name', 'class_ratio', 'acc','spec','sens','auc', 'auprc', 'balance_accuracy', 'f1_score', 'ppv', 'npv']\n",
    "split_counter = 0\n",
    "\n",
    "#train model\n",
    "for train_index, test_index in kf.split(X, y):\n",
    "    #split data\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "    #Build models -> it can be commented if the models have been trained\n",
    "    models_temp = pd.DataFrame(build_models(X_train, y_train[target_outcome], params, split_counter), columns=['modelname', 'class_ratio'])\n",
    "    models3 = pd.concat([models3,models_temp]).reset_index(drop=True)\n",
    "    split_counter+=1\n",
    "        \n",
    "#evaluate model\n",
    "for modelname, classratio in models3.values:\n",
    "    # print('======================================================================')\n",
    "    print(modelname)\n",
    "    model = pickle.load(open('./models/'+ target_outcome + '/'+ modelname + '.sav', 'rb'))\n",
    "    summary_result3.append((str(model), classratio, ) + summariseResult (X_test, y_test[target_outcome], model) )       \n",
    "\n",
    "\n",
    "summary_result3 = pd.DataFrame(summary_result3, columns=cols)\n",
    "summary_result3['model_num'] = summary_result3.index\n",
    "# summary_result1['method_name'] = summary_result1.apply(lambda x: 'LR' if x.model_num%2 == 0 else 'XGBoost', axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e27d5bb5-e42f-4ad0-9c59-af9b9f5645cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(target_outcome)\n",
    "summary_result3['model_name'] = summary_result3.apply(lambda x: modelNameFixer(x.model_name), axis=1)\n",
    "summary_result3.groupby('model_name').mean().sort_values(['auc'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6365bfd3-728e-4071-9abd-d8b87135d795",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_result3.to_csv(\"summaryResult_outcome3.csv\")\n",
    "summary_result3 = pd.read_csv(\"summaryResult_outcome3.csv\")\n",
    "\n",
    "bar = sns.catplot(x = \"model_name\",       # x variable name\n",
    "            y = \"auc\",       # y variable name            \n",
    "            data = summary_result3,     # dataframe to plot\n",
    "            kind = \"bar\",\n",
    "            height=5,\n",
    "            aspect=5/2.5,\n",
    "            ci = None)\n",
    "ax = bar.facet_axis(0,0)\n",
    "for p in ax.patches:\n",
    "    ax.text(p.get_x() + 0.01, \n",
    "            p.get_height() * 1.01, \n",
    "            '{0:.4f}'.format(p.get_height()), \n",
    "            color='black', rotation='horizontal', fontsize=11)\n",
    "    \n",
    "# listOf_Yticks = np.arange(0.5, 0.7, 0.05)\n",
    "ax.set_ylim(0.4, 1)\n",
    "ax.set_ylabel('AUC Score', fontsize=11)\n",
    "ax.set_xlabel('Method', fontsize=11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "722308db-b7ef-479b-b5fd-4f57a8ff1fa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model3 = pickle.load(open('./models/outcome_combined_12months/0DTModel.sav', 'rb'))\n",
    "\n",
    "# pd.DataFrame([best_model3.feature_importances_], columns=X.columns).T.sort_values(0, ascending=False)\n",
    "sorted_idx = best_model3.feature_importances_.argsort()\n",
    "plt.figure(figsize=(5,7))\n",
    "plt.barh(X.columns[sorted_idx][-10:], best_model3.feature_importances_[sorted_idx][-10:])\n",
    "plt.xlabel(\"Decision Tree Feature Importance\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d90e68e-3bb4-4768-9026-eaa1af12ef41",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "best_model3 = pickle.load(open('./models/outcome_combined_12months/0RFModel.sav', 'rb'))\n",
    "\n",
    "# pd.DataFrame([best_model3.feature_importances_], columns=X.columns).T.sort_values(0, ascending=False)\n",
    "sorted_idx = best_model3.feature_importances_.argsort()\n",
    "plt.figure(figsize=(5,7))\n",
    "plt.barh(X.columns[sorted_idx][-10:], best_model3.feature_importances_[sorted_idx][-10:])\n",
    "plt.xlabel(\"Random Forest Feature Importance\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63e290ea-fbf1-42bd-b7db-4712fdf65e11",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "best_model3 = pickle.load(open('./models/outcome_combined_12months/0XGBoostModel.sav', 'rb'))\n",
    "\n",
    "# pd.DataFrame([best_model3.feature_importances_], columns=X.columns).T.sort_values(0, ascending=False)\n",
    "sorted_idx = best_model3.feature_importances_.argsort()\n",
    "plt.figure(figsize=(5,7))\n",
    "plt.barh(X.columns[sorted_idx][-10:], best_model3.feature_importances_[sorted_idx][-10:])\n",
    "plt.xlabel(\"XGBoost Feature Importance\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
