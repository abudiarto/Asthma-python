{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ee4d8f95-286c-4067-8985-4b7d6f9d0b6c",
   "metadata": {},
   "source": [
    "# LSTM Model using Clinical + Therapy sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ae1286de-3d50-4eb3-b3c7-a4404748f00b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-25 16:43:41.565373: I tensorflow/core/util/port.cc:111] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-10-25 16:43:41.888350: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-10-25 16:43:41.888392: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-10-25 16:43:41.890174: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-10-25 16:43:42.036699: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-10-25 16:43:43.299371: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import imdb\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM, Embedding, Dropout\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from tensorflow.keras.metrics import AUC, SensitivityAtSpecificity\n",
    "from tensorflow.keras.optimizers import Adam, Adagrad, RMSprop\n",
    "#internal validation\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report, f1_score, balanced_accuracy_score, matthews_corrcoef, auc, average_precision_score, roc_auc_score, balanced_accuracy_score, roc_curve, accuracy_score\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "# fix random seed for reproducibility\n",
    "tf.random.set_seed(1234)\n",
    "\n",
    "target_outcome = 'outcome_combined_12months'\n",
    "max_codes = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "99d66269-80cc-4450-9432-b75bcb598efb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30229"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the dataset but only keep the top n words, zero the rest\n",
    "data = pickle.load(open('../SeqModel/data_all.sav', 'rb'))\n",
    "code2idx = pickle.load(open('../SeqModel/code2idx_all.sav', 'rb'))\n",
    "idx2code = pickle.load(open('../SeqModel/idx2code_all.sav', 'rb'))\n",
    "\n",
    "vocab_size = len(code2idx)\n",
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "23098e77-76c5-422c-bdbd-a0152e9876c4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# #Data split conventional (mixed countries)\n",
    "# trainingData, testData = train_test_split(data, test_size=0.1, stratify=data[target_outcome], random_state=1234)\n",
    "# trainingData, valData = train_test_split(trainingData, test_size=0.2, stratify=trainingData[target_outcome], random_state=1234)\n",
    "# print(trainingData.shape)\n",
    "# print(valData.shape)\n",
    "# print(testData.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9d0d0809-4055-42b9-a738-5438011b7eb4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Data split, train=England, eval=Scot+Wales\n",
    "trainingData = data[(data.Country == 'England') & (data.age >= 18)]\n",
    "trainingData, valData = train_test_split(trainingData, test_size=0.2, stratify=trainingData[target_outcome], random_state=1234)\n",
    "trainingData, evalData = train_test_split(trainingData, test_size=0.2, stratify=trainingData[target_outcome], random_state=1234)\n",
    "testData = data[((data.Country == 'Wales') | (data.Country == 'Scotland')) & (data.age >= 18)]\n",
    "testDataWales = data[(data.Country == 'Wales') & (data.age >= 18)]\n",
    "testDataScotland = data[(data.Country == 'Scotland') & (data.age >= 18)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9f157bd3-b8a1-47e5-b6de-3e4f7d466bb5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:  13412\n",
      "Val:  4192\n",
      "Eval (internal validation):  3354\n",
      "Test:  1491\n",
      "Test - Wales:  973\n",
      "Test - Scotland:  518\n"
     ]
    }
   ],
   "source": [
    "print('Train: ', trainingData.shape[0])\n",
    "print('Val: ', valData.shape[0])\n",
    "print('Eval (internal validation): ', evalData.shape[0])\n",
    "print('Test: ', testData.shape[0])\n",
    "print('Test - Wales: ', testDataWales.shape[0])\n",
    "print('Test - Scotland: ', testDataScotland.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bdf217de-6216-4a7d-b8ef-705c69fb52cf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13412,)\n",
      "(13412, 14)\n"
     ]
    }
   ],
   "source": [
    "print(trainingData.patid.unique().shape)\n",
    "print(trainingData.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a8913a7a-5e44-4359-85a4-5e4bdf6501c7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[43487233, 43487235, 43464708, 43139079, 43378699, 43139096, 43165721, 43378721, 43165731, 43165732, 43487269, 43165737, 43165746, 43325496, 43311166, 43464772, 43227211, 43466834, 43378773, 43311191, 43339865, 43139165, 43284586, 43374709, 43139214, 43315349, 43165847, 43430042, 43442340, 43145381, 43327661, 43350191, 43491513, 43315386, 43135161, 43145404, 43253954, 43430083, 43192522, 43190477, 43339982, 43190478, 43253966, 43303126, 43423963, 43430108, 43426012, 43430118, 43180267, 43251950, 43317488, 43141371, 43340029, 43317502, 43190531, 43317508, 43190533, 43204870, 43491591, 43340044, 43317518, 43430159, 43190548, 43317526, 43315483, 43208987, 43315486, 43317538, 43254052, 43208998, 43192615, 43317543, 43209011, 43430199, 43430210, 43413830, 43489611, 43340108, 43209038, 43491667, 43340118, 43477336, 43491680, 43491683, 43272551, 43413865, 43221371, 43426174, 43342206, 43413898, 43336077, 43209102, 43489679, 43342222, 43489683, 43426195, 43489687, 43188637, 43221410, 43342248, 43491760, 43262384, 43145648, 43262393, 43426234, 43420103, 43336137, 43426254, 43426256, 43491794, 43373014, 43188697, 43188698, 43491804, 43426270, 43373023, 43272675, 43489770, 43336177, 43416050, 43188726, 43336187, 43188732, 43461119, 43354623, 43188737, 43416074, 43205133, 43336208, 43141648, 43188754, 43145745, 43426324, 43420181, 43334167, 43348507, 43137565, 43348533, 43137590, 43188792, 43334201, 43225657, 43141693, 43188798, 43422271, 43221570, 43201099, 43326028, 43334223, 43141712, 43227730, 43205204, 43141717, 43446875, 43141724, 43201115, 43139682, 43201124, 43137642, 43205226, 43205230, 43446898, 43137653, 43420278, 43446903, 43227772, 43221631, 43201160, 43305611, 43489943, 43221657, 43381406, 43139746, 43446951, 43446952, 43137715, 43221684, 43137725, 43334334, 43229886, 43305665, 43446982, 43264714, 43305679, 43408084, 43447001, 43221722, 43221726, 43408102, 43309800, 43375338, 43125484, 43496172, 43229934, 43444976, 43447031, 43383544, 43447038, 43143934, 43143938, 43307779, 43467524, 43283205, 43264772, 43496205, 43383569, 43283218, 43166482, 43143956, 43223826, 43191061, 43275032, 43332380, 43264796, 43275038, 43191071, 43229988, 43275048, 43166506, 43143980, 43223860, 43180852, 43223863, 43248444, 43166525, 43469637, 43223884, 43191117, 43176784, 43326293, 43248471, 43469657, 43311969, 43275107, 43283299, 43283302, 43332458, 43191146, 43176813, 43176816, 43275120, 43463538, 43166580, 43283317, 43414391, 43248507, 43275133, 43275145, 43094922, 43322250, 43223947, 43158409, 43344781, 43309965, 43447183, 43463569, 43275156, 43275157, 43322263, 43463575, 43158425, 43180955, 43475872, 43322273, 43340707, 43176870, 43166640, 43322297, 43426753, 43475907, 43475908, 43344840, 43287496, 43322322, 43428826, 43344866, 43428846, 43463674, 43463676, 43344894, 43172865, 43179009, 43203589, 43496454, 43256838, 43144197, 43463689, 43428900, 43346990, 43258927, 43308081, 43205690, 43254846, 43443263, 43447360, 43344961, 43322437, 43443270, 43347017, 43308107, 43426892, 43347019, 43443278, 43443280, 43308119, 43254875, 43443298, 43347045, 43447403, 43261036, 43351153, 43254898, 43478133, 43347069, 43205762, 43254917, 43457670, 43347084, 43179161, 43207853, 43261103, 43261110, 43379896, 43414715, 43162812, 43461828, 43457746, 43136213, 43347159, 43410656, 43103466, 43130099, 43130106, 43103485, 43382013, 43267328, 43130118, 43113735, 43136279, 43267351, 43103514, 43412762, 43267359, 43130144, 43427108, 43267371, 43144492, 43136302, 43136305, 43410742, 43337020, 43136320, 43414861, 43130190, 43330895, 43451732, 43144532, 43451736, 43378008, 43378012, 43113822, 43312483, 43412837, 43378024, 43451773, 43144573, 43451776, 43160960, 43279750, 43337095, 43337102, 43412882, 43337111, 43259292, 43429276, 43226530, 43160994, 43167138, 43136422, 43136427, 43425197, 43169205, 43255224, 43337148, 43412936, 43265481, 43345357, 43412948, 43259348, 43339226, 43169244, 43343329, 43169255, 43480568, 43306489, 43255291, 43169279, 43259395, 43265544, 43265559, 43124248, 43413018, 43124250, 43181599, 43480612, 43181604, 43259431, 43181608, 43429423, 43443764, 43259451, 43419197, 43189823, 43140677, 43419215, 43382354, 43306580, 43189844, 43327067, 43376231, 43306623, 43181700, 43191940, 43349638, 43286154, 43286158, 43286159, 43464340, 43286168, 43089567, 43271855, 43142845, 43224772, 43382470, 43478726, 43257551, 43349714, 43179736, 43349728, 43175653, 43185893, 43349736, 43204333, 43257583, 43323121, 43349748, 43179769, 43470587, 43456259, 43323148, 43165455, 43489041, 43224854, 43261723, 43226914, 43226915, 43464484, 43144996, 43228966, 43323184, 43323192, 43163449, 43253564, 43286338, 43493188, 43464518, 43284307, 43323226, 43226974, 43251554, 43226978, 43173731, 43226981, 43253602, 43323241, 43226990, 43304816, 43325303, 43446138, 43145086, 43251585, 43251592, 43323273, 43286409, 43491212, 43423629, 43179916, 43253654, 43464599, 43165591, 43227034, 43202459, 43423654, 43304873, 43261865, 43173801, 43446192, 43499441, 43423666, 43284403, 43251636, 43227060, 43251641, 43378623, 43372481, 43304898, 43263938, 43337667, 43491273, 43263961, 43378652, 43464682, 43466731, 43339761, 43423730, 43284465, 43268088, 43378684]\n"
     ]
    }
   ],
   "source": [
    "#make sure no data leak between sets\n",
    "print(list(set(trainingData.patid.values).intersection(set(valData.patid.values))))\n",
    "print(list(set(trainingData.patid.values).intersection(set(evalData.patid.values))))\n",
    "print(list(set(valData.patid.values).intersection(set(evalData.patid.values))))\n",
    "print(list(set(valData.patid.values).intersection(set(testData.patid.values))))\n",
    "print(list(set(trainingData.patid.values).intersection(set(testData.patid.values))))\n",
    "print(list(set(testData.patid.values).intersection(set(testDataScotland.patid.values)))) # here data leak is expected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a8ae2fa9-09d0-4bdc-ba46-3abec45b4c66",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    0.832165\n",
      "1    0.167835\n",
      "Name: outcome_combined_12months, dtype: float64\n",
      "0    0.8323\n",
      "1    0.1677\n",
      "Name: outcome_combined_12months, dtype: float64\n",
      "0    0.832141\n",
      "1    0.167859\n",
      "Name: outcome_combined_12months, dtype: float64\n",
      "0    0.738431\n",
      "1    0.261569\n",
      "Name: outcome_combined_12months, dtype: float64\n",
      "0    0.738952\n",
      "1    0.261048\n",
      "Name: outcome_combined_12months, dtype: float64\n",
      "0    0.737452\n",
      "1    0.262548\n",
      "Name: outcome_combined_12months, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(trainingData[target_outcome].value_counts(normalize=True))\n",
    "print(valData[target_outcome].value_counts(normalize=True))\n",
    "print(evalData[target_outcome].value_counts(normalize=True))\n",
    "print(testData[target_outcome].value_counts(normalize=True))\n",
    "print(testDataWales[target_outcome].value_counts(normalize=True))\n",
    "print(testDataScotland[target_outcome].value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "25ed906e-adb2-4c91-b2ef-fb50bd84ba3c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# X and y\n",
    "X_train = np.array(trainingData.read_code_seq_padded_idx.values)\n",
    "X_train = np.array([x for x in X_train])\n",
    "X_val = np.array(valData.read_code_seq_padded_idx.values)\n",
    "X_val = np.array([x for x in X_val])\n",
    "X_eval = np.array(evalData.read_code_seq_padded_idx.values)\n",
    "X_eval = np.array([x for x in X_eval])\n",
    "X_test = np.array(testData.read_code_seq_padded_idx.values)\n",
    "X_test = np.array([x for x in X_test])\n",
    "X_testWales = np.array(testDataWales.read_code_seq_padded_idx.values)\n",
    "X_testWales = np.array([x for x in X_testWales])\n",
    "X_testScotland = np.array(testDataScotland.read_code_seq_padded_idx.values)\n",
    "X_testScotland = np.array([x for x in X_testScotland])\n",
    "\n",
    "y_train = trainingData[target_outcome].values\n",
    "y_val = valData[target_outcome].values\n",
    "y_eval = evalData[target_outcome].values\n",
    "y_test = testData[target_outcome].values\n",
    "y_testWales = testDataWales[target_outcome].values\n",
    "y_testScotland = testDataScotland[target_outcome].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "add5e859-7525-40af-966e-02c99c4399af",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:  13412\n",
      "Val:  4192\n",
      "Eval (internal validation):  3354\n",
      "Test:  1491\n",
      "Test - Wales:  973\n",
      "Test - Scotland:  518\n"
     ]
    }
   ],
   "source": [
    "print('Train: ', X_train.shape[0])\n",
    "print('Val: ', X_val.shape[0])\n",
    "print('Eval (internal validation): ', X_eval.shape[0])\n",
    "print('Test: ', X_test.shape[0])\n",
    "print('Test - Wales: ', X_testWales.shape[0])\n",
    "print('Test - Scotland: ', X_testScotland.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "692d48bc-7f2c-49f0-89d3-6ce06ebfb9dd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 1, 1: 4.958240781874722}\n"
     ]
    }
   ],
   "source": [
    "pos_weight = trainingData.outcome_combined_12months.value_counts()[0]/trainingData.outcome_combined_12months.value_counts()[1]\n",
    "class_weight = {0:1, 1:pos_weight}\n",
    "print(class_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afeed10f-72a8-457d-bfcb-f2662e74bfc6",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-25 16:43:53.471826: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-10-25 16:43:53.585752: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-10-25 16:43:53.585805: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-10-25 16:43:53.592016: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-10-25 16:43:53.592112: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-10-25 16:43:53.592158: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-10-25 16:43:54.711939: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-10-25 16:43:54.712023: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-10-25 16:43:54.712031: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1977] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2023-10-25 16:43:54.712066: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-10-25 16:43:54.712084: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 3413 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3060 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 500, 200)          6045800   \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 500, 100)          120400    \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 500, 100)          0         \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 100)               80400     \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 100)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                6464      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6253129 (23.85 MB)\n",
      "Trainable params: 6253129 (23.85 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-25 16:43:57.872704: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f44449d8850 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2023-10-25 16:43:57.872757: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "2023-10-25 16:43:57.899631: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2023-10-25 16:43:57.982362: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "2023-10-25 16:43:57.984009: E ./tensorflow/compiler/xla/stream_executor/stream_executor_internal.h:124] SetPriority unimplemented for this stream.\n",
      "2023-10-25 16:43:57.987538: E ./tensorflow/compiler/xla/stream_executor/stream_executor_internal.h:124] SetPriority unimplemented for this stream.\n",
      "2023-10-25 16:43:57.987994: E ./tensorflow/compiler/xla/stream_executor/stream_executor_internal.h:124] SetPriority unimplemented for this stream.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  1/210 [..............................] - ETA: 9:49 - loss: 1.0365 - auc: 0.4286"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-25 16:43:58.646644: E ./tensorflow/compiler/xla/stream_executor/stream_executor_internal.h:124] SetPriority unimplemented for this stream.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "210/210 [==============================] - 132s 618ms/step - loss: 1.1016 - auc: 0.6375 - val_loss: 0.6520 - val_auc: 0.7186\n",
      "Epoch 2/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/rapids/lib/python3.10/site-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "210/210 [==============================] - 129s 613ms/step - loss: 1.0099 - auc: 0.7278 - val_loss: 0.6327 - val_auc: 0.7000\n",
      "Epoch 3/30\n",
      "210/210 [==============================] - 133s 633ms/step - loss: 0.9657 - auc: 0.7618 - val_loss: 0.6973 - val_auc: 0.7109\n",
      "Epoch 4/30\n",
      " 39/210 [====>.........................] - ETA: 1:43 - loss: 0.9265 - auc: 0.7870"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# create the model\n",
    "embedding_vector_length = 200\n",
    "earlyStopping = EarlyStopping(monitor='val_auc', patience=10, verbose=0, mode='max', restore_best_weights=True)\n",
    "mcp_save = ModelCheckpoint('../SeqModel/seqModel_all.mdl_wts.hdf5', save_best_only=True, monitor='val_auc', mode='min')\n",
    "\n",
    "with tf.device('/CPU:0'):\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(vocab_size, embedding_vector_length, input_length=max_codes))\n",
    "    model.add(LSTM(100, return_sequences=True))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(LSTM(100))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    opt = RMSprop(learning_rate=0.0005)\n",
    "    metrics = [\n",
    "        AUC(num_thresholds=4000, name='auc'),\n",
    "    ]\n",
    "    model.compile(loss='binary_crossentropy', optimizer=opt, metrics=metrics, )\n",
    "    print(model.summary())\n",
    "    history = model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=30, batch_size=64, class_weight = class_weight, callbacks = [earlyStopping, mcp_save])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdbddf77-c941-48d2-9bbd-b80b77d85e5b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# list all data in history\n",
    "print(history.history.keys())\n",
    "# summarize history for accuracy\n",
    "plt.plot(history.history['auc'])\n",
    "plt.plot(history.history['val_auc'])\n",
    "plt.ylim(0.55,1)\n",
    "plt.title('model AUC')\n",
    "plt.ylabel('AUC')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylim(0.1, 1.15)\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20c11344-dfa9-40e6-b2d2-63388d84ba09",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with tf.device('/CPU:0'):\n",
    "    model.evaluate(X_eval, y_eval)\n",
    "    model.evaluate(X_test, y_test)\n",
    "    model.evaluate(X_testWales, y_testWales)\n",
    "    model.evaluate(X_testScotland, y_testScotland)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f7fd35d-2903-48e4-a655-b55f16b99da1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Model evaluation function\n",
    "def summariseResult (testY, preds):\n",
    "    tn, fp, fn, tp = confusion_matrix(testY, preds).ravel()\n",
    "    specificity = tn / (tn+fp)\n",
    "    sensitivity = tp / (tp+fn)\n",
    "    ppv = 100*tp/(tp+fp)\n",
    "    npv = 100*tn/(fn+tn)\n",
    "    acc = accuracy_score(testY, preds)\n",
    "    f1score = f1_score(testY, preds, average = 'binary')\n",
    "    balanceacc = balanced_accuracy_score(testY, preds)\n",
    "    fpr, tpr, thresholds = roc_curve(testY, preds, pos_label=1)\n",
    "    aucscore = auc(fpr, tpr)\n",
    "    # aucscore = roc_auc_score(testY, preds)\n",
    "    auprc = average_precision_score(testY, preds)\n",
    "    # plot_confusion_matrix(model, testX, testY, cmap='viridis')  \n",
    "    return np.round(acc,4), np.round(specificity,4), np.round(sensitivity,4), np.round(aucscore,4), np.round(auprc,4), np.round(balanceacc,4), np.round(f1score,4), np.round(ppv,4), np.round(npv,4)\n",
    "\n",
    "data_test_Xs = [X_eval, X_test, X_testWales, X_testScotland]\n",
    "data_test_ys = [y_eval, y_test, y_testWales, y_testScotland]\n",
    "for data_test_X, data_test_y in zip(data_test_Xs, data_test_ys):\n",
    "    with tf.device('/CPU:0'):\n",
    "        preds = model.predict(data_test_X)\n",
    "    preds = [0 if pred <0.5 else 1 for pred in preds]\n",
    "    print(summariseResult(data_test_y, np.squeeze(preds)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8a50962-2f80-4931-8eb7-df84792130ed",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.save('../SeqModel/model_all.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f9f42bb-89f7-4693-852f-ae329cc7afe7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
