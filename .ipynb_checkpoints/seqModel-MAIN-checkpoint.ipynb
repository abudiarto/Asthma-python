{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cc8032a7-260b-40a8-8cbe-e292ab403047",
   "metadata": {},
   "source": [
    "# LSTM Model using Therapy sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae1286de-3d50-4eb3-b3c7-a4404748f00b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import imdb\n",
    "from tensorflow.keras.models import Sequential, Model, load_model\n",
    "from tensorflow.keras.layers import Dense, LSTM, Embedding, Dropout, Bidirectional, Input, concatenate, Reshape, Activation, Flatten, Add, BatchNormalization, Multiply, LeakyReLU\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau, TensorBoard\n",
    "from tensorflow.keras.metrics import AUC, SensitivityAtSpecificity\n",
    "from tensorflow.keras.optimizers import Adam, Adagrad, RMSprop, Adamax, SGD, Adadelta\n",
    "from tensorflow.keras.initializers import Constant\n",
    "from tensorflow.keras.regularizers import L1L2, L1, L2\n",
    "from livelossplot import PlotLossesKeras\n",
    "#internal validation\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report, f1_score, balanced_accuracy_score, matthews_corrcoef, auc, average_precision_score, roc_auc_score, balanced_accuracy_score, roc_curve, accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "# fix random seed for reproducibility\n",
    "tf.random.set_seed(1234)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9d1e4f0-1280-448d-8df8-55a2dd6648d9",
   "metadata": {},
   "source": [
    "# RUN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2e26e6d-1fba-430e-a954-9676cc730947",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sets =  pickle.load(open('../SeqModel/sets_search_long.sav', 'rb'))\n",
    "sets_eval = pickle.load(open('../SeqModel/sets_search_long_eval.sav', 'rb'))\n",
    "code2idx = pickle.load(open('../SeqModel/all_vocab.sav', 'rb'))\n",
    "month2idx = pickle.load(open('../SeqModel/all_vocab_month.sav', 'rb'))\n",
    "vocab_size = len(code2idx)+1\n",
    "month_size = len(month2idx)+1\n",
    "print(vocab_size)\n",
    "print(month_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6af0a99e-6756-4ac7-81ff-cf991c3d21bd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "Xt_train, Xt_val, Xt_eval, Xs_train, Xs_val, Xs_eval, Xm_train, Xm_val, Xm_eval, y_train, y_val, y_eval = sets\n",
    "Xt_test, Xt_testWales, Xt_testScotland, Xs_test, Xs_testWales, Xs_testScotland, Xm_test, Xm_testWales, Xm_testScotland, y_test, y_testWales, y_testScotland = sets_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "add5e859-7525-40af-966e-02c99c4399af",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print('Train: ', Xs_train.shape[0])\n",
    "print('Val: ', Xs_val.shape[0])\n",
    "print('Eval (internal validation): ', Xs_eval.shape[0])\n",
    "print('Test: ', Xs_test.shape[0])\n",
    "print('Test - Wales: ', Xs_testWales.shape[0])\n",
    "print('Test - Scotland: ', Xs_testScotland.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "692d48bc-7f2c-49f0-89d3-6ce06ebfb9dd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pos_weight = sum(x == 0 for x in y_train)/sum(x == 1 for x in y_train)\n",
    "class_weight = {0:1, 1:pos_weight}\n",
    "print(class_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ef863ce-002a-4913-a8e4-a7492f20c049",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "np.cbrt(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95667606-62df-44a4-a3db-7a440d36947f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "target_outcome = '12months'\n",
    "max_codes = 750\n",
    "tab_feature_size = Xt_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4943f759-cf30-4366-b7c8-bf33fbb73101",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def earlyFussion():\n",
    "       \n",
    "    # inputs1 = Input(shape=tab_feature_size)\n",
    "    inputs2 = Input(shape=max_codes)\n",
    "    inputs3 = Input(shape=max_codes)\n",
    "    \n",
    "    \n",
    "    #clinical embedding for lstm\n",
    "    embedding = Embedding(vocab_size, 75, input_length=max_codes)(inputs2)\n",
    "    \n",
    "    #month embedding for lstm\n",
    "    embedding_month = Embedding(month_size, 7, input_length=max_codes)(inputs3)\n",
    "    \n",
    "    # nn = Dense(32, activation='relu', kernel_initializer='glorot_uniform', kernel_regularizer=L1L2(l1=0.0, l2=0.1))(inputs1)\n",
    "    # nn = Dropout(0.5)(nn)\n",
    "    lstmClinical = Bidirectional(LSTM(units=16, return_sequences=True, kernel_regularizer=L1L2(l1=0.0, l2=0.1)))(embedding)\n",
    "    lstmMonth = Bidirectional(LSTM(units=16, return_sequences=True, kernel_regularizer=L1L2(l1=0.0, l2=0.1)))(embedding_month)\n",
    "    # lstm = Add()([lstmClinical, lstmMonth])\n",
    "    lstm = lstmClinical\n",
    "    \n",
    "    # nn = Reshape((1, 32))(nn)\n",
    "    # add = concatenate([nn, lstm], axis=1)\n",
    "    # nn = Dense(16, activation='relu', kernel_initializer='glorot_uniform', kernel_regularizer=L1L2(l1=0.0, l2=0.1))(nn)\n",
    "    # nn = Dropout(0.5)(nn)\n",
    "    lstm = Bidirectional(LSTM(units=8, return_sequences=True, kernel_regularizer=L1L2(l1=0.0, l2=0.1)))(lstm)\n",
    "    lstm = Dropout(0.5)(lstm)\n",
    "    \n",
    "    # # nn = Reshape((301, 64))(nn)\n",
    "    # add = concatenate([nn, lstm], axis=1)\n",
    "    # nn = Dense(16, activation='relu', kernel_initializer='glorot_uniform', kernel_regularizer=L1L2(l1=0.0, l2=0.1))(nn)\n",
    "    # nn = Dropout(0.5)(nn)\n",
    "    lstm = Bidirectional(LSTM(units=8, return_sequences=True, kernel_regularizer=L1L2(l1=0.0, l2=0.1)))(lstm)\n",
    "    lstm = Dropout(0.5)(lstm)\n",
    "    \n",
    "    # nn = Reshape((1, 16))(nn)\n",
    "    # model_tot = concatenate([nn, lstm], axis=1)\n",
    "    # model_tot = BatchNormalization()(model_tot)\n",
    "\n",
    "    model_tot = Dense(units=8, activation=LeakyReLU())(lstm)\n",
    "    model_tot = Dropout(0.5)(model_tot)\n",
    "    \n",
    "    model_tot = Flatten()(model_tot)\n",
    "    output = Dense(1, activation='sigmoid')(model_tot)\n",
    "    \n",
    "    opt = Adadelta(learning_rate=8e-5, clipvalue=.5)\n",
    "    metrics = [\n",
    "        AUC(num_thresholds=1000, name='auc', curve='ROC'),\n",
    "        AUC(num_thresholds=1000, name='auprc', curve='PR'),\n",
    "        tf.keras.metrics.Precision(name='prec'),\n",
    "        tf.keras.metrics.Recall(name='rec'),\n",
    "        tf.keras.metrics.TrueNegatives(name='TN'),\n",
    "        tf.keras.metrics.TruePositives(name='TP'),\n",
    "        tf.keras.metrics.PrecisionAtRecall(0.8)\n",
    "    ]\n",
    "    \n",
    "    loss = tf.keras.losses.BinaryCrossentropy()\n",
    "    \n",
    "    model = Model(inputs=[inputs2, inputs3], outputs=output)\n",
    "    model.compile(\n",
    "        loss='binary_crossentropy', \n",
    "        optimizer=opt, \n",
    "        metrics=metrics)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1375ac8-eeac-420d-bb0b-3c62b2494cf9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from sklearn.utils import class_weight\n",
    "# sklearn_weights = class_weight.compute_class_weight('balanced', classes=np.unique(y_train), y=y_train)\n",
    "# class_weight = dict(enumerate(sklearn_weights))\n",
    "\n",
    "#Hyperparameter\n",
    "lr = 1e-5\n",
    "clipvalue = 0.2\n",
    "epoch = 1000\n",
    "batch_size = 256\n",
    "embedding_vector_length = 50\n",
    "month_embedding_vector_length = 5\n",
    "# embedding_vector_length = int(np.sqrt(vocab_size))\n",
    "# embedding_vector_length = int(np.cbrt(vocab_size))\n",
    "print(embedding_vector_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bb0d784-620b-44e3-8aeb-c3d39b8dce0a",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "#visualise model\n",
    "model = earlyFussion()\n",
    "# model = earlyFussion()\n",
    "print(model.summary())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71dcd4e8-9bc0-479d-b5ac-ec2488e953ac",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# TF_GPU_ALLOCATOR=cuda_malloc_async\n",
    "#training\n",
    "with tf.device('/GPU:0'):\n",
    "    earlyStopping = EarlyStopping(monitor='val_auc', patience=100, verbose=0, mode='max', restore_best_weights=True)\n",
    "    mcp_save = ModelCheckpoint('../SeqModel/seqModel_therapy_tabSeq.mdl_wts.hdf5', save_best_only=True, monitor='val_auc', mode='min')\n",
    "    history = model.fit([Xs_train[:,:max_codes], Xm_train[:,:max_codes]], y_train, validation_data=([Xs_val[:,:max_codes], Xm_val[:,:max_codes]], y_val), \n",
    "                            epochs=epoch, batch_size=128, \n",
    "                        class_weight = class_weight, \n",
    "                        callbacks = [earlyStopping, mcp_save])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afeed10f-72a8-457d-bfcb-f2662e74bfc6",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# %%time\n",
    "\n",
    "# # create the model\n",
    "# embedding_vector_length = 50\n",
    "# earlyStopping = EarlyStopping(monitor='val_auc', patience=10, verbose=0, mode='max', restore_best_weights=True)\n",
    "# mcp_save = ModelCheckpoint('../SeqModel/seqModel_therapy.mdl_wts.hdf5', save_best_only=True, monitor='val_auc', mode='min')\n",
    "\n",
    "# with tf.device('/GPU:0'):\n",
    "#     model = Sequential()\n",
    "#     model.add(Embedding(vocab_size, embedding_vector_length, input_length=max_codes))\n",
    "#     model.add(LSTM(128, return_sequences=True, kernel_regularizer=L1L2(l1=0.02, l2=0.03)))\n",
    "#     model.add(Dropout(0.5))\n",
    "#     model.add(LSTM(64,  kernel_regularizer=L1L2(l1=0.02, l2=0.03)))\n",
    "#     model.add(Dropout(0.5))\n",
    "#     model.add(Dense(32, activation=LeakyReLU(alpha=.3), kernel_regularizer=L1L2(l1=0.02, l2=0.03)))\n",
    "#     model.add(Dense(1, activation='sigmoid'))\n",
    "#     opt = Adadelta(learning_rate=5e-3, clipvalue=0.3)\n",
    "#     metrics = [\n",
    "#         AUC(num_thresholds=3, name='auc'),\n",
    "#     ]\n",
    "#     model.compile(loss='binary_crossentropy', optimizer=opt, metrics=metrics, )\n",
    "#     print(model.summary())\n",
    "#     history = model.fit(Xs_train, y_train, validation_data=(Xs_val, y_val), epochs=30, batch_size=128, class_weight = class_weight, callbacks = [earlyStopping, mcp_save])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdbddf77-c941-48d2-9bbd-b80b77d85e5b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# list all data in history\n",
    "print(history.history.keys())\n",
    "# summarize history for accuracy\n",
    "plt.plot(history.history['auc'])\n",
    "plt.plot(history.history['val_auc'])\n",
    "plt.title('model AUC')\n",
    "plt.ylabel('AUC')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "# plt.ylim(0.3, 1)\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(history.history['auprc'])\n",
    "plt.plot(history.history['val_auprc'])\n",
    "plt.title('model auprc')\n",
    "# plt.ylim(0.3, 1)\n",
    "plt.ylabel('auprc')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28c5fa1e-8204-469e-87fb-dea80b4c493f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "preds = model.predict([Xs_eval[:,:max_codes], Xm_eval[:,:max_codes]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73976443-4e78-45d5-93e7-a776a2960b79",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "preds_smooth = [0 if x < .48 else 1 for x in preds]\n",
    "print(confusion_matrix(y_eval, preds_smooth))\n",
    "print(roc_auc_score(y_eval, preds_smooth))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11ed267b-cefa-47b7-baac-0972a2447ab3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fpr, tpr, thresholds = roc_curve(y_eval, preds, pos_label=1, drop_intermediate=False)\n",
    "auc(fpr, tpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20c11344-dfa9-40e6-b2d2-63388d84ba09",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with tf.device('/GPU:0'):\n",
    "    model.evaluate([Xt_eval, Xs_eval[:,:max_codes], Xm_eval[:,:max_codes]], y_eval)\n",
    "    model.evaluate([Xt_test, Xs_test[:,:max_codes], Xm_test[:,:max_codes]], y_test)\n",
    "    # model.evaluate(X_testWales, y_testWales)\n",
    "    # model.evaluate(X_testScotland, y_testScotland)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f7fd35d-2903-48e4-a655-b55f16b99da1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Model evaluation function\n",
    "def summariseResult (testY, preds):\n",
    "    tn, fp, fn, tp = confusion_matrix(testY, preds).ravel()\n",
    "    specificity = tn / (tn+fp)\n",
    "    sensitivity = tp / (tp+fn)\n",
    "    ppv = 100*tp/(tp+fp)\n",
    "    npv = 100*tn/(fn+tn)\n",
    "    acc = accuracy_score(testY, preds)\n",
    "    f1score = f1_score(testY, preds, average = 'binary')\n",
    "    balanceacc = balanced_accuracy_score(testY, preds)\n",
    "    fpr, tpr, thresholds = roc_curve(testY, preds, pos_label=1)\n",
    "    aucscore = auc(fpr, tpr)\n",
    "    # aucscore = roc_auc_score(testY, preds)\n",
    "    auprc = average_precision_score(testY, preds)\n",
    "    # plot_confusion_matrix(model, testX, testY, cmap='viridis')  \n",
    "    return np.round(acc,4), np.round(specificity,4), np.round(sensitivity,4), np.round(aucscore,4), np.round(auprc,4), np.round(balanceacc,4), np.round(f1score,4), np.round(ppv,4), np.round(npv,4)\n",
    "\n",
    "data_test_Xs = [X_eval, X_test, X_testWales, X_testScotland]\n",
    "data_test_ys = [y_eval, y_test, y_testWales, y_testScotland]\n",
    "for data_test_X, data_test_y in zip(data_test_Xs, data_test_ys):\n",
    "    with tf.device('/CPU:0'):\n",
    "        preds = model.predict(data_test_X)\n",
    "    preds = [0 if pred <0.5 else 1 for pred in preds]\n",
    "    print(summariseResult(data_test_y, np.squeeze(preds)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8a50962-2f80-4931-8eb7-df84792130ed",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.save('../SeqModel/model_therapy.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1adb28e-44a2-4303-8b79-25348bfcaad9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from keras.models import load_model\n",
    "# a = load_model('../SeqModel/my_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f9f42bb-89f7-4693-852f-ae329cc7afe7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
