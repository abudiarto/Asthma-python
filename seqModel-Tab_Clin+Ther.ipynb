{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cc8032a7-260b-40a8-8cbe-e292ab403047",
   "metadata": {},
   "source": [
    "# combine tabular data with seq of clinical and therapy readcodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ae1286de-3d50-4eb3-b3c7-a4404748f00b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-10 00:44:09.717910: I tensorflow/core/util/port.cc:111] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-12-10 00:44:09.785488: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-12-10 00:44:09.785545: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-12-10 00:44:09.785578: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-12-10 00:44:09.799694: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import imdb\n",
    "from tensorflow.keras.models import Sequential, Model, load_model\n",
    "from tensorflow.keras.layers import Dense, LSTM, Embedding, Dropout, Bidirectional, Input, concatenate, Reshape, Activation, Flatten, Add, BatchNormalization, Multiply, LeakyReLU\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau, TensorBoard\n",
    "from tensorflow.keras.metrics import AUC, SensitivityAtSpecificity\n",
    "from tensorflow.keras.optimizers import Adam, Adagrad, RMSprop, Adamax, SGD, Adadelta\n",
    "from tensorflow.keras.initializers import Constant\n",
    "from tensorflow.keras.regularizers import L1L2, L1, L2\n",
    "from livelossplot import PlotLossesKeras\n",
    "#internal validation\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report, f1_score, balanced_accuracy_score, matthews_corrcoef, auc, average_precision_score, roc_auc_score, balanced_accuracy_score, roc_curve, accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "# fix random seed for reproducibility\n",
    "tf.random.set_seed(1234)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96b6e815-ba3e-471b-ba0e-efb907dfed14",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Load tabular data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "12e5a964-b378-45ee-a3f1-30c4a35dda53",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Data loader\n",
    "# trainingData = pd.read_csv('../FinalData/trainingDataEncoded_08102023.csv')\n",
    "# validationData = pd.read_csv('../FinalData/validationDataEncoded_08102023.csv')\n",
    "# evaluationData = pd.read_csv('../FinalData/evaluationDataEncoded_08102023.csv')\n",
    "# evaluationDataWales = pd.read_csv('../FinalData/evaluationDataWalesEncoded_08102023.csv')\n",
    "# evaluationDataScotland = pd.read_csv('../FinalData/evaluationDataScotlandEncoded_08102023.csv')\n",
    "\n",
    "trainingData, validationData, internalEvaluationData, evaluationData, evaluationDataWales, evaluationDataScotland = pickle.load(open('../FinalData/dataset_scaled_2vs1_09122023.sav', 'rb'))\n",
    "\n",
    "trainingData = trainingData[(trainingData.age >=8) & (trainingData.age <=80)]\n",
    "validationData = validationData[(validationData.age >=8) & (validationData.age <=80)]\n",
    "internalEvaluationData = internalEvaluationData[(internalEvaluationData.age >=8) & (internalEvaluationData.age <=80)]\n",
    "evaluationData = evaluationData[(evaluationData.age >=8) & (evaluationData.age <=80)]\n",
    "evaluationDataWales = evaluationDataWales[(evaluationDataWales.age >=8) & (evaluationDataWales.age <=80)]\n",
    "evaluationDataScotland = evaluationDataScotland[(evaluationDataScotland.age >=8) & (evaluationDataScotland.age <=80)]\n",
    "\n",
    "\n",
    "trainingData = trainingData.rename({'3MonthsOutcome': '3months', '6MonthsOutcome': '6months','9MonthsOutcome': '9months','12MonthsOutcome': '12months',}, axis=1)\n",
    "validationData = validationData.rename({'3MonthsOutcome': '3months', '6MonthsOutcome': '6months','9MonthsOutcome': '9months','12MonthsOutcome': '12months',}, axis=1)\n",
    "internalEvaluationData = internalEvaluationData.rename({'3MonthsOutcome': '3months', '6MonthsOutcome': '6months','9MonthsOutcome': '9months','12MonthsOutcome': '12months',}, axis=1)\n",
    "evaluationData = evaluationData.rename({'3MonthsOutcome': '3months', '6MonthsOutcome': '6months','9MonthsOutcome': '9months','12MonthsOutcome': '12months',}, axis=1)\n",
    "evaluationDataWales = evaluationDataWales.rename({'3MonthsOutcome': '3months', '6MonthsOutcome': '6months','9MonthsOutcome': '9months','12MonthsOutcome': '12months',}, axis=1)\n",
    "evaluationDataScotland = evaluationDataScotland.rename({'3MonthsOutcome': '3months', '6MonthsOutcome': '6months','9MonthsOutcome': '9months','12MonthsOutcome': '12months',}, axis=1)\n",
    "\n",
    "# trainingData = trainingData.rename({'outcome_3months': '3months', 'outcome_combined_6months': '6months','outcome_combined_12months': '12months','outcome_combined_24months': '24months',}, axis=1)\n",
    "# validationData = validationData.rename({'outcome_3months': '3months', 'outcome_combined_6months': '6months','outcome_combined_12months': '12months','outcome_combined_24months': '24months',}, axis=1)\n",
    "# internalEvaluationData = internalEvaluationData.rename({'outcome_3months': '3months', 'outcome_combined_6months': '6months','outcome_combined_12months': '12months','outcome_combined_24months': '24months',}, axis=1)\n",
    "# evaluationData = evaluationData.rename({'outcome_3months': '3months', 'outcome_combined_6months': '6months','outcome_combined_12months': '12months','outcome_combined_24months': '24months',}, axis=1)\n",
    "# evaluationDataWales = evaluationDataWales.rename({'outcome_3months': '3months', 'outcome_combined_6months': '6months','outcome_combined_12months': '12months','outcome_combined_24months': '24months',}, axis=1)\n",
    "# evaluationDataScotland = evaluationDataScotland.rename({'outcome_3months': '3months', 'outcome_combined_6months': '6months','outcome_combined_12months': '12months','outcome_combined_24months': '24months',}, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "293e45cc-eb7f-4fee-89d8-a8081c0151d1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features size:  67\n",
      "['sex', 'age', 'CharlsonScore', 'BTS_step', 'average_daily_dose_ICS', 'prescribed_daily_dose_ICS', 'ICS_medication_possesion_ratio', 'numOCS', 'PriorEducation', 'numPCS', 'numPCSAsthma', 'numAntibioticsEvents', 'numAntibioticswithLRTI', 'numOCSwithLRTI', 'numAsthmaAttacks', 'numAcuteRespEvents', 'numHospEvents', 'rhinitis', 'cardiovascular', 'heartfailure', 'psoriasis', 'anaphylaxis', 'diabetes', 'ihd', 'anxiety', 'eczema', 'nasalpolyps', 'ethnic_group_Asian - ethnic group', 'ethnic_group_Black - ethnic group', 'ethnic_group_Mixed ethnic census group', 'ethnic_group_Other ethnic group', 'ethnic_group_White - ethnic group', 'ethnic_group_not_recorded', 'smokingStatus_Active Smoker', 'smokingStatus_Former Smoker', 'smokingStatus_Non Smoker', 'DeviceType_BAI', 'DeviceType_DPI', 'DeviceType_NEB', 'DeviceType_pMDI', 'DeviceType_unknown', 'cat_BMI_normal', 'cat_BMI_not recorded', 'cat_BMI_obese', 'cat_BMI_overweight', 'cat_BMI_underweight', 'imd_decile_0', 'imd_decile_1', 'imd_decile_2', 'imd_decile_3', 'imd_decile_4', 'imd_decile_5', 'imd_decile_6', 'imd_decile_7', 'imd_decile_8', 'imd_decile_9', 'imd_decile_10', 'PEFStatus_60-80', 'PEFStatus_less than 60', 'PEFStatus_more than 80', 'PEFStatus_not_recorded', 'EosinophilLevel_high', 'EosinophilLevel_normal', 'EosinophilLevel_unknown', 'system_EMIS', 'system_SystemOne', 'system_Vision']\n"
     ]
    }
   ],
   "source": [
    "#Define feature candidates\n",
    "\n",
    "features_columns = trainingData.columns.to_list()\n",
    "exclude_columns = ['patid', 'practice_id', #identifier\n",
    "                   'BMI', #use the categorical instead\n",
    "                   'ethnicity', #use ethnic_group instead\n",
    "                   'Spacer',  #all zero\n",
    "                   \n",
    "                   'outcome_3months', 'outcome_6months', 'outcome_9months', 'outcome_12months', 'outcome_15months', 'outcome_18months', \n",
    "                   'outcome_21months', 'outcome_24months', 'outcome_combined_6months', 'outcome_combined_9months', 'outcome_combined_12months', \n",
    "                   'outcome_combined_15months', 'outcome_combined_18months', 'outcome_combined_24months', '3months', '6months', '9months', '12months', '24months', #outcomes variable\n",
    "                   \n",
    "                   'postcode_district', 'County', 'LocalAuthority', 'OutputAreaClassification', #location related variables, use IMD decile only\n",
    "                   \n",
    "                   'cat_age', 'cat_average_daily_dose_ICS', 'cat_prescribed_daily_dose_ICS', 'cat_ICS_medication_possesion_ratio', 'cat_numOCS', 'cat_numOCSEvents', \n",
    "                   'cat_numOCSwithLRTI', 'cat_numAcuteRespEvents', 'cat_numAntibioticsEvents', 'cat_numAntibioticswithLRTI', 'cat_numAsthmaAttacks', 'cat_numHospEvents', \n",
    "                   'cat_numPCS', 'cat_numPCSAsthma', #use continous vars instead\n",
    "                   \n",
    "                   'count_rhinitis', 'count_cardiovascular', 'count_heartfailure',\n",
    "                   'count_psoriasis', 'count_anaphylaxis', 'count_diabetes', 'count_ihd',\n",
    "                   'count_anxiety', 'count_eczema', 'count_nasalpolyps',\n",
    "                   'count_paracetamol', 'count_nsaids', 'count_betablocker', #use binary ones\n",
    "                   \n",
    "                   'paracetamol', 'nsaids', 'betablocker', #no data in evaluation\n",
    "                   \n",
    "                   'numOCSEvents', #duplicate with numOCS\n",
    "                   \n",
    "                   'month_12', 'month_4', 'month_5', 'month_10', 'month_1', 'month_6', 'month_3', \n",
    "                   'month_11', 'month_8', 'month_9', 'month_7', 'month_2', #month of attacks\n",
    "                   \n",
    "                   # 'system_EMIS', 'system_SystemOne', 'system_Vision', #primary care system used\n",
    "                  ]\n",
    "exclude_columns = exclude_columns + [x for x in features_columns if '_count' in x] #filter out commorbid count variables\n",
    "features_columns = [x for x in features_columns if x not in exclude_columns]\n",
    "print('Features size: ', len(features_columns))\n",
    "print(features_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9d1e4f0-1280-448d-8df8-55a2dd6648d9",
   "metadata": {},
   "source": [
    "# load sequence data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ba0cdd2d-5347-47e4-8435-5d80018fdba8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "clinical = pd.read_feather('../SeqModel/all_data_clinical.feather')\n",
    "therapy = pd.read_feather('../SeqModel/all_data_therapy.feather')\n",
    "seqCols = ['patid',\n",
    "       'read_code_seq_padded_end_idx_clin',\n",
    "       'month_padded_idx_end_clin',\n",
    "       'read_code_seq_padded_end_idx_ther',\n",
    "       'month_padded_idx_end_ther']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d72b417e-3671-414a-ab47-dbe548316101",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sequence_data = clinical.merge(therapy[['patid', 'read_code_seq_padded_idx', 'read_code_seq_padded_end_idx',\n",
    "       'month_padded_idx', 'month_padded_idx_end']], on='patid', suffixes=['_clin', '_ther'], how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "25f21cb5-e88b-4f4e-b2ea-72ef9034ca48",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "trainingData = trainingData.merge(sequence_data[seqCols], on='patid', how='inner')\n",
    "validationData = validationData.merge(sequence_data[seqCols], on='patid', how='inner')\n",
    "internalEvaluationData = internalEvaluationData.merge(sequence_data[seqCols], on='patid', how='inner')\n",
    "evaluationData = evaluationData.merge(sequence_data[seqCols], on='patid', how='inner')\n",
    "evaluationDataWales = evaluationDataWales.merge(sequence_data[seqCols], on='patid', how='inner')\n",
    "evaluationDataScotland = evaluationDataScotland.merge(sequence_data[seqCols], on='patid', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1ee6b74c-ad65-4e0b-bc67-d8e9d3fd02a1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(127450, 131)\n",
      "(39675, 131)\n",
      "(31980, 131)\n",
      "(8044, 131)\n",
      "(5359, 131)\n",
      "(2685, 131)\n"
     ]
    }
   ],
   "source": [
    "print(trainingData.shape)\n",
    "print(validationData.shape)\n",
    "print(internalEvaluationData.shape)\n",
    "print(evaluationData.shape)\n",
    "print(evaluationDataWales.shape)\n",
    "print(evaluationDataScotland.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ec6b20f0-4a38-45fe-a059-8d4b8aca7988",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(127450, 67)\n",
      "(31980, 67)\n",
      "(39675, 67)\n",
      "(8044, 67)\n",
      "(5359, 67)\n",
      "(2685, 67)\n"
     ]
    }
   ],
   "source": [
    "Xt_train = np.array(trainingData[features_columns].values)\n",
    "Xt_val = np.array(validationData[features_columns].values)\n",
    "Xt_internaleval = np.array(internalEvaluationData[features_columns].values)\n",
    "Xt_eval = np.array(evaluationData[features_columns].values)\n",
    "Xt_eval_Wales = np.array(evaluationDataWales[features_columns].values)\n",
    "Xt_eval_Scotland = np.array(evaluationDataScotland[features_columns].values)\n",
    "\n",
    "#scalling tabular data\n",
    "scaler = StandardScaler().fit(Xt_train)\n",
    "Xt_train = scaler.transform(Xt_train)\n",
    "Xt_val = scaler.transform(Xt_val)\n",
    "Xt_internaleval = scaler.transform(Xt_internaleval)\n",
    "Xt_eval = scaler.transform(Xt_eval)\n",
    "Xt_eval_Wales = scaler.transform(Xt_eval_Wales)\n",
    "Xt_eval_Scotland = scaler.transform(Xt_eval_Scotland)\n",
    "\n",
    "Xclin_train = np.array(trainingData['read_code_seq_padded_end_idx_clin'].values)\n",
    "Xclin_val = np.array(validationData['read_code_seq_padded_end_idx_clin'].values)\n",
    "Xclin_internaleval = np.array(internalEvaluationData['read_code_seq_padded_end_idx_clin'].values)\n",
    "Xclin_eval = np.array(evaluationData['read_code_seq_padded_end_idx_clin'].values)\n",
    "Xclin_eval_Wales = np.array(evaluationDataWales['read_code_seq_padded_end_idx_clin'].values)\n",
    "Xclin_eval_Scotland = np.array(evaluationDataScotland['read_code_seq_padded_end_idx_clin'].values)\n",
    "Xclin_train = np.array([x for x in Xclin_train])\n",
    "Xclin_val = np.array([x for x in Xclin_val])\n",
    "Xclin_internaleval = np.array([x for x in Xclin_internaleval])\n",
    "Xclin_eval = np.array([x for x in Xclin_eval])\n",
    "Xclin_eval_Wales = np.array([x for x in Xclin_eval_Wales])\n",
    "Xclin_eval_Scotland = np.array([x for x in Xclin_eval_Scotland])\n",
    "\n",
    "Xther_train = np.array(trainingData['read_code_seq_padded_end_idx_ther'].values)\n",
    "Xther_val = np.array(validationData['read_code_seq_padded_end_idx_ther'].values)\n",
    "Xther_internaleval = np.array(internalEvaluationData['read_code_seq_padded_end_idx_ther'].values)\n",
    "Xther_eval = np.array(evaluationData['read_code_seq_padded_end_idx_ther'].values)\n",
    "Xther_eval_Wales = np.array(evaluationDataWales['read_code_seq_padded_end_idx_ther'].values)\n",
    "Xther_eval_Scotland = np.array(evaluationDataScotland['read_code_seq_padded_end_idx_ther'].values)\n",
    "Xther_train = np.array([x for x in Xther_train])\n",
    "Xther_val = np.array([x for x in Xther_val])\n",
    "Xther_internaleval = np.array([x for x in Xther_internaleval])\n",
    "Xther_eval = np.array([x for x in Xther_eval])\n",
    "Xther_eval_Wales = np.array([x for x in Xther_eval_Wales])\n",
    "Xther_eval_Scotland = np.array([x for x in Xther_eval_Scotland])\n",
    "\n",
    "\n",
    "\n",
    "print(Xt_train.shape)\n",
    "print(Xt_internaleval.shape)\n",
    "print(Xt_val.shape)\n",
    "print(Xt_eval.shape)\n",
    "print(Xt_eval_Wales.shape)\n",
    "print(Xt_eval_Scotland.shape)\n",
    "\n",
    "# target_outcomes = ['3months', '6months', '12months', '24months'] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f2e26e6d-1fba-430e-a954-9676cc730947",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51644\n",
      "10709\n",
      "13\n"
     ]
    }
   ],
   "source": [
    "#vocab\n",
    "code2idx_clin = pickle.load(open('../SeqModel/all_vocab_clinical.sav', 'rb'))\n",
    "code2idx_ther = pickle.load(open('../SeqModel/all_vocab_therapy.sav', 'rb'))\n",
    "month2idx = pickle.load(open('../SeqModel/all_vocab_month.sav', 'rb'))\n",
    "vocab_size_clinical = len(code2idx_clin)+1\n",
    "vocab_size_therapy = len(code2idx_ther)+1\n",
    "month_size = len(month2idx)+1\n",
    "print(vocab_size_clinical)\n",
    "print(vocab_size_therapy)\n",
    "print(month_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "95667606-62df-44a4-a3db-7a440d36947f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 1, 1: 5.418068284822238}\n"
     ]
    }
   ],
   "source": [
    "target_outcome = '12months'\n",
    "max_codes_clin = Xclin_train.shape[1]\n",
    "max_codes_ther = Xther_train.shape[1]\n",
    "tab_feature_size = Xt_train.shape[1]\n",
    "\n",
    "y_train = trainingData[target_outcome].values\n",
    "y_val = validationData[target_outcome].values\n",
    "y_internaleval = internalEvaluationData[target_outcome].values\n",
    "y_eval = evaluationData[target_outcome].values\n",
    "y_eval_Wales = evaluationDataWales[target_outcome].values\n",
    "y_eval_Scotland = evaluationDataScotland[target_outcome].values\n",
    "\n",
    "pos_weight = sum(x == 0 for x in y_train)/sum(x == 1 for x in y_train)\n",
    "class_weight = {0:1, 1:pos_weight}\n",
    "print(class_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ff45f82c-62f0-4eab-8a38-1f6519f8d2e5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def hierarchical():\n",
    "    #tabular dara - demography   \n",
    "    inputs1 = Input(shape=tab_feature_size)\n",
    "    nn = Dense(32, activation='relu', kernel_initializer='glorot_uniform', kernel_regularizer=L1L2(l1=0.0, l2=0.1))(inputs1)\n",
    "    nn = Dropout(0.5)(nn)\n",
    "    \n",
    "    #clinical embedding for lstm\n",
    "    inputs2 = Input(shape=max_codes_clin)\n",
    "    embedding_clin = Embedding(vocab_size_clinical, int(np.cbrt(vocab_size_clinical)), input_length=max_codes_clin)(inputs2)\n",
    "    lstmClinical = Bidirectional(LSTM(units=16, return_sequences=True, kernel_regularizer=L1L2(l1=0.0, l2=0.1)))(embedding_clin)\n",
    "    \n",
    "    \n",
    "    ###Layer 1 - merge tab and lstm clin\n",
    "    nn = Reshape((1, 32))(nn)\n",
    "    add = concatenate([nn, lstmClinical], axis=1)\n",
    "    \n",
    "    \n",
    "    #therapy embedding for lstm\n",
    "    inputs3 = Input(shape=max_codes_ther)\n",
    "    embedding_ther = Embedding(vocab_size_therapy, int(np.cbrt(vocab_size_therapy)), input_length=max_codes_ther)(inputs3)\n",
    "    lstmTherapy = Bidirectional(LSTM(units=16, return_sequences=True, kernel_regularizer=L1L2(l1=0.0, l2=0.1)))(embedding_ther)\n",
    "    \n",
    "    ###Layer 2 - merge add (tab+clin) and lstm ther\n",
    "    add = concatenate([add, lstmTherapy], axis=1)\n",
    "    \n",
    "    ###layer 3 - LSTM to the final product\n",
    "    lstm = Bidirectional(LSTM(units=8, return_sequences=True, kernel_regularizer=L1L2(l1=0.0, l2=0.1)))(add)\n",
    "    lstm = Dropout(0.5)(lstm)\n",
    "    \n",
    "    \n",
    "    ###layer 4 - FCN before classification layer\n",
    "    final = Dense(units=8, activation=LeakyReLU())(lstm)\n",
    "    final = Flatten()(final)\n",
    "    finalr = Dropout(0.5)(final)\n",
    "    \n",
    "    ###layer 5 - classification layer\n",
    "    output = Dense(1, activation='sigmoid')(final)\n",
    "    \n",
    "    opt = RMSprop(learning_rate=1e-3, clipvalue=.5)\n",
    "    metrics = [\n",
    "        AUC(num_thresholds=1000, name='auc', curve='ROC'),\n",
    "        AUC(num_thresholds=1000, name='auprc', curve='PR'),\n",
    "        tf.keras.metrics.Precision(name='prec'),\n",
    "        tf.keras.metrics.Recall(name='rec'),\n",
    "        tf.keras.metrics.TrueNegatives(name='TN'),\n",
    "        tf.keras.metrics.TruePositives(name='TP'),\n",
    "        tf.keras.metrics.PrecisionAtRecall(0.8)\n",
    "    ]\n",
    "    \n",
    "    loss = tf.keras.losses.BinaryCrossentropy()\n",
    "    \n",
    "    model = Model(inputs=[inputs1, inputs2, inputs3], outputs=output)\n",
    "    model.compile(\n",
    "        loss='binary_crossentropy', \n",
    "        optimizer=opt, \n",
    "        metrics=metrics)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b1375ac8-eeac-420d-bb0b-3c62b2494cf9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n"
     ]
    }
   ],
   "source": [
    "# from sklearn.utils import class_weight\n",
    "# sklearn_weights = class_weight.compute_class_weight('balanced', classes=np.unique(y_train), y=y_train)\n",
    "# class_weight = dict(enumerate(sklearn_weights))\n",
    "\n",
    "#Hyperparameter\n",
    "lr = 1e-5\n",
    "clipvalue = 0.2\n",
    "epoch = 1000\n",
    "batch_size = 256\n",
    "embedding_vector_length = 50\n",
    "month_embedding_vector_length = 5\n",
    "# embedding_vector_length = int(np.sqrt(vocab_size))\n",
    "# embedding_vector_length = int(np.cbrt(vocab_size))\n",
    "print(embedding_vector_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4bb0d784-620b-44e3-8aeb-c3d39b8dce0a",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-10 01:14:47.669300: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-12-10 01:14:47.780879: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-12-10 01:14:47.780931: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-12-10 01:14:47.784578: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-12-10 01:14:47.784633: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-12-10 01:14:47.784646: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-12-10 01:14:50.682624: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-12-10 01:14:50.682678: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-12-10 01:14:50.682686: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1977] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2023-12-10 01:14:50.682758: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-12-10 01:14:50.682798: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 637 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3060 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n",
      "2023-12-10 01:14:52.136281: I tensorflow/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)        [(None, 67)]                 0         []                            \n",
      "                                                                                                  \n",
      " dense (Dense)               (None, 32)                   2176      ['input_1[0][0]']             \n",
      "                                                                                                  \n",
      " input_2 (InputLayer)        [(None, 62)]                 0         []                            \n",
      "                                                                                                  \n",
      " dropout (Dropout)           (None, 32)                   0         ['dense[0][0]']               \n",
      "                                                                                                  \n",
      " embedding (Embedding)       (None, 62, 37)               1910828   ['input_2[0][0]']             \n",
      "                                                                                                  \n",
      " input_3 (InputLayer)        [(None, 129)]                0         []                            \n",
      "                                                                                                  \n",
      " reshape (Reshape)           (None, 1, 32)                0         ['dropout[0][0]']             \n",
      "                                                                                                  \n",
      " bidirectional (Bidirection  (None, 62, 32)               6912      ['embedding[0][0]']           \n",
      " al)                                                                                              \n",
      "                                                                                                  \n",
      " embedding_1 (Embedding)     (None, 129, 22)              235598    ['input_3[0][0]']             \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)   (None, 63, 32)               0         ['reshape[0][0]',             \n",
      "                                                                     'bidirectional[0][0]']       \n",
      "                                                                                                  \n",
      " bidirectional_1 (Bidirecti  (None, 129, 32)              4992      ['embedding_1[0][0]']         \n",
      " onal)                                                                                            \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate  (None, 192, 32)              0         ['concatenate[0][0]',         \n",
      " )                                                                   'bidirectional_1[0][0]']     \n",
      "                                                                                                  \n",
      " bidirectional_2 (Bidirecti  (None, 192, 16)              2624      ['concatenate_1[0][0]']       \n",
      " onal)                                                                                            \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)         (None, 192, 16)              0         ['bidirectional_2[0][0]']     \n",
      "                                                                                                  \n",
      " dense_1 (Dense)             (None, 192, 8)               136       ['dropout_1[0][0]']           \n",
      "                                                                                                  \n",
      " flatten (Flatten)           (None, 1536)                 0         ['dense_1[0][0]']             \n",
      "                                                                                                  \n",
      " dense_2 (Dense)             (None, 1)                    1537      ['flatten[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 2164803 (8.26 MB)\n",
      "Trainable params: 2164803 (8.26 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#visualise model\n",
    "model = hierarchical()\n",
    "# model = earlyFussion()\n",
    "print(model.summary())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "71dcd4e8-9bc0-479d-b5ac-ec2488e953ac",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-10 01:15:51.838199: W tensorflow/core/framework/op_kernel.cc:1839] OP_REQUIRES failed at xla_ops.cc:562 : INVALID_ARGUMENT: Trying to access resource Resource-25-at-0x558aeba265c0 (defined @ /opt/conda/envs/rapids/lib/python3.10/site-packages/keras/src/engine/base_layer_utils.py:137) located in device /job:localhost/replica:0/task:0/device:GPU:0 from device /job:localhost/replica:0/task:0/device:CPU:0\n",
      " Cf. https://www.tensorflow.org/xla/known_issues#tfvariable_on_a_different_device\n",
      "2023-12-10 01:15:51.838288: W tensorflow/core/framework/op_kernel.cc:1839] OP_REQUIRES failed at xla_ops.cc:562 : INVALID_ARGUMENT: Trying to access resource Resource-24-at-0x558aecadb460 (defined @ /opt/conda/envs/rapids/lib/python3.10/site-packages/keras/src/engine/base_layer_utils.py:137) located in device /job:localhost/replica:0/task:0/device:GPU:0 from device /job:localhost/replica:0/task:0/device:CPU:0\n",
      " Cf. https://www.tensorflow.org/xla/known_issues#tfvariable_on_a_different_device\n",
      "2023-12-10 01:15:51.838323: I tensorflow/core/framework/local_rendezvous.cc:421] Local rendezvous recv item cancelled. Key hash: 9630860234517447660\n",
      "2023-12-10 01:15:51.838337: I tensorflow/core/framework/local_rendezvous.cc:421] Local rendezvous recv item cancelled. Key hash: 2932178060672697796\n",
      "2023-12-10 01:15:51.838345: I tensorflow/core/framework/local_rendezvous.cc:421] Local rendezvous recv item cancelled. Key hash: 748771795955205682\n",
      "2023-12-10 01:15:51.838358: I tensorflow/core/framework/local_rendezvous.cc:421] Local rendezvous recv item cancelled. Key hash: 682371761805763057\n",
      "2023-12-10 01:15:51.838366: I tensorflow/core/framework/local_rendezvous.cc:421] Local rendezvous recv item cancelled. Key hash: 12898502487656908329\n",
      "2023-12-10 01:15:51.838373: I tensorflow/core/framework/local_rendezvous.cc:421] Local rendezvous recv item cancelled. Key hash: 10640547113051915889\n",
      "2023-12-10 01:15:51.838380: I tensorflow/core/framework/local_rendezvous.cc:421] Local rendezvous recv item cancelled. Key hash: 8343308523747469627\n",
      "2023-12-10 01:15:51.838388: I tensorflow/core/framework/local_rendezvous.cc:421] Local rendezvous recv item cancelled. Key hash: 413578398671743743\n",
      "2023-12-10 01:15:51.838395: I tensorflow/core/framework/local_rendezvous.cc:421] Local rendezvous recv item cancelled. Key hash: 10505542632849402763\n",
      "2023-12-10 01:15:51.838403: I tensorflow/core/framework/local_rendezvous.cc:421] Local rendezvous recv item cancelled. Key hash: 4547245000219610759\n",
      "2023-12-10 01:15:51.838418: I tensorflow/core/framework/local_rendezvous.cc:421] Local rendezvous recv item cancelled. Key hash: 13770265389360352779\n",
      "2023-12-10 01:15:51.838426: I tensorflow/core/framework/local_rendezvous.cc:421] Local rendezvous recv item cancelled. Key hash: 7837732137507333711\n",
      "2023-12-10 01:15:51.838434: I tensorflow/core/framework/local_rendezvous.cc:421] Local rendezvous recv item cancelled. Key hash: 6521977877416366549\n",
      "2023-12-10 01:15:51.838441: I tensorflow/core/framework/local_rendezvous.cc:421] Local rendezvous recv item cancelled. Key hash: 10027283010255263653\n",
      "2023-12-10 01:15:51.838449: I tensorflow/core/framework/local_rendezvous.cc:421] Local rendezvous recv item cancelled. Key hash: 13614649580505504031\n",
      "2023-12-10 01:15:51.838503: I tensorflow/core/framework/local_rendezvous.cc:421] Local rendezvous recv item cancelled. Key hash: 6615719952761035443\n",
      "2023-12-10 01:15:51.838561: I tensorflow/core/framework/local_rendezvous.cc:421] Local rendezvous recv item cancelled. Key hash: 4953941951163418538\n",
      "2023-12-10 01:15:51.838591: I tensorflow/core/framework/local_rendezvous.cc:421] Local rendezvous recv item cancelled. Key hash: 8507673345606321764\n",
      "2023-12-10 01:15:51.838600: I tensorflow/core/framework/local_rendezvous.cc:421] Local rendezvous recv item cancelled. Key hash: 6397237021083913374\n",
      "2023-12-10 01:15:51.838608: I tensorflow/core/framework/local_rendezvous.cc:421] Local rendezvous recv item cancelled. Key hash: 14716330697467514592\n",
      "2023-12-10 01:15:51.838615: I tensorflow/core/framework/local_rendezvous.cc:421] Local rendezvous recv item cancelled. Key hash: 16669695245131575060\n",
      "2023-12-10 01:15:51.838623: I tensorflow/core/framework/local_rendezvous.cc:421] Local rendezvous recv item cancelled. Key hash: 5984153677829664860\n",
      "2023-12-10 01:15:51.838631: I tensorflow/core/framework/local_rendezvous.cc:421] Local rendezvous recv item cancelled. Key hash: 1963642536478110226\n",
      "2023-12-10 01:15:51.838638: I tensorflow/core/framework/local_rendezvous.cc:421] Local rendezvous recv item cancelled. Key hash: 18031821842217636660\n",
      "2023-12-10 01:15:51.838646: I tensorflow/core/framework/local_rendezvous.cc:421] Local rendezvous recv item cancelled. Key hash: 2718407136512890062\n",
      "2023-12-10 01:15:51.838653: I tensorflow/core/framework/local_rendezvous.cc:421] Local rendezvous recv item cancelled. Key hash: 6718964559560619236\n",
      "2023-12-10 01:15:51.838661: I tensorflow/core/framework/local_rendezvous.cc:421] Local rendezvous recv item cancelled. Key hash: 12237984728763184414\n",
      "2023-12-10 01:15:51.838680: I tensorflow/core/framework/local_rendezvous.cc:421] Local rendezvous recv item cancelled. Key hash: 17828366282834016438\n",
      "2023-12-10 01:15:51.838687: I tensorflow/core/framework/local_rendezvous.cc:421] Local rendezvous recv item cancelled. Key hash: 7255051240670812670\n",
      "2023-12-10 01:15:51.838695: I tensorflow/core/framework/local_rendezvous.cc:421] Local rendezvous recv item cancelled. Key hash: 16015439758968961860\n",
      "2023-12-10 01:15:51.838704: I tensorflow/core/framework/local_rendezvous.cc:421] Local rendezvous recv item cancelled. Key hash: 10771079674870644394\n",
      "2023-12-10 01:15:51.839024: W tensorflow/core/framework/op_kernel.cc:1839] OP_REQUIRES failed at xla_ops.cc:562 : INVALID_ARGUMENT: Trying to access resource Resource-23-at-0x558aecad5480 (defined @ /opt/conda/envs/rapids/lib/python3.10/site-packages/keras/src/engine/base_layer_utils.py:137) located in device /job:localhost/replica:0/task:0/device:GPU:0 from device /job:localhost/replica:0/task:0/device:CPU:0\n",
      " Cf. https://www.tensorflow.org/xla/known_issues#tfvariable_on_a_different_device\n",
      "2023-12-10 01:15:51.839074: W tensorflow/core/framework/op_kernel.cc:1839] OP_REQUIRES failed at xla_ops.cc:562 : INVALID_ARGUMENT: Trying to access resource Resource-22-at-0x558aec8d2d60 (defined @ /opt/conda/envs/rapids/lib/python3.10/site-packages/keras/src/engine/base_layer_utils.py:137) located in device /job:localhost/replica:0/task:0/device:GPU:0 from device /job:localhost/replica:0/task:0/device:CPU:0\n",
      " Cf. https://www.tensorflow.org/xla/known_issues#tfvariable_on_a_different_device\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Graph execution error:\n\nDetected at node RMSprop/StatefulPartitionedCall_25 defined at (most recent call last):\n  File \"/opt/conda/envs/rapids/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n\n  File \"/opt/conda/envs/rapids/lib/python3.10/runpy.py\", line 86, in _run_code\n\n  File \"/opt/conda/envs/rapids/lib/python3.10/site-packages/ipykernel_launcher.py\", line 17, in <module>\n\n  File \"/opt/conda/envs/rapids/lib/python3.10/site-packages/traitlets/config/application.py\", line 1043, in launch_instance\n\n  File \"/opt/conda/envs/rapids/lib/python3.10/site-packages/ipykernel/kernelapp.py\", line 725, in start\n\n  File \"/opt/conda/envs/rapids/lib/python3.10/site-packages/tornado/platform/asyncio.py\", line 195, in start\n\n  File \"/opt/conda/envs/rapids/lib/python3.10/asyncio/base_events.py\", line 603, in run_forever\n\n  File \"/opt/conda/envs/rapids/lib/python3.10/asyncio/base_events.py\", line 1909, in _run_once\n\n  File \"/opt/conda/envs/rapids/lib/python3.10/asyncio/events.py\", line 80, in _run\n\n  File \"/opt/conda/envs/rapids/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 513, in dispatch_queue\n\n  File \"/opt/conda/envs/rapids/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 502, in process_one\n\n  File \"/opt/conda/envs/rapids/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 409, in dispatch_shell\n\n  File \"/opt/conda/envs/rapids/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 729, in execute_request\n\n  File \"/opt/conda/envs/rapids/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 429, in do_execute\n\n  File \"/opt/conda/envs/rapids/lib/python3.10/site-packages/ipykernel/zmqshell.py\", line 540, in run_cell\n\n  File \"/opt/conda/envs/rapids/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 2914, in run_cell\n\n  File \"/opt/conda/envs/rapids/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 2960, in _run_cell\n\n  File \"/opt/conda/envs/rapids/lib/python3.10/site-packages/IPython/core/async_helpers.py\", line 78, in _pseudo_sync_runner\n\n  File \"/opt/conda/envs/rapids/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3185, in run_cell_async\n\n  File \"/opt/conda/envs/rapids/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3377, in run_ast_nodes\n\n  File \"/opt/conda/envs/rapids/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3457, in run_code\n\n  File \"/tmp/ipykernel_361001/1375305670.py\", line 1, in <module>\n\n  File \"/opt/conda/envs/rapids/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 2419, in run_cell_magic\n\n  File \"/opt/conda/envs/rapids/lib/python3.10/site-packages/decorator.py\", line 232, in fun\n\n  File \"/opt/conda/envs/rapids/lib/python3.10/site-packages/IPython/core/magic.py\", line 187, in <lambda>\n\n  File \"/opt/conda/envs/rapids/lib/python3.10/site-packages/IPython/core/magics/execution.py\", line 1335, in time\n\n  File \"<timed exec>\", line 6, in <module>\n\n  File \"/opt/conda/envs/rapids/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n\n  File \"/opt/conda/envs/rapids/lib/python3.10/site-packages/keras/src/engine/training.py\", line 1783, in fit\n\n  File \"/opt/conda/envs/rapids/lib/python3.10/site-packages/keras/src/engine/training.py\", line 1377, in train_function\n\n  File \"/opt/conda/envs/rapids/lib/python3.10/site-packages/keras/src/engine/training.py\", line 1360, in step_function\n\n  File \"/opt/conda/envs/rapids/lib/python3.10/site-packages/keras/src/engine/training.py\", line 1349, in run_step\n\n  File \"/opt/conda/envs/rapids/lib/python3.10/site-packages/keras/src/engine/training.py\", line 1130, in train_step\n\n  File \"/opt/conda/envs/rapids/lib/python3.10/site-packages/keras/src/optimizers/optimizer.py\", line 544, in minimize\n\n  File \"/opt/conda/envs/rapids/lib/python3.10/site-packages/keras/src/optimizers/optimizer.py\", line 1223, in apply_gradients\n\n  File \"/opt/conda/envs/rapids/lib/python3.10/site-packages/keras/src/optimizers/optimizer.py\", line 652, in apply_gradients\n\n  File \"/opt/conda/envs/rapids/lib/python3.10/site-packages/keras/src/optimizers/optimizer.py\", line 1253, in _internal_apply_gradients\n\n  File \"/opt/conda/envs/rapids/lib/python3.10/site-packages/keras/src/optimizers/optimizer.py\", line 1345, in _distributed_apply_gradients_fn\n\n  File \"/opt/conda/envs/rapids/lib/python3.10/site-packages/keras/src/optimizers/optimizer.py\", line 1340, in apply_grad_to_update_var\n\nDetected at node RMSprop/StatefulPartitionedCall_25 defined at (most recent call last):\n  File \"/opt/conda/envs/rapids/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n\n  File \"/opt/conda/envs/rapids/lib/python3.10/runpy.py\", line 86, in _run_code\n\n  File \"/opt/conda/envs/rapids/lib/python3.10/site-packages/ipykernel_launcher.py\", line 17, in <module>\n\n  File \"/opt/conda/envs/rapids/lib/python3.10/site-packages/traitlets/config/application.py\", line 1043, in launch_instance\n\n  File \"/opt/conda/envs/rapids/lib/python3.10/site-packages/ipykernel/kernelapp.py\", line 725, in start\n\n  File \"/opt/conda/envs/rapids/lib/python3.10/site-packages/tornado/platform/asyncio.py\", line 195, in start\n\n  File \"/opt/conda/envs/rapids/lib/python3.10/asyncio/base_events.py\", line 603, in run_forever\n\n  File \"/opt/conda/envs/rapids/lib/python3.10/asyncio/base_events.py\", line 1909, in _run_once\n\n  File \"/opt/conda/envs/rapids/lib/python3.10/asyncio/events.py\", line 80, in _run\n\n  File \"/opt/conda/envs/rapids/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 513, in dispatch_queue\n\n  File \"/opt/conda/envs/rapids/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 502, in process_one\n\n  File \"/opt/conda/envs/rapids/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 409, in dispatch_shell\n\n  File \"/opt/conda/envs/rapids/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 729, in execute_request\n\n  File \"/opt/conda/envs/rapids/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 429, in do_execute\n\n  File \"/opt/conda/envs/rapids/lib/python3.10/site-packages/ipykernel/zmqshell.py\", line 540, in run_cell\n\n  File \"/opt/conda/envs/rapids/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 2914, in run_cell\n\n  File \"/opt/conda/envs/rapids/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 2960, in _run_cell\n\n  File \"/opt/conda/envs/rapids/lib/python3.10/site-packages/IPython/core/async_helpers.py\", line 78, in _pseudo_sync_runner\n\n  File \"/opt/conda/envs/rapids/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3185, in run_cell_async\n\n  File \"/opt/conda/envs/rapids/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3377, in run_ast_nodes\n\n  File \"/opt/conda/envs/rapids/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3457, in run_code\n\n  File \"/tmp/ipykernel_361001/1375305670.py\", line 1, in <module>\n\n  File \"/opt/conda/envs/rapids/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 2419, in run_cell_magic\n\n  File \"/opt/conda/envs/rapids/lib/python3.10/site-packages/decorator.py\", line 232, in fun\n\n  File \"/opt/conda/envs/rapids/lib/python3.10/site-packages/IPython/core/magic.py\", line 187, in <lambda>\n\n  File \"/opt/conda/envs/rapids/lib/python3.10/site-packages/IPython/core/magics/execution.py\", line 1335, in time\n\n  File \"<timed exec>\", line 6, in <module>\n\n  File \"/opt/conda/envs/rapids/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n\n  File \"/opt/conda/envs/rapids/lib/python3.10/site-packages/keras/src/engine/training.py\", line 1783, in fit\n\n  File \"/opt/conda/envs/rapids/lib/python3.10/site-packages/keras/src/engine/training.py\", line 1377, in train_function\n\n  File \"/opt/conda/envs/rapids/lib/python3.10/site-packages/keras/src/engine/training.py\", line 1360, in step_function\n\n  File \"/opt/conda/envs/rapids/lib/python3.10/site-packages/keras/src/engine/training.py\", line 1349, in run_step\n\n  File \"/opt/conda/envs/rapids/lib/python3.10/site-packages/keras/src/engine/training.py\", line 1130, in train_step\n\n  File \"/opt/conda/envs/rapids/lib/python3.10/site-packages/keras/src/optimizers/optimizer.py\", line 544, in minimize\n\n  File \"/opt/conda/envs/rapids/lib/python3.10/site-packages/keras/src/optimizers/optimizer.py\", line 1223, in apply_gradients\n\n  File \"/opt/conda/envs/rapids/lib/python3.10/site-packages/keras/src/optimizers/optimizer.py\", line 652, in apply_gradients\n\n  File \"/opt/conda/envs/rapids/lib/python3.10/site-packages/keras/src/optimizers/optimizer.py\", line 1253, in _internal_apply_gradients\n\n  File \"/opt/conda/envs/rapids/lib/python3.10/site-packages/keras/src/optimizers/optimizer.py\", line 1345, in _distributed_apply_gradients_fn\n\n  File \"/opt/conda/envs/rapids/lib/python3.10/site-packages/keras/src/optimizers/optimizer.py\", line 1340, in apply_grad_to_update_var\n\n2 root error(s) found.\n  (0) INVALID_ARGUMENT:  Trying to access resource Resource-25-at-0x558aeba265c0 (defined @ /opt/conda/envs/rapids/lib/python3.10/site-packages/keras/src/engine/base_layer_utils.py:137) located in device /job:localhost/replica:0/task:0/device:GPU:0 from device /job:localhost/replica:0/task:0/device:CPU:0\n Cf. https://www.tensorflow.org/xla/known_issues#tfvariable_on_a_different_device\n\t [[{{node RMSprop/StatefulPartitionedCall_25}}]]\n\t [[Cumsum_4/_74]]\n  (1) INVALID_ARGUMENT:  Trying to access resource Resource-25-at-0x558aeba265c0 (defined @ /opt/conda/envs/rapids/lib/python3.10/site-packages/keras/src/engine/base_layer_utils.py:137) located in device /job:localhost/replica:0/task:0/device:GPU:0 from device /job:localhost/replica:0/task:0/device:CPU:0\n Cf. https://www.tensorflow.org/xla/known_issues#tfvariable_on_a_different_device\n\t [[{{node RMSprop/StatefulPartitionedCall_25}}]]\n0 successful operations.\n0 derived errors ignored. [Op:__inference_train_function_17959]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/rapids/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/rapids/lib/python3.10/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     ]\n\u001b[0;32m---> 60\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     61\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     62\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Graph execution error:\n\nDetected at node RMSprop/StatefulPartitionedCall_25 defined at (most recent call last):\n  File \"/opt/conda/envs/rapids/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n\n  File \"/opt/conda/envs/rapids/lib/python3.10/runpy.py\", line 86, in _run_code\n\n  File \"/opt/conda/envs/rapids/lib/python3.10/site-packages/ipykernel_launcher.py\", line 17, in <module>\n\n  File \"/opt/conda/envs/rapids/lib/python3.10/site-packages/traitlets/config/application.py\", line 1043, in launch_instance\n\n  File \"/opt/conda/envs/rapids/lib/python3.10/site-packages/ipykernel/kernelapp.py\", line 725, in start\n\n  File \"/opt/conda/envs/rapids/lib/python3.10/site-packages/tornado/platform/asyncio.py\", line 195, in start\n\n  File \"/opt/conda/envs/rapids/lib/python3.10/asyncio/base_events.py\", line 603, in run_forever\n\n  File \"/opt/conda/envs/rapids/lib/python3.10/asyncio/base_events.py\", line 1909, in _run_once\n\n  File \"/opt/conda/envs/rapids/lib/python3.10/asyncio/events.py\", line 80, in _run\n\n  File \"/opt/conda/envs/rapids/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 513, in dispatch_queue\n\n  File \"/opt/conda/envs/rapids/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 502, in process_one\n\n  File \"/opt/conda/envs/rapids/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 409, in dispatch_shell\n\n  File \"/opt/conda/envs/rapids/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 729, in execute_request\n\n  File \"/opt/conda/envs/rapids/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 429, in do_execute\n\n  File \"/opt/conda/envs/rapids/lib/python3.10/site-packages/ipykernel/zmqshell.py\", line 540, in run_cell\n\n  File \"/opt/conda/envs/rapids/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 2914, in run_cell\n\n  File \"/opt/conda/envs/rapids/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 2960, in _run_cell\n\n  File \"/opt/conda/envs/rapids/lib/python3.10/site-packages/IPython/core/async_helpers.py\", line 78, in _pseudo_sync_runner\n\n  File \"/opt/conda/envs/rapids/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3185, in run_cell_async\n\n  File \"/opt/conda/envs/rapids/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3377, in run_ast_nodes\n\n  File \"/opt/conda/envs/rapids/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3457, in run_code\n\n  File \"/tmp/ipykernel_361001/1375305670.py\", line 1, in <module>\n\n  File \"/opt/conda/envs/rapids/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 2419, in run_cell_magic\n\n  File \"/opt/conda/envs/rapids/lib/python3.10/site-packages/decorator.py\", line 232, in fun\n\n  File \"/opt/conda/envs/rapids/lib/python3.10/site-packages/IPython/core/magic.py\", line 187, in <lambda>\n\n  File \"/opt/conda/envs/rapids/lib/python3.10/site-packages/IPython/core/magics/execution.py\", line 1335, in time\n\n  File \"<timed exec>\", line 6, in <module>\n\n  File \"/opt/conda/envs/rapids/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n\n  File \"/opt/conda/envs/rapids/lib/python3.10/site-packages/keras/src/engine/training.py\", line 1783, in fit\n\n  File \"/opt/conda/envs/rapids/lib/python3.10/site-packages/keras/src/engine/training.py\", line 1377, in train_function\n\n  File \"/opt/conda/envs/rapids/lib/python3.10/site-packages/keras/src/engine/training.py\", line 1360, in step_function\n\n  File \"/opt/conda/envs/rapids/lib/python3.10/site-packages/keras/src/engine/training.py\", line 1349, in run_step\n\n  File \"/opt/conda/envs/rapids/lib/python3.10/site-packages/keras/src/engine/training.py\", line 1130, in train_step\n\n  File \"/opt/conda/envs/rapids/lib/python3.10/site-packages/keras/src/optimizers/optimizer.py\", line 544, in minimize\n\n  File \"/opt/conda/envs/rapids/lib/python3.10/site-packages/keras/src/optimizers/optimizer.py\", line 1223, in apply_gradients\n\n  File \"/opt/conda/envs/rapids/lib/python3.10/site-packages/keras/src/optimizers/optimizer.py\", line 652, in apply_gradients\n\n  File \"/opt/conda/envs/rapids/lib/python3.10/site-packages/keras/src/optimizers/optimizer.py\", line 1253, in _internal_apply_gradients\n\n  File \"/opt/conda/envs/rapids/lib/python3.10/site-packages/keras/src/optimizers/optimizer.py\", line 1345, in _distributed_apply_gradients_fn\n\n  File \"/opt/conda/envs/rapids/lib/python3.10/site-packages/keras/src/optimizers/optimizer.py\", line 1340, in apply_grad_to_update_var\n\nDetected at node RMSprop/StatefulPartitionedCall_25 defined at (most recent call last):\n  File \"/opt/conda/envs/rapids/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n\n  File \"/opt/conda/envs/rapids/lib/python3.10/runpy.py\", line 86, in _run_code\n\n  File \"/opt/conda/envs/rapids/lib/python3.10/site-packages/ipykernel_launcher.py\", line 17, in <module>\n\n  File \"/opt/conda/envs/rapids/lib/python3.10/site-packages/traitlets/config/application.py\", line 1043, in launch_instance\n\n  File \"/opt/conda/envs/rapids/lib/python3.10/site-packages/ipykernel/kernelapp.py\", line 725, in start\n\n  File \"/opt/conda/envs/rapids/lib/python3.10/site-packages/tornado/platform/asyncio.py\", line 195, in start\n\n  File \"/opt/conda/envs/rapids/lib/python3.10/asyncio/base_events.py\", line 603, in run_forever\n\n  File \"/opt/conda/envs/rapids/lib/python3.10/asyncio/base_events.py\", line 1909, in _run_once\n\n  File \"/opt/conda/envs/rapids/lib/python3.10/asyncio/events.py\", line 80, in _run\n\n  File \"/opt/conda/envs/rapids/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 513, in dispatch_queue\n\n  File \"/opt/conda/envs/rapids/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 502, in process_one\n\n  File \"/opt/conda/envs/rapids/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 409, in dispatch_shell\n\n  File \"/opt/conda/envs/rapids/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 729, in execute_request\n\n  File \"/opt/conda/envs/rapids/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 429, in do_execute\n\n  File \"/opt/conda/envs/rapids/lib/python3.10/site-packages/ipykernel/zmqshell.py\", line 540, in run_cell\n\n  File \"/opt/conda/envs/rapids/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 2914, in run_cell\n\n  File \"/opt/conda/envs/rapids/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 2960, in _run_cell\n\n  File \"/opt/conda/envs/rapids/lib/python3.10/site-packages/IPython/core/async_helpers.py\", line 78, in _pseudo_sync_runner\n\n  File \"/opt/conda/envs/rapids/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3185, in run_cell_async\n\n  File \"/opt/conda/envs/rapids/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3377, in run_ast_nodes\n\n  File \"/opt/conda/envs/rapids/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3457, in run_code\n\n  File \"/tmp/ipykernel_361001/1375305670.py\", line 1, in <module>\n\n  File \"/opt/conda/envs/rapids/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 2419, in run_cell_magic\n\n  File \"/opt/conda/envs/rapids/lib/python3.10/site-packages/decorator.py\", line 232, in fun\n\n  File \"/opt/conda/envs/rapids/lib/python3.10/site-packages/IPython/core/magic.py\", line 187, in <lambda>\n\n  File \"/opt/conda/envs/rapids/lib/python3.10/site-packages/IPython/core/magics/execution.py\", line 1335, in time\n\n  File \"<timed exec>\", line 6, in <module>\n\n  File \"/opt/conda/envs/rapids/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n\n  File \"/opt/conda/envs/rapids/lib/python3.10/site-packages/keras/src/engine/training.py\", line 1783, in fit\n\n  File \"/opt/conda/envs/rapids/lib/python3.10/site-packages/keras/src/engine/training.py\", line 1377, in train_function\n\n  File \"/opt/conda/envs/rapids/lib/python3.10/site-packages/keras/src/engine/training.py\", line 1360, in step_function\n\n  File \"/opt/conda/envs/rapids/lib/python3.10/site-packages/keras/src/engine/training.py\", line 1349, in run_step\n\n  File \"/opt/conda/envs/rapids/lib/python3.10/site-packages/keras/src/engine/training.py\", line 1130, in train_step\n\n  File \"/opt/conda/envs/rapids/lib/python3.10/site-packages/keras/src/optimizers/optimizer.py\", line 544, in minimize\n\n  File \"/opt/conda/envs/rapids/lib/python3.10/site-packages/keras/src/optimizers/optimizer.py\", line 1223, in apply_gradients\n\n  File \"/opt/conda/envs/rapids/lib/python3.10/site-packages/keras/src/optimizers/optimizer.py\", line 652, in apply_gradients\n\n  File \"/opt/conda/envs/rapids/lib/python3.10/site-packages/keras/src/optimizers/optimizer.py\", line 1253, in _internal_apply_gradients\n\n  File \"/opt/conda/envs/rapids/lib/python3.10/site-packages/keras/src/optimizers/optimizer.py\", line 1345, in _distributed_apply_gradients_fn\n\n  File \"/opt/conda/envs/rapids/lib/python3.10/site-packages/keras/src/optimizers/optimizer.py\", line 1340, in apply_grad_to_update_var\n\n2 root error(s) found.\n  (0) INVALID_ARGUMENT:  Trying to access resource Resource-25-at-0x558aeba265c0 (defined @ /opt/conda/envs/rapids/lib/python3.10/site-packages/keras/src/engine/base_layer_utils.py:137) located in device /job:localhost/replica:0/task:0/device:GPU:0 from device /job:localhost/replica:0/task:0/device:CPU:0\n Cf. https://www.tensorflow.org/xla/known_issues#tfvariable_on_a_different_device\n\t [[{{node RMSprop/StatefulPartitionedCall_25}}]]\n\t [[Cumsum_4/_74]]\n  (1) INVALID_ARGUMENT:  Trying to access resource Resource-25-at-0x558aeba265c0 (defined @ /opt/conda/envs/rapids/lib/python3.10/site-packages/keras/src/engine/base_layer_utils.py:137) located in device /job:localhost/replica:0/task:0/device:GPU:0 from device /job:localhost/replica:0/task:0/device:CPU:0\n Cf. https://www.tensorflow.org/xla/known_issues#tfvariable_on_a_different_device\n\t [[{{node RMSprop/StatefulPartitionedCall_25}}]]\n0 successful operations.\n0 derived errors ignored. [Op:__inference_train_function_17959]"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# TF_GPU_ALLOCATOR=cuda_malloc_async\n",
    "#training\n",
    "with tf.device('/CPU:0'):\n",
    "    earlyStopping = EarlyStopping(monitor='val_auc', patience=50, verbose=0, mode='max', restore_best_weights=True)\n",
    "    mcp_save = ModelCheckpoint('../SeqModel/seqModel_therapy_tabSeq.mdl_wts.hdf5', save_best_only=True, monitor='val_auc', mode='min')\n",
    "    history = model.fit([Xt_train, Xclin_train[:,:max_codes_clin], Xther_train[:,:max_codes_ther]], y_train, validation_data=([Xt_val, Xclin_val[:,:max_codes_clin], Xther_val[:,:max_codes_ther]], y_val), \n",
    "                            epochs=epoch, batch_size=128, \n",
    "                        class_weight = class_weight, \n",
    "                        callbacks = [earlyStopping, mcp_save])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdbddf77-c941-48d2-9bbd-b80b77d85e5b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# list all data in history\n",
    "print(history.history.keys())\n",
    "# summarize history for accuracy\n",
    "plt.plot(history.history['auc'])\n",
    "plt.plot(history.history['val_auc'])\n",
    "plt.title('model AUC')\n",
    "plt.ylabel('AUC')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "# plt.ylim(0.3, 1)\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(history.history['auprc'])\n",
    "plt.plot(history.history['val_auprc'])\n",
    "plt.title('model auprc')\n",
    "# plt.ylim(0.3, 1)\n",
    "plt.ylabel('auprc')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1af5a989-8735-4b2e-955d-c4c1852626d4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with tf.device('/GPU:0'):\n",
    "    model.evaluate([Xt_eval, Xs_clin_eval[:,:max_codes_clin], Xs_ther_eval[:,:max_codes_ther]], y_eval)\n",
    "    model.evaluate([Xt_test, Xs_clin_test[:,:max_codes_clin], Xs_ther_test[:,:max_codes_ther]], y_test)\n",
    "    model.evaluate([Xt_testWales, Xs_clin_testWales[:,:max_codes_clin], Xs_ther_testWales[:,:max_codes_ther]], y_testWales)\n",
    "    model.evaluate([Xt_testScotland, Xs_clin_testScotland[:,:max_codes_clin], Xs_ther_testScotland[:,:max_codes_ther]], y_testScotland)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1f8ec53-d208-499f-8ff5-87d475065fd7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.predict([Xt_test, Xs_clin_test[:,:max_codes_clin], Xs_ther_test[:,:max_codes_ther]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50569eb6-1ac3-40f2-9c84-da785fdaff72",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def summariseResultWithThreshold (Xt_test, Xs_clin_test, Xs_ther_test, testY, model):\n",
    "    preds = model.predict([Xt_test, Xs_clin_test, Xs_ther_test])\n",
    "    # tn, fp, fn, tp = confusion_matrix(testY, preds).ravel()\n",
    "    # specificity = tn / (tn+fp)\n",
    "    # sensitivity = tp / (tp+fn)\n",
    "    # ppv = 100*tp/(tp+fp)\n",
    "    # npv = 100*tn/(fn+tn)\n",
    "    # acc = accuracy_score(testY, preds)\n",
    "    # f1score = f1_score(testY, preds, average = 'binary')\n",
    "    # balanceacc = balanced_accuracy_score(testY, preds)\n",
    "    fpr, tpr, thresholds = roc_curve(testY, preds, pos_label=1)\n",
    "    # aucscore = auc(fpr, tpr)\n",
    "    aucscore = roc_auc_score(testY, preds)\n",
    "    auprc = average_precision_score(testY, preds)\n",
    "    # plot_confusion_matrix(model, testX, testY, cmap='viridis')  \n",
    "    return np.round(aucscore,4), np.round(auprc,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e1a6da4-5e73-4a66-9597-c4239873e2e3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(summariseResultWithThreshold(Xt_eval, Xs_clin_eval[:,:max_codes_clin], Xs_ther_eval[:,:max_codes_ther], y_eval, model))\n",
    "print(summariseResultWithThreshold(Xt_test, Xs_clin_test[:,:max_codes_clin], Xs_ther_test[:,:max_codes_ther], y_test, model))\n",
    "print(summariseResultWithThreshold(Xt_testWales, Xs_clin_testWales[:,:max_codes_clin], Xs_ther_testWales[:,:max_codes_ther], y_testWales, model))\n",
    "print(summariseResultWithThreshold(Xt_testScotland, Xs_clin_testScotland[:,:max_codes_clin], Xs_ther_testScotland[:,:max_codes_ther], y_testScotland, model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afeed10f-72a8-457d-bfcb-f2662e74bfc6",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# %%time\n",
    "\n",
    "# # create the model\n",
    "# embedding_vector_length = 50\n",
    "# earlyStopping = EarlyStopping(monitor='val_auc', patience=10, verbose=0, mode='max', restore_best_weights=True)\n",
    "# mcp_save = ModelCheckpoint('../SeqModel/seqModel_therapy.mdl_wts.hdf5', save_best_only=True, monitor='val_auc', mode='min')\n",
    "\n",
    "# with tf.device('/GPU:0'):\n",
    "#     model = Sequential()\n",
    "#     model.add(Embedding(vocab_size, embedding_vector_length, input_length=max_codes))\n",
    "#     model.add(LSTM(128, return_sequences=True, kernel_regularizer=L1L2(l1=0.02, l2=0.03)))\n",
    "#     model.add(Dropout(0.5))\n",
    "#     model.add(LSTM(64,  kernel_regularizer=L1L2(l1=0.02, l2=0.03)))\n",
    "#     model.add(Dropout(0.5))\n",
    "#     model.add(Dense(32, activation=LeakyReLU(alpha=.3), kernel_regularizer=L1L2(l1=0.02, l2=0.03)))\n",
    "#     model.add(Dense(1, activation='sigmoid'))\n",
    "#     opt = Adadelta(learning_rate=5e-3, clipvalue=0.3)\n",
    "#     metrics = [\n",
    "#         AUC(num_thresholds=3, name='auc'),\n",
    "#     ]\n",
    "#     model.compile(loss='binary_crossentropy', optimizer=opt, metrics=metrics, )\n",
    "#     print(model.summary())\n",
    "#     history = model.fit(Xs_train, y_train, validation_data=(Xs_val, y_val), epochs=30, batch_size=128, class_weight = class_weight, callbacks = [earlyStopping, mcp_save])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4943f759-cf30-4366-b7c8-bf33fbb73101",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def earlyFussion():\n",
    "       \n",
    "    inputs1 = Input(shape=tab_feature_size)\n",
    "    inputs2 = Input(shape=max_codes)\n",
    "    inputs3 = Input(shape=max_codes)\n",
    "    \n",
    "    \n",
    "    #clinical embedding for lstm\n",
    "    embedding = Embedding(vocab_size, 50, input_length=max_codes)(inputs2)\n",
    "    \n",
    "    #month embedding for lstm\n",
    "    embedding_month = Embedding(month_size, 7, input_length=max_codes)(inputs3)\n",
    "    \n",
    "    nn = Dense(32, activation='relu', kernel_initializer='glorot_uniform', kernel_regularizer=L1L2(l1=0.0, l2=0.1))(inputs1)\n",
    "    nn = Dropout(0.5)(nn)\n",
    "    lstmClinical = Bidirectional(LSTM(units=16, return_sequences=True, kernel_regularizer=L1L2(l1=0.0, l2=0.1)))(embedding)\n",
    "    lstmMonth = Bidirectional(LSTM(units=16, return_sequences=True, kernel_regularizer=L1L2(l1=0.0, l2=0.1)))(embedding_month)\n",
    "    # lstm = Add()([lstmClinical, lstmMonth])\n",
    "    lstm = lstmClinical\n",
    "    \n",
    "    # nn = Reshape((1, 32))(nn)\n",
    "    # add = concatenate([nn, lstm], axis=1)\n",
    "    nn = Dense(16, activation='relu', kernel_initializer='glorot_uniform', kernel_regularizer=L1L2(l1=0.0, l2=0.1))(nn)\n",
    "    nn = Dropout(0.5)(nn)\n",
    "    lstm = Bidirectional(LSTM(units=8, return_sequences=True, kernel_regularizer=L1L2(l1=0.0, l2=0.1)))(lstm)\n",
    "    lstm = Dropout(0.5)(lstm)\n",
    "    \n",
    "    # # nn = Reshape((301, 64))(nn)\n",
    "    # add = concatenate([nn, lstm], axis=1)\n",
    "    nn = Dense(16, activation='relu', kernel_initializer='glorot_uniform', kernel_regularizer=L1L2(l1=0.0, l2=0.1))(nn)\n",
    "    nn = Dropout(0.5)(nn)\n",
    "    lstm = Bidirectional(LSTM(units=8, return_sequences=True, kernel_regularizer=L1L2(l1=0.0, l2=0.1)))(lstm)\n",
    "    lstm = Dropout(0.5)(lstm)\n",
    "    \n",
    "    nn = Reshape((1, 16))(nn)\n",
    "    model_tot = concatenate([nn, lstm], axis=1)\n",
    "    # model_tot = BatchNormalization()(model_tot)\n",
    "\n",
    "    model_tot = Dense(units=8, activation=LeakyReLU())(model_tot)\n",
    "    nn = Dropout(0.5)(nn)\n",
    "    \n",
    "    model_tot = Flatten()(model_tot)\n",
    "    output = Dense(1, activation='sigmoid')(model_tot)\n",
    "    \n",
    "    opt = RMSprop(learning_rate=1e-4, clipvalue=.5)\n",
    "    metrics = [\n",
    "        AUC(num_thresholds=3, name='auc', curve='ROC'),\n",
    "        AUC(num_thresholds=3, name='auprc', curve='PR'),\n",
    "        tf.keras.metrics.Precision(name='prec'),\n",
    "        tf.keras.metrics.Recall(name='rec'),\n",
    "        tf.keras.metrics.TrueNegatives(name='TN'),\n",
    "        tf.keras.metrics.TruePositives(name='TP'),\n",
    "        tf.keras.metrics.PrecisionAtRecall(0.8)\n",
    "    ]\n",
    "    \n",
    "    loss = tf.keras.losses.BinaryCrossentropy()\n",
    "    \n",
    "    model = Model(inputs=[inputs1, inputs2, inputs3], outputs=output)\n",
    "    model.compile(\n",
    "        loss='binary_crossentropy', \n",
    "        optimizer=opt, \n",
    "        metrics=metrics)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20c11344-dfa9-40e6-b2d2-63388d84ba09",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with tf.device('/GPU:0'):\n",
    "    model.evaluate([Xt_eval, Xs_eval[:,:max_codes], Xm_eval[:,:max_codes]], y_eval)\n",
    "    model.evaluate([Xt_test, Xs_test[:,:max_codes], Xm_test[:,:max_codes]], y_test)\n",
    "    # model.evaluate(X_testWales, y_testWales)\n",
    "    # model.evaluate(X_testScotland, y_testScotland)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f7fd35d-2903-48e4-a655-b55f16b99da1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Model evaluation function\n",
    "def summariseResult (testY, preds):\n",
    "    tn, fp, fn, tp = confusion_matrix(testY, preds).ravel()\n",
    "    specificity = tn / (tn+fp)\n",
    "    sensitivity = tp / (tp+fn)\n",
    "    ppv = 100*tp/(tp+fp)\n",
    "    npv = 100*tn/(fn+tn)\n",
    "    acc = accuracy_score(testY, preds)\n",
    "    f1score = f1_score(testY, preds, average = 'binary')\n",
    "    balanceacc = balanced_accuracy_score(testY, preds)\n",
    "    fpr, tpr, thresholds = roc_curve(testY, preds, pos_label=1)\n",
    "    aucscore = auc(fpr, tpr)\n",
    "    # aucscore = roc_auc_score(testY, preds)\n",
    "    auprc = average_precision_score(testY, preds)\n",
    "    # plot_confusion_matrix(model, testX, testY, cmap='viridis')  \n",
    "    return np.round(acc,4), np.round(specificity,4), np.round(sensitivity,4), np.round(aucscore,4), np.round(auprc,4), np.round(balanceacc,4), np.round(f1score,4), np.round(ppv,4), np.round(npv,4)\n",
    "\n",
    "data_test_Xs = [X_eval, X_test, X_testWales, X_testScotland]\n",
    "data_test_ys = [y_eval, y_test, y_testWales, y_testScotland]\n",
    "for data_test_X, data_test_y in zip(data_test_Xs, data_test_ys):\n",
    "    with tf.device('/CPU:0'):\n",
    "        preds = model.predict(data_test_X)\n",
    "    preds = [0 if pred <0.5 else 1 for pred in preds]\n",
    "    print(summariseResult(data_test_y, np.squeeze(preds)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8a50962-2f80-4931-8eb7-df84792130ed",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.save('../SeqModel/model_therapy.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1adb28e-44a2-4303-8b79-25348bfcaad9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from keras.models import load_model\n",
    "# a = load_model('../SeqModel/my_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f9f42bb-89f7-4693-852f-ae329cc7afe7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
